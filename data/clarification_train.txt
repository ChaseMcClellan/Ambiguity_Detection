Clarify this requirement: I find the left navigation button for "add connection" confusing.   It seems to be the gateway to two different features:  creating a new connection definition, and opening a new connection.

If it were me I would

1. Rename the button to "connect"
2. Remove the "New Connection" value from the slide-off
3. Make the slide-off from the button be the existing connection values (e.g. the ones that you get currently by doing to "new connection" -> "connection".
Ambiguous terms: confusing, new, existing
Questions:
1. What specifically makes the left navigation button for "add connection" confusing?
2. Can you clarify what you mean by "existing connection values"?
Clarified requirement: Modify the left navigation button labeled "add connection" by renaming it to "connect," removing the "New Connection" option from the slide-off menu, and displaying the current connection values in the slide-off menu instead.


Clarify this requirement: in the SQL pane, create a new sql statement:  

    select * from foo where id = 1234

highlight "1234" and right click.  Choose "copy"

Instead of copying the highlighted text, it seems to copy the entire contents of the SQL pane, not just the highlighted text.  It also brings up a modal dialog box containing the copied SQL which must be dismissed.

FWIW, ctrl-c and ctrl-v work as expected.

BONUS ISSUE:   the right-click does not offer you a "paste" option.

I'm running Firefox in Ubuntu Mate, if that makes any difference.
Ambiguous terms: highlighted, entire contents, modal dialog box, expected, right-click, paste, difference
Questions:
1. What is meant by "highlighted text" in this context?
2. Can you clarify what is considered the "entire contents" of the SQL pane?
Clarified requirement: In the SQL pane, create a new SQL statement, select * from foo where id = 1234. Then, highlight the specific text "1234" and right click to choose the "copy" option. The copied text should only be the highlighted "1234" text, not the entire contents of the SQL pane.


Clarify this requirement: The settings widget ("gears" icon in upper right corner) expands on hover.  There is just enough of a delay when I mouse over that that I click on the link. But by the time I click, the widget has expanded, and I end up clicking on the "logout" link.

Some alternative solutions

1. At a minimum, don't have a clickable link replace the hover zone
2. Leave that settings widget expanded at all times.  There is plenty of space.
3. Move the contents of the settings widget to the left-side menu bar.  That already includes some of the features from the widget anyway.
Ambiguous terms: enough, plenty, some
Questions:
1. What is considered "enough" delay when hovering over the settings widget?
2. How much space is considered "plenty" for the settings widget to be expanded at all times?
Clarified requirement: 3. Transfer the contents of the settings widget to the left-side menu bar, as it already contains some features from the widget.


Clarify this requirement: Very often we need to copy column name (table field name) to clipboard, but interface don't allow this. Can we make it possible, maybe via right-click menu "Copy column title"?
Ambiguous terms: very often, need, copy, column name, table field name, interface, make it possible, maybe, right-click menu
Questions:
1. What specific interface are you referring to that currently doesn't allow copying column names to the clipboard?
2. Are there any limitations or restrictions that need to be considered when implementing the "Copy column title" feature via the right-click menu?
Clarified requirement: Allow users to copy column names (table field names) to the clipboard by implementing a "Copy column title" feature accessible via the right-click menu in the specified interface.


Clarify this requirement: In most cases databases are launched locally on default ports. For simplify creating new connection will be good in "Create connection" form make "Server" and "Port" fields as not required, and test the database defaults (localhost and default port), if those fields are not filled. 
What do you think about this idea?
Ambiguous terms: good, simplify, required, defaults, filled
Questions:
1. What is meant by "good" in this context?
2. Can you clarify what is meant by "filled" in relation to the fields?
Clarified requirement: In most cases, databases are launched locally on default ports. To simplify creating a new connection, it would be beneficial to have the "Server" and "Port" fields in the "Create connection" form marked as optional. The database should default to localhost and the default port if these fields are left empty. What is your opinion on this approach?


Clarify this requirement: I would like to suggest a new feature that deals with the possibility of continuing to edit the SQL code in the editor while a specific query is running.
Ambiguous terms: possibility, specific
Questions:
1. What is meant by "possibility" in this context?
2. Can you clarify what is meant by "specific query"?
Clarified requirement: "I would like to suggest a new feature that allows users to continue editing the SQL code in the editor while a particular query is running."


Clarify this requirement: On macOS, every app is supposed to have a unique bundle identifier (`CFBundleIdentifier` key in `Info.plist`). A proper one for this app would be `org.omnidb.omnidb` or just `org.omnidb`.

Version 2 of this app had `com.electron.omnidb` which isn’t the best but it was good enough. However, the new betas use `io.nw.nwjs` which is incredibly generic. It means that other apps (and macOS in general) will have a harder time identifying and interacting with your app.
Ambiguous terms: unique, proper, best, good enough, incredibly generic, harder time
Questions:
1. What criteria determine a bundle identifier to be considered "proper"?
2. Can you provide examples of how a generic bundle identifier like `io.nw.nwjs` could cause issues with app identification and interaction on macOS?
Clarified requirement: On macOS, each app must have a unique bundle identifier (`CFBundleIdentifier` key in `Info.plist`). A bundle identifier like `org.omnidb.omnidb` or `org.omnidb` is considered proper. The previous version of the app used `com.electron.omnidb`, which was acceptable. However, the new betas use `io.nw.nwjs`, which is too generic and can lead to difficulties in app identification and interaction on macOS.


Clarify this requirement: When opening OmniDB, the application window always opens maximized to the screen, regardless of the application window size when last opened. Clicking the maximize icon in the upper right shrinks the window down, but not to the same size as when the application was previously open. This means I have to manually resize the application window every time I open the application.

Thanks for the good work! I really enjoy using OmniDB.

OmniDB 3.0.3b
macOS 10.15.7
Ambiguous terms: maximized, shrink, manually resize
Questions:
1. What do you mean by "maximized" in the context of the application window?
2. Can you clarify what you mean by "shrink" and "manually resize" in relation to the application window?
Clarified requirement: When opening OmniDB, the application window should always open to fill the entire screen. Clicking the maximize icon in the upper right should reduce the window size, but it should return to the same size as when the application was last opened. This should eliminate the need for manual resizing of the application window each time it is opened.


Clarify this requirement: Upon scrolling down in the query tab and resizing it to make it smaller, i.e. the query result bigger, it becomes impossible to scroll down completely, i.e. the lower part of the query can't be reached without increasing the query size again.
Ambiguous terms: smaller, bigger, impossible, completely, lower part, increasing
Questions:
1. What does "smaller" and "bigger" refer to in this context?
2. Can you clarify what is meant by "lower part" and "increasing"?
Clarified requirement: Upon scrolling down in the query tab and resizing it to decrease its size, i.e. making the query result larger, it becomes impossible to scroll down completely, i.e. the bottom part of the query can't be reached without increasing the query size again.


Clarify this requirement: I'm running a heroku instance with a Postgres add-on.  The server has ~2000 databases.  I can't find a way to filter to only show my database, is there a feature in OmniDB for that?
Ambiguous terms: filter, feature
Questions:
1. What specific criteria are you looking to use for filtering the databases?
2. Can you clarify what you mean by a "feature in OmniDB"?
Clarified requirement: Running a Heroku instance with a Postgres add-on containing approximately 2000 databases, the user is seeking a way to filter and display only their database within OmniDB.


Clarify this requirement: Suggestion: It allows to perform the SQL indentation from the Indent SQL button for a specific selected query.
Ambiguous terms: specific
Questions:
1. What does "specific selected query" refer to in this context?
2. Can you clarify what is meant by "performing the SQL indentation"?
Clarified requirement: "Suggestion: The feature allows users to perform SQL indentation by clicking the Indent SQL button for a selected query."


Clarify this requirement: OmniDB 3 b slows down significantly during typing of the search actually turns up objects matching the completion. Even a keystroke isn't necessarily helping. It seems the list is newly generated for every prefix after every keystroke, even though I finished typing the complete relname already. That is particular annoying when OmniDB starts to do lookups of relations within the where or the group by clause.

There is even a case when the js is very slow, where the cursor looses focus. I can reproduce that behavior by typing a frequent regclass prefix, but I don't know what causes this.

All the best
pgaro
Ambiguous terms: significantly, slow, particular, annoying, very slow
Questions:
1. What specific actions are considered slow in OmniDB 3 b?
2. Can you provide more details about the behavior when the cursor loses focus?
Clarified requirement: OmniDB 3 b experiences significant slowdowns during the typing of searches that match completion. The list appears to be regenerated for every prefix even after completing the full relname. This behavior is particularly annoying when OmniDB performs lookups of relations in the where or group by clause. Additionally, there are instances where the JavaScript is slow, causing the cursor to lose focus, particularly when typing a frequent regclass prefix. The exact cause of this behavior is unknown.


Clarify this requirement: Not specifying a value leads to '' for strings and a syntax error for int etc.

While the later is awful, I think the former is not really desirable either. null sounds like the sane default to me, in particular since that does avoid postgres internal defaults for triggering. Which has the advantage of being independent from the type.
Ambiguous terms: null, sane, desirable, avoid, independent
Questions:
1. What is meant by "null" in this context?
2. Can you clarify what is meant by "sane default"?
Clarified requirement: Not specifying a value should result in 'null' for strings and a syntax error for integers. However, using 'null' as the default value is preferred to avoid triggering internal defaults in Postgres, as it is independent from the data type.


Clarify this requirement: This is the main functionalities I'm missing all the time. The idea would be to simply open the function/table with the corresponding regclass/regproc without the need to tediously navigate through the entire tree.
Ambiguous terms: main, simply, tediously, entire
Questions:
1. What specific functionalities are missing?
2. Can you clarify what you mean by "navigating through the entire tree"?
Clarified requirement: The missing functionalities refer to the ability to open the function/table with the corresponding regclass/regproc without the need for extensive navigation through the tree.


Clarify this requirement: use ssh agent is much easier to use. we can just ssh-add then omnidb should be ready to connect.

It will also be much useful, if the omnidb allow custom ssh command or just use the same .ssh/config as ssh command.
Ambiguous terms: easier, useful, custom, same
Questions:
1. What specifically makes using the ssh agent easier?
2. Can you clarify what you mean by "custom ssh command" and using the "same .ssh/config as ssh command"?
Clarified requirement: Utilize the ssh agent for easier connection to Omnidb by running ssh-add, and enable the option for Omnidb to either accept custom ssh commands or use the .ssh/config file for configuration.


Clarify this requirement: Hi, 
Are there any plans to support other databases besides the standard SQL? Example ElasticSearch, Mongo, Cassandra?
Ambiguous terms: plans, support, other databases, standard SQL, Example, ElasticSearch, Mongo, Cassandra
Questions:
1. What is meant by "plans" in this context?
2. Can you clarify what is meant by "support" for other databases?
Clarified requirement: Determine if there are intentions to add compatibility for databases such as ElasticSearch, Mongo, and Cassandra in addition to standard SQL.


Clarify this requirement: Suggestion: I don't particularly use the autocomplete and whenever I open OmniDB, I need to disable the button for all databases that are opened.
Ambiguous terms: particularly, user-friendly
Questions:
1. What is meant by "disable the button" in this context?
2. What is the specific action that needs to be taken regarding the autocomplete feature?
Clarified requirement: "Suggestion: When opening OmniDB, I do not use the autocomplete feature. I need to disable the autocomplete button for all opened databases."


Clarify this requirement: Wouldn't be great to have version control (git) for pulling and pushing the snippets from/to a snippets repo. 
I know there are open source components for doing that, such as https://github.com/alberthier/git-webui, which can be added into OmniDB roadmap.
Ambiguous terms: great, user-friendly, open source, roadmap
Questions:
1. What specific features or functionalities are desired in the version control system for snippets?
2. What is meant by adding the open source component into the OmniDB roadmap?
Clarified requirement: Implement version control (git) functionality for pulling and pushing code snippets to a snippets repository. Consider integrating open source components like https://github.com/alberthier/git-webui into the development plan for OmniDB.


Clarify this requirement: Every time I open OmniDB or reload the page, I must click and scroll through five levels of tree navigation to get to the (only) schema I use. 

- It would be nice if OmniDB remembered the tree state for each connection tab - ! 
- Alternatively/additionally, connections could have a 'default' tree state that they open in. 
- Or, one could save the tree state as a bookmark, to open it in a single click. 

My tree levels are Postgres 11.6 -> Databases -> myDB -> Schemas -> mySchema.
I never need/use anything in the tree except mySchema. 

Thanks! I love OmniDB!
Ambiguous terms: nice, remembered, default, single click, love
Questions:
1. What does it mean for OmniDB to "remember the tree state" for each connection tab?
2. How would saving the tree state as a bookmark work in this context?
Clarified requirement: Every time the user opens OmniDB or reloads the page, they must click and scroll through five levels of tree navigation to get to the schema they use. The user would like OmniDB to store the tree state for each connection tab or have connections open in a default tree state. Additionally, they suggest being able to save the tree state as a bookmark for one-click access. The user's tree levels are Postgres 11.6 -> Databases -> myDB -> Schemas -> mySchema, and they only need to access mySchema.


Clarify this requirement: I am finding difficult to view which server I am working on. 
I always work with minimum 3 server and always need to switch to other server

1. In Sidebar current server shows as Icon when you move mouse then only it is showing detail of connection
2. In tree view also no IP address or connection-name showing.

if you can add ip address/connection-name in tree view that will help.
Ambiguous terms: difficult, minimum, switch, detail, help
Questions:
1. What specific information about the server connection is missing in the current view?
2. Can you clarify what you mean by "switching to other server"?
Clarified requirement: It is challenging to identify the server being worked on due to lack of detailed information in the current view. The sidebar only displays the server as an icon, revealing connection details when the mouse hovers over it. Additionally, the tree view does not show the IP address or connection name. Adding the IP address/connection name in the tree view would facilitate server identification.


Clarify this requirement: Hello folks, 

After some comments and tests, we decided to open this issue so the community could propose and decide on which shortcuts should be maintained in OmniDB. This may be constantly updated according to comments and considerations.

**Now available**:
- `Autocomplete`
- `Cancel Query`
- `Indent`
- `New Inner Tab`
- `Remove Current Inner Tab`
- `Run Explain`
- `Run Explain Analyze`
- `Run Query`
- `Select Left Inner Tab`
- `Select Right Inner Tab`

**Returning** (being re-included):
- `Next Command (Console Tab)`
- `Previous Command (Console Tab)`
- `Select Left Outer Tab`
- `Select Right Outer Tab`

**Removed**:
- `New Connection Tab`
- `Remove Current Connection Tab`

**NEW**:
- empty

Thanks
Ambiguous terms: constantly, maintained, community, considerations, available, Returning, Removed, NEW
Questions:
1. What does "constantly updated" mean in this context?
2. Can you clarify what is meant by "community" proposing and deciding on shortcuts?
Clarified requirement: Thanks.


Clarify this requirement: How can I change the font size of editor and interface separately. 

In old version there is option to do the same.
Ambiguous terms: separately, option
Questions:
1. What specifically do you mean by changing the font size of the editor and interface separately?
2. Can you clarify what you mean by "option" in the context of the old version?
Clarified requirement: Change the font size of the editor and interface independently. In the old version, there was a specific feature that allowed this customization.


Clarify this requirement: In 3.0.2b the ssh tab only uses a little box in the tab in the up-left corner
![image](https://user-images.githubusercontent.com/36895220/98289374-15f65800-1f76-11eb-94c0-a69dce2ce3cb.png)
Ambiguous terms: little, up-left
Questions:
1. What does "little box" refer to in the ssh tab?
2. Can you clarify the specific location of the "up-left corner" within the ssh tab?
Clarified requirement: In version 3.0.2b, the ssh tab contains a small box located in the upper-left corner.


Clarify this requirement: Follow-up of #403 

Implement a way for the user to override OmniDB default layout, specifying custom dimensions of each panel
Ambiguous terms: way, custom, dimensions
Questions:
1. What specific aspects of the default layout can the user override?
2. Can you provide more details on what is meant by "custom dimensions"?
Clarified requirement: Follow-up of #403: Implement functionality for the user to modify the default layout of OmniDB by specifying unique dimensions for each panel.


Clarify this requirement: Hi guys, can you please add the ability to view objects of other schemas in oracle connections ?
Ambiguous terms: ability, view, objects, other, schemas, oracle connections
Questions:
1. What specifically do you mean by "view objects"?
2. Can you clarify what you mean by "other schemas" in this context?
Clarified requirement: Add the capability to access and display objects from different schemas within Oracle connections.


Clarify this requirement: The OmniDB icon in the lower right corner, is overlapping the list scroll, this prevents the scroll from being pulled via click.

![image](https://user-images.githubusercontent.com/11354911/97636206-856cc480-1a17-11eb-9466-4be410be2720.png)
Ambiguous terms: overlapping, prevents, pulled
Questions:
1. What does it mean for the OmniDB icon to be "overlapping" the list scroll?
2. Can you clarify what you mean by "prevents the scroll from being pulled via click"?
Clarified requirement: The OmniDB icon in the lower right corner is covering a part of the list scroll, making it inaccessible for clicking and scrolling.


Clarify this requirement: Outer Menu is not very practical yet.

As of now, the outer menu is collapsed by default when working on a clientWindow that is smaller than 1981px.
While extended, it is floating above the content.

This is not ideal, forcing the user to navigate the menu or expand it manually to better locate connections.

Suggestion is to apply the large screen layout when extended and apply it as the default status.

![menu_change](https://user-images.githubusercontent.com/11302800/97593840-d57c6480-19e0-11eb-9c42-07d2120195fd.png)
Ambiguous terms: very practical, ideal, better
Questions:
1. What specific aspects of the current outer menu make it impractical?
2. Can you clarify what you mean by "large screen layout" in this context?
Clarified requirement: The current outer menu is collapsed by default on clientWindows smaller than 1981px, making it difficult for users to locate connections. The suggestion is to change the default status of the menu to the extended large screen layout shown in the image provided.


Clarify this requirement: One thing I wondered about is if there is a good way to make stuff like buffers or verbose configurable. Not having them is usually worse than having a bit of noise, but making it optional would be nice in some places.
Ambiguous terms: good, stuff, configurable, worse, bit of noise, nice
Questions:
1. What specifically is meant by "stuff" in this context?
2. Can you clarify what is meant by "verbose configurable"?
Clarified requirement: I am looking for a way to make buffers or verbose options configurable. It is preferable to have them available with some noise, but having the option to make them optional would be beneficial in certain situations.


Clarify this requirement: Greetings, is there a way to authenticate users by Open-Id Client? We have a Keycloak SSO server. Could it be through some plugin or community code to perform this authentication?
Ambiguous terms: way, authenticate, user, plugin, community code, perform
Questions:
1. What specific actions or processes are involved in authenticating users by Open-Id Client?
2. What is meant by "perform this authentication" in the context of using a plugin or community code?
Clarified requirement: Implement a method to authenticate users using Open-Id Client with a Keycloak SSO server, potentially through a plugin or community-developed code for the authentication process.


Clarify this requirement: When running omnidb in server mode, I would like to be logged out when I close my browser.  (For double bonus points, I would like to be able to configure my session to expire after X minutes of non-use, but that might be a bridge too far.)
Ambiguous terms: like, close, configure, expire, X minutes, non-use, bridge too far
Questions:
1. What does "close my browser" specifically mean in this context?
2. Can you clarify what "X minutes of non-use" refers to?
Clarified requirement: When running omnidb in server mode, the user should be automatically logged out when the browser is closed. Additionally, there should be an option to set a session timeout for a specified number of minutes of inactivity.


Clarify this requirement: Hi how do i get omnidb_plugin for PostgreSQL 11 or 12 on windows?
DLL seems to be missing from omnidb-plugin_2.17.0-windows-amd64.zip.

Thanks,
Ambiguous terms: missing
Questions:
1. What specific functionality or purpose does the omnidb_plugin serve for PostgreSQL 11 or 12 on Windows?
2. Are you looking for assistance in locating the missing DLL file within the omnidb-plugin_2.17.0-windows-amd64.zip?
Clarified requirement: "Seeking guidance on how to obtain the omnidb_plugin for PostgreSQL 11 or 12 on Windows, as the DLL appears to be absent from the omnidb-plugin_2.17.0-windows-amd64.zip file."


Clarify this requirement: hi，How to change sqlite to mysql ? 
because our project USES mysql to manage user rights and so on
Ambiguous terms: change, manage
Questions:
1. What specific aspect of the project involves changing from sqlite to mysql?
2. How are user rights currently being managed in the project?
Clarified requirement: The project needs to transition from using sqlite to mysql for managing user rights and other functionalities.


Clarify this requirement: Hi,
New user here, looking to replace client-side pgAdmin with a server-side solution. OmniDB looks perfect for the job - lightweight / pretty / intuitive :-)

Having had a play, there are two features I miss from pgAdmin3:

1. The option to include field headers when copying from the Data Table output (via both clipboard or csv export methods)
2. The expanded tree view being remembered from session to session.  This saves quite a few clicks upon startup.

Apologies if these features already exist and I have missed them.  I look forward to using the software in anger :-)

(using omnidb-server on CentOS7,  omnidb-app_2.17.0-centos-amd64.rpm)

Cheers,

Rob
Ambiguous terms: pretty, intuitive, lightweight, miss, remembered, quite a few, anger
Questions:
1. What specific features in pgAdmin3 are considered field headers when copying from the Data Table output?
2. Can you clarify what is meant by the expanded tree view being remembered from session to session?
Clarified requirement: Rob


Clarify this requirement: Build containers and UAT machines.
Ambiguous terms: Build, containers, UAT, machines
Questions:
1. What specific type of containers are being referred to?
2. What is the purpose of the UAT machines?
Clarified requirement: Create physical or virtual containers for software deployment and set up User Acceptance Testing (UAT) machines for testing purposes.


Clarify this requirement: Hi,

I'm running OmniDB 2.16.0 with 10.4.8-MariaDB-1:10.4.8+maria~bionic-log. I'm getting a 1064 error when using variables.

## To reproduce:

1. Open a new Query Tab
1. Enter the following query:

        SET @avalue="my value";
        SELECT @avalue;

1. Run the query

**Expected result:**
```
+----------+
| @avalue  |
+----------+
| my value |
+----------+
```

**Actual result:**

`(1064, "You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'SELECT @avalue' at line 2")`

_If I copy-paste the query into a **>\_ Console** tab and run it, the query produces the expected result._
Ambiguous terms: error, variables, query, syntax, expected, actual, result
Questions:
1. What specific variables are causing the 1064 error?
2. Can you provide more information on the syntax issue mentioned in the error message?
Clarified requirement: If I copy-paste the query into a **>_ Console** tab and run it, the query produces the expected result.


Clarify this requirement: please add quick searck in menu tree

Por favor agregar una busqueda rapida en el arbol de menu
![2ndquadrant2](https://user-images.githubusercontent.com/2963281/65079490-eac13b80-d964-11e9-906f-00defc33b38e.png)
Ambiguous terms: quick, fast
Questions:
1. What specific functionality should the "quick search" in the menu tree perform?
2. Should the quick search feature be available for all levels of the menu tree?
Clarified requirement: Add a search feature in the menu tree that allows users to quickly search for specific items within the menu structure.


Clarify this requirement: Data Actions -> Edit Data

It would be really nifty to be able to right click a row and do 'Clone Row' and have the new row go into the bottom of the grid into the normal spot of a new row so that you can edit it prior to doing a save.
Ambiguous terms: nifty, normal
Questions:
1. What is meant by "normal spot of a new row"?
2. Can you clarify what is expected to happen after the new row is edited?
Clarified requirement: It would be useful to have the ability to right-click a row, select 'Clone Row', and have the new row appear at the bottom of the grid as a new row for editing before saving.


Clarify this requirement: Something that would be great would be to be able to control the colors of individual elements (ie, build our own themes).

I'm a huge fan of dark mode, easier on the eyes, especially at night.

All the dark mode themes I've tried so far have an off-white color for the text, which is hard to read.  I would like to be able to set the query editor font color to be plain white, and adjust the other colors like keywords/comments and such.

Thanks!
Ambiguous terms: great, control, colors, individual, build, own, themes, dark mode, easier, night, off-white, plain white, adjust, keywords, comments
Questions:
1. What specific elements are you referring to when you mention "individual elements"?
2. Can you clarify what you mean by "adjust the other colors like keywords/comments and such"?
Clarified requirement: Enable the ability to customize the colors of specific elements, such as setting the query editor font color to white and modifying colors for keywords and comments in order to create custom themes, particularly focusing on a dark mode for improved readability at night.


Clarify this requirement: Another thing I miss from pgadmin3.

Click on a column and show the DDL to create that column
ALTER TABLE foo ADD COLUMN bar text DEFAULT 'abc123' NOT NULL;

Also, split the DDL into individual actions
ALTER TABLE foo ADD COLUMN bar text;
ALTER TABLE foo ALTER COLUMN bar SET DEFAULT 'abc123';
ALTER TABLE foo ALTER COLUMN bar SET NOT NULL;
Ambiguous terms: miss, show, split, individual
Questions:
1. What specific feature from pgadmin3 do you miss in this context?
2. Can you clarify what you mean by "splitting the DDL into individual actions"?
Clarified requirement: Implement a feature similar to pgadmin3 where users can click on a column to view the DDL required to create that column. Additionally, separate the DDL statement provided into distinct actions for adding a column, setting a default value, and setting the column as not null.


Clarify this requirement: - Do not merge inner tabs of similar outer tabs into a unique outer tab while reloading a previous session

- Callback for saving inner tab name on the fly instead of waiting for inner tab query execution

- Callback for saving new inner tab  at creation time instead of query execution
Ambiguous terms: unique, saving on the fly, query execution
Questions:
1. What is meant by "saving on the fly"?
2. Can you clarify what is meant by "query execution"?
Clarified requirement: - Provide a callback to save a new inner tab at the time of creation instead of waiting for a query to be executed.


Clarify this requirement: Hi, I'm using 2.15 and I like a lot the debugging option, but there is a little improvement could be done: If you repeatedly modify and debug a function, and this function have parameters you must to set those parameters on each debug. This is because every time you refresh the thebug window to update the code, the parameters values are gone.

I checked that this could be avoided if you set the function parameter to a default, but this only work if the function has a single parameter.

The solution could be to save the parameters to debug when you refresh the code to update it.
Let me know if this is clear enough and a lot of thanks to all people contributing to this great tool.

Oscar
Ambiguous terms: little, improvement, repeatedly, a lot, could be, avoided, single, could be, save, clear enough, great
Questions:
1. What specific improvements could be made to the debugging option?
2. Can you clarify how setting the function parameter to a default only works if the function has a single parameter?
Clarified requirement: Oscar using version 2.15 likes the debugging option but finds it cumbersome to repeatedly set parameters when debugging functions. Setting parameters to a default only works for functions with a single parameter. Oscar suggests saving the parameters for debugging when refreshing the code.


Clarify this requirement: It would be useful to have the possibiity to export the graph as image and as well as graph with possibility to modify the placement of nodes.
Ambiguous terms: useful, possibility, modify
Questions:
1. What specific format should the image be exported as?
2. Can you provide more details on how the placement of nodes can be modified?
Clarified requirement: It is requested to have the ability to export the graph as an image in a specified format, and also to export the graph with the capability to adjust the placement of nodes.


Clarify this requirement: Hi,

in my point of view, it could be a great enhancement to be able to import/create OmniDB connections from the .pgpass file. I think this could be done for other DB too.
Ambiguous terms: great, enhancement, could be, other
Questions:
1. What specific features or functionalities are considered enhancements in this context?
2. Which other databases are being referred to for the potential import/create feature?
Clarified requirement: "In my point of view, it would be beneficial to add the capability to import/create OmniDB connections from the .pgpass file. This feature should also be extended to support other types of databases."


Clarify this requirement: I often end up working with a whole bunch of queries in a tab, so my tab looks like this:

```
select * from foo;

select * from bar;
```

What would be really convenient is a command (with associated key combination) that would allow me to execute the query that my text cursor is currently in.

So if my cursor is anywhere in `select * from bar` and I hit the right key combo, Omnidb figures out where the statement blocks are, and only executes `select * from bar`, and ignores `select * from foo`

this is a feature that I've seen in other products, and I thought I would hate it, but it turns out to be super-convenient
Ambiguous terms: convenient, convenient, super-convenient
Questions:
1. What specific key combination should trigger the execution of the query?
2. How should Omnidb determine the boundaries of the statement blocks?
Clarified requirement: I need a feature in Omnidb that allows me to execute the query where my text cursor is located using a specified key combination. Omnidb should determine the statement boundaries to execute only the query under the cursor, ignoring other queries in the tab.


Clarify this requirement: Hello, we're currently testing and gettting ready for production with the software which we find it amazing so far.
The main problem is storing the passwords. 
We're running SQL servers (Mysql and postgresql).
For postgresql we're using .pgpass which is working good, but we must have the same thing for mysql aswell. I tried creating a .my.cnf file with the following info 

```
[client]
user = user
password = password
host = serveraddress
```
But it's not working as expected... Any other option for this? Thank you
Ambiguous terms: amazing, good, expected
Questions:
1. What specifically is not working as expected with the .my.cnf file?
2. What outcome are you hoping to achieve with storing passwords for MySQL?
Clarified requirement: We are testing and preparing for production with software that we find impressive. The issue lies in storing passwords for MySQL. We currently use .pgpass for PostgreSQL successfully and need a similar solution for MySQL. Creating a .my.cnf file with specified information did not yield the expected results. Is there an alternative option for securely storing MySQL passwords? Thank you.


Clarify this requirement: I use Edit Data pages a lot.
It would be very handy to be able to apply the changes without reaching for a mouse.

Thanks a lot in advance, and thanks for your work - OmniDB is just great!
Ambiguous terms: a lot, handy, apply, great
Questions:
1. What specific changes are being made on the Edit Data pages?
2. Can you clarify what you mean by "applying the changes without reaching for a mouse"?
Clarified requirement: I frequently use Edit Data pages to make changes. It would be convenient to have the ability to save the changes without using a mouse. Thank you in advance for your assistance, and I appreciate the quality of OmniDB.


Clarify this requirement: Feature request:

Select multiple rows, right click and copy selections as sql statement like insert/delete.

Once copied, the clipborad should have someting like

```sql
INSERT INTO MyTable(ID,Col1,Col2,Col3) VALUES (10,'hello world','some value','2010-10-20');
INSERT INTO MyTable(ID,Col1,Col2,Col3) VALUES (11,'hello world','some value','2010-10-20');
INSERT INTO MyTable(ID,Col1,Col2,Col3) VALUES (12,'hello world','some value','2010-10-20');
```

Sequel Pro can do this but it is a macOS only software.

![](https://www.endpoint.com/blog/2014/01/10/copy-data-between-mysql-databases-with/image-1.png)

Let me know if it is on the roadmap, Thanks :)
Ambiguous terms: multiple, right click, like, should, like, roadmap
Questions:
1. What specific actions should be included when selecting multiple rows and right-clicking to copy selections as an SQL statement?
2. Can you clarify what you mean by "like insert/delete" in the context of copying selections as an SQL statement?
Clarified requirement: Please confirm if this feature is planned for implementation. Thank you!


Clarify this requirement: Table has no primary key, existing rows will be read only.
![image](https://user-images.githubusercontent.com/25076827/54358737-07ba4080-469c-11e9-8c39-e93a14cab116.png)
Ambiguous terms: no, read only
Questions:
1. What is meant by "existing rows will be read only"?
2. Are there any specific constraints or limitations related to the lack of a primary key in the table?
Clarified requirement: The table does not have a primary key, and the existing rows can only be read but not modified.


Clarify this requirement: Hi OmniDB team,

in our web api, we're using Row Security Policies for different purposes. Right now, the console tab do the job (obviously :) ) but it would be cool if OmniDB could display these (on a per table basis) ion the tree view.

Don't know if it's a very asked feature (don't know any GUI PG tools displaying RLS) but I try asking :)
Ambiguous terms: cool, very asked
Questions:
1. What specific information should be displayed for Row Security Policies on a per table basis in the tree view?
2. Can you clarify what you mean by "very asked feature"?
Clarified requirement: In our web api, we're using Row Security Policies for different purposes. Right now, the console tab handles this job, but it would be beneficial if OmniDB could display specific information related to Row Security Policies on a per table basis in the tree view. I am unsure if this feature is commonly requested in GUI PG tools that display RLS, but I am inquiring about its implementation.


Clarify this requirement: Omni
![image](https://user-images.githubusercontent.com/1695852/53117769-a5957200-3519-11e9-89ef-30cc2436c067.png)

Pgadmin3 has a nice feature where you see the DDL for creating an individual column
![image](https://user-images.githubusercontent.com/1695852/53117907-f5743900-3519-11e9-90a0-7387f98a02b6.png)


Although pgadmin3 doesn't have a straight DDL for creating with defaults... this would also be nice.

IF you have a not null constraint on the column, you of course cannot create the column and then set it to not null, but it is convenient if you want to do a quick alter set not null if it's pertinent to the situation.


The ideal DDL to show would be a single create statement along with the individual features

ALTER TABLE live_dialer.campaigns ADD COLUMN numbers_remaining integer NOT NULL DEFAULT 0;

-- OR
ALTER TABLE live_dialer.campaigns ADD COLUMN numbers_remaining integer;
ALTER TABLE live_dialer.campaigns ALTER COLUMN numbers_remaining SET NOT NULL;
ALTER TABLE live_dialer.campaigns ALTER COLUMN numbers_remaining SET DEFAULT 0;
Ambiguous terms: nice, ideal, convenient
Questions:
1. What specific features are considered "nice" in the context of pgadmin3?
2. Can you clarify what is meant by "ideal" and "convenient" in the context of the DDL for creating columns in pgadmin3?
Clarified requirement: Omni Pgadmin3 should display a single DDL statement that includes the creation of a column with specific features, such as setting it to not null and assigning a default value. This should be done in a way that allows for quick alterations if necessary.


Clarify this requirement: Initial idea from @pasquall in issue #567 . For example if the selected node is a table `table2`:

- **Up**: Goes to the node above in the same level. For example, will select `table1`;
- **Down**: Goes to the node below in the same level. For example, will select `table3`;
- **Left**: Ascend a level in the treeview. In this case, will select node `Tables`;
- **Right**: Descend a level in the treeview. In this case, will expand the `table2` node and select `Columns`.
Ambiguous terms: same level, ascend, descend
Questions:
1. What does "same level" refer to in the context of the treeview?
2. Can you clarify what is meant by "ascend" and "descend" in the treeview hierarchy?
Clarified requirement: - **Right**: Moves down a level in the treeview hierarchy. In this case, will expand the `table2` node and select `Columns`.


Clarify this requirement: Please confirm when we can expect Oracle Dashboard for Oracle DB.

Thanks
SSubhan
Ambiguous terms: confirm, expect
Questions:
1. When do you need confirmation by?
2. What specific information are you looking for regarding the Oracle Dashboard for Oracle DB?
Clarified requirement: Please provide a timeline for when we can expect the Oracle Dashboard for Oracle DB.


Clarify this requirement: Hello,

Can you help me, please, with the following information:
For PostrgreSQL Debugger - when you will introduce functionality "Step Into"?

Thank you,

Daniel
Ambiguous terms: introduce, functionality, Step Into
Questions:
1. What do you mean by "introduce functionality" in the context of PostgreSQL Debugger?
2. Can you clarify what you mean by "Step Into" in relation to the PostgreSQL Debugger?
Clarified requirement: Daniel is asking for information about when the functionality "Step Into" will be implemented in the PostgreSQL Debugger.


Clarify this requirement: I'm trying to deploy this on a Heroku-like platform, but the fact that OmniDB is using sqlite databases under the hood makes for a less-than-ideal experience. In order to run in certain environments like Heroku, the app needs to be [stateless](https://12factor.net/processes) and store stateful information in a backing service. 

It looks like this shouldn't be too difficult to achieve since the interface for a different database could be swapped in for the default sqlite one being used currently. The place I know sqlite is being used is for the user database, but it looks like it could be used in a few other places as well.
Ambiguous terms: less-than-ideal, certain, stateless, stateful, different, few other
Questions:
1. What specific challenges does using sqlite databases pose for deploying on a Heroku-like platform?
2. Can you provide examples of the other places where sqlite is being used besides the user database?
Clarified requirement: The app needs to be modified to use a different database instead of sqlite, specifically for the user database, in order to deploy successfully on a Heroku-like platform and follow the principles of statelessness.


Clarify this requirement: It would be great to have a checkbox whether or not to automatically word-wrap the query editor
Ambiguous terms: great, checkbox, automatically, word-wrap
Questions:
1. What specific action does the checkbox control in relation to word-wrapping?
2. Can you clarify what you mean by "automatically" word-wrapping?
Clarified requirement: A checkbox should be added to the query editor to enable or disable automatic word-wrapping.


Clarify this requirement: Sometimes it's just really convenient to be able to see multiple things on the screen at once without flipping tabs.  Especially with multiple monitors or multiple virtual workspaces and all that.

I would love to see the ability to detach a tab into its own window.  (And then also be able to bring that tab back into the main window)  Or join that window with another detached window to make a two-tab window.
Ambiguous terms: convenient, multiple, love, ability, own, main, join, two-tab
Questions:
1. What is meant by "detach a tab into its own window"?
2. Can you clarify what is meant by "join that window with another detached window to make a two-tab window"?
Clarified requirement: Allow users to separate a tab from the main window into a new window, and provide the option to reattach the tab back to the main window. Additionally, enable the merging of two detached windows to create a window with two tabs.


Clarify this requirement: Feature Request

The new group feature is a great start, but it seems that when we select a group, it just moves the checkboxes.  But I would figure for a full-featured group manager, it would filter and only show the servers in the group.

I like the fact that servers can be in multiple groups, so this interface design is nice.  What we need I believe is an 'Group Edit Mode', where you can check or uncheck from the entire list of servers.  And then once you're out of 'Group Edit Mode', then it'll only show the grouped-servers in that group!
Ambiguous terms: great, full-featured, nice, believe
Questions:
1. What specific actions should be available in the "Group Edit Mode"?
2. How should the interface differentiate between servers that are in multiple groups?
Clarified requirement: Feature Request: Enhance the group feature by adding a "Group Edit Mode" where users can check or uncheck servers from a list, and once out of this mode, only servers belonging to the selected group are displayed. Servers can be in multiple groups.


Clarify this requirement: Add in the navigator inside the schema, an item to list all the aggregate created in this schema.
Ambiguous terms: Add, navigator, item, aggregate, created
Questions:
1. What specific type of navigator are we referring to in this context?
2. Can you clarify what is meant by "aggregate" in this schema?
Clarified requirement: Include a navigation element within the schema that lists all the aggregates that have been created within that schema.


Clarify this requirement: Unless I'm missing something, snippets are difficult for me to use because I must go find the desired snippet from the snippet tab, then copy it to the clipboard, and then go back to the query window and paste it.   It would be much better if I could use the autocomplete feature to match based on the snippet name and it would expand to the contents of that snippet in the query window.

Is there a currently better way to do this other than copy/paste? If not, I'd like to request this feature.

Thanks.
Ambiguous terms: difficult, better, much better, currently better
Questions:
1. What specifically makes using snippets difficult in the current process?
2. What do you mean by "currently better way" in this context?
Clarified requirement: The user finds it challenging to use snippets because they have to manually locate, copy, and paste them. They are requesting a feature where they can use autocomplete to match snippet names and have them expand directly in the query window, instead of the current manual process. They are also inquiring if there is an alternative method to copy/paste snippets efficiently.


Clarify this requirement: Hi there, loving OmniDB so far!

The default behaviour when submitting a SELECT query (in a Query Tab) seems to be to return at most 50 rows, at which point "Fetch more" and "Fetch all" buttons pop up (and work as advertised).

I think the limit of 50 should be both configurable and removable. In my workflow I am rarely interested in a subset of query results.

Thanks!
Ambiguous terms: configurable, removable, subset
Questions:
1. What does "configurable" mean in this context?
2. How would you define "subset" of query results?
Clarified requirement: The default behavior in OmniDB when submitting a SELECT query is to return a maximum of 50 rows, with the option to fetch more or all results. The requester suggests that the limit of 50 rows should be adjustable and able to be removed, as they are typically interested in viewing all query results in their workflow.


Clarify this requirement: I am interested in finding/contributing to efforts to create an open source data analysis platform, similar to what Tableau offers. I have found a couple of solid contenders, such as [Apache Superset](https://superset.incubator.apache.org/). OmniDB also seems compelling, being built with Python/Django. I notice there is already some OmniDB code related to data mining (in dataMining.js). 

What are your thoughts on OmniDB serving as a basis for some data analysis extensions, such as visualizing the output of queries in a simple and intuitive manner?
Ambiguous terms: simple, intuitive
Questions:
1. What specific criteria define "simple" in the context of visualizing query outputs?
2. How would you define "intuitive" when it comes to data analysis extensions?
Clarified requirement: I am exploring the potential of using OmniDB as a foundation for developing data analysis extensions. This involves visualizing query outputs in a manner that is straightforward and easy to understand.


Clarify this requirement: Hi,
Some feature requests here, as we are in the process of comparing temboard, pgadmin4 and omnidb.

What we really appreciate with temboard is its ability to automatically register new installed databases. For example, we have to deploy tons of new PostgreSQL servers/instances/databases. This is automated with ansible. One step in the automated process is to install the temboard agent in a newly installed PostgreSQL server. Then this agent automatically contact the temboard server to register all PostgreSQL instances and databases found on the newly installed PostgreSQL server.

What we also really like with temboard is that temboard users don't have to recreate connections to the PostgreSQL servers they have to manage: it's done once for all users.
So to reproduce this in omnidb seem currently not possible.
One suggestion could be to implement groups in omnidb. Then associate users and PostgreSQL connections to groups: by the way, all users in a group could automatically get access to all PostgreSQL connections assigned to that group.
This last feature request would be particularly important and urgent to continue considering omnidb for an enterprise usage, when you have teams of several tens of DBAs.
Ambiguous terms: automatically, tons of, user-friendly, really appreciate, like, currently, possible, one suggestion, could be, particulary important, urgent, several tens of
Questions:
1. Can you clarify what you mean by "recreate connections to the PostgreSQL servers" in temboard?
2. What specific functionality in omnidb is currently preventing the reproduction of the feature you like in temboard?
Clarified requirement: In the comparison of temboard, pgadmin4, and omnidb, the team appreciates temboard's ability to automatically register new installed databases and the seamless connection management for users. They are looking for omnidb to implement a similar feature where users do not have to recreate connections to PostgreSQL servers and databases. The suggestion is to introduce groups in omnidb, allowing users in a group to automatically access PostgreSQL connections assigned to that group. This feature is crucial for enterprise usage with multiple DBAs.


Clarify this requirement: I love OmniDB and think the user experience could be improved with some UI changes. With an application like this that I easily spend several hours a day using, even the most minor changes can significantly improve how pleasant it is to work with the application and make it the most usable solution of any DB GUI.

- Auto fit the width of columns in the `Data` view of query output. Only if the column is very wide (for example a huge JSON column) should it be cut off.
  - For the columns that are cut off, double clicking the column width expander should auto fit that column
- Auto fit the width of the navigator window on the left and always keep it auto fit. So if you collapse some nodes causing it to need less width then it shrinks, and same when expanding some nodes it should expand to the width it needs
- The table details window on the bottom left of the screen should be able to be closed in settings. For the kind of information I need when I'm in the GUI it isn't something I ever look at so it takes up useful screen real estate from the navigator window
- Closing a tab shouldn't require a confirmation, at least this should be configurable in settings. We are used to closing tabs without confirmation in browsers, text editors, IDEs, and this should be no different. The only case is if you have unsaved changes then it should prompt if we'd like to save changes
- A less intrusive close icon should be used, for example the way browsers do it where the close icon appears only when you mouse over the tab. Because right now I have many distracting bright red "X" icons all over the screen
- Be able to customize the font used in the application. I have some nice system fonts that I use in my IDE and other applications and it would be good to be able to use the same one in this application, which is also nice when all applications I use have a consistent font
- Don't make all text in the navigator on the left in a bold font, because when everything is bold then nothing stands out in the navigator window and it's harder on the eyes
Ambiguous terms: improved, pleasant, usable, minor, most, less intrusive, nice, consistent, harder
Questions:
1. What specific UI changes are being suggested for the OmniDB application?
2. Can you provide examples of the kind of information displayed in the table details window that is not needed?
Clarified requirement: - Avoid using bold font for all text in the left navigator window to improve visibility."


Clarify this requirement: Pgadmin3 has this nice feature so you can easily find for example a function name just by type the first char of it but in OmniDB if i have a lot of functions inside my database schema i have to scroll down by myself to get to the one that i am searching for!
Ambiguous terms: nice, easily, a lot, scroll down by myself, searching for
Questions:
1. What specific feature in Pgadmin3 allows users to find a function name by typing the first character?
2. Can you clarify what you mean by "scroll down by myself" in OmniDB?
Clarified requirement: In OmniDB, users are unable to easily find a function name by typing the first character like in Pgadmin3, which causes difficulty when searching for a specific function among a large number of functions in the database schema.


Clarify this requirement: Selecting a theme is a great feature, but some of the default theme colors are not ideal.  For example in the dark themes, error messages are red on gray and are very difficult to read, especially at the default (small) font size.

It would be great to be able to customize individual component font colors that are part of a theme.
Ambiguous terms: great, ideal, difficult, customizable, individual
Questions:
1. What specific default theme colors are considered not ideal?
2. Can you provide examples of the individual component font colors that users should be able to customize?
Clarified requirement: The feature should allow users to customize specific default theme colors that are difficult to read, such as red error messages on gray backgrounds in dark themes, and also customize individual component font colors within a theme.


Clarify this requirement: It would be great if OmniDB could support the following use case:
When viewing some rows in a query result, I would like to navigate to connected tables by (right)-clicking on a data-entry in foreign-key columns. The matched row is then opened in a new query-tab.

I have seen the behavior in Adminer and think it would be very helpful in OmniDB as well.
Ambiguous terms: great, some, navigate, connected, foreign-key, helpful
Questions:
1. What specific actions should be taken when navigating to connected tables by clicking on a data-entry in foreign-key columns?
2. Can you provide more details on how the behavior in Adminer works for navigating to connected tables?
Clarified requirement: OmniDB should allow users to navigate to connected tables by clicking on a data-entry in foreign-key columns. When this action is taken, the matched row should be opened in a new query-tab, similar to the behavior in Adminer.


Clarify this requirement: Pgadmin3 has this nice feature so you can easily alter things like triggers, sequences (just about everything), by copy/paste and some quick edits by prefixing all the DDL with the associated DROP.

![image](https://user-images.githubusercontent.com/1695852/46637243-423a1300-cb29-11e8-9feb-fd3a04a3704e.png)
Ambiguous terms: nice, easily, quick
Questions:
1. What specific features does Pgadmin3 have for altering triggers and sequences?
2. Can you clarify what is meant by "prefixing all the DDL with the associated DROP"?
Clarified requirement: Pgadmin3 allows users to alter triggers, sequences, and other elements by copy/pasting DDL and making quick edits, such as adding the associated DROP statement as a prefix.


Clarify this requirement: Hi
Our users would like to have the possibility to do mass imports from a csv file. There is a closed issue #31 , but for some reason I can't find this functionality in latest OmniDB Server or anywhere in documentation. Does this functionality exist, is it planned or for now we would need to write our own plugin, if we want to get imports from csv?

Regards,
Ambiguous terms: mass imports, possibility, functionality, planned
Questions:
1. What specific actions or operations should be included in the "mass imports" from a csv file?
2. When referring to the functionality that cannot be found, what specific features or capabilities are expected in this context?
Clarified requirement: Our users are requesting the ability to perform bulk data imports from a csv file in the latest OmniDB Server. Despite not finding this feature in the current version or documentation, we need to determine if it exists, if it is planned for a future release, or if we should develop a custom plugin for csv imports.


Clarify this requirement: If one names query tabs the names are lost on relogin, while the to the content of the tab is kept. Would it be possible to make the query tab names persistent in a similar manner?

Regards
pgaro
Ambiguous terms: persistent, similar
Questions:
1. What is meant by "persistent" in this context?
2. How should the query tab names be made persistent in a similar manner?
Clarified requirement: If one names query tabs, the names are lost on relogin, while the content of the tab is kept. The request is to make the query tab names remain saved even after relogin in a similar way to how the content is retained.


Clarify this requirement: For reference: https://developer.apple.com/documentation/xcode/notarizing_macos_software_before_distribution
Ambiguous terms: reference, notarizing, software, distribution
Questions:
1. What specifically is meant by "reference" in this context?
2. Can you clarify what is involved in the process of "notarizing" software before distribution?
Clarified requirement: The requirement is to follow the guidelines outlined at https://developer.apple.com/documentation/xcode/notarizing_macos_software_before_distribution for the notarization of macOS software before distribution.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

When used on mobile devices, the current button sizes and their gaps are too small and the user easily fails to tap the target button.

### Button size
The current buttons are basically 20x20, while some guidelines suggest bigger buttons such as 
> As a general rule, a button needs a hit region of at least 44x44 pt — in visionOS, 60x60 pt — to ensure that people can select it easily, whether they use a fingertip, a pointer, their eyes, or a remote.
> https://developer.apple.com/design/human-interface-guidelines/buttons

![Image](https://github.com/user-attachments/assets/1bc7e867-d2d9-4fa5-993d-43aeedf5d150)

### Gaps

For example, the camera control in `gr.Image()` has two buttons to take a photo and to select the device.
They are too close to tap the right one on mobile.

![Image](https://github.com/user-attachments/assets/faccf10d-f4b1-4155-bb4a-58a0d062261a)

Additional context: [internal link](https://huggingface.slack.com/archives/C03K5G9UM8V/p1746449108624729)
Ambiguous terms: small, easily, bigger, close
Questions:
1. What specific actions are considered "too small" for the current button sizes?
2. How close is considered "too close" for the buttons in the camera control?
Clarified requirement: For example, the camera control in `gr.Image()` has buttons that are too close together for easy tapping on mobile devices.


Clarify this requirement: Some Gradio apps (e.g. those ones that generate videos or 3d objects) can take minutes to run. In this case, it would be great if there was a way for users to save the results of their generations so that they don't worry about losing it e.g. if they leave the page or generate something else.

Some ideas:
* Let users click on the download button before the generation is complete to auto-download it
* Allow users to get the deep-link to their Space before the generation is complete
* Save runs of a Gradio app (basically just their corresponding deep links) in the settings so users can see the history of their previous generations.
Ambiguous terms: great, user-friendly, auto-download, deep-link, history
Questions:
1. What is meant by "deep-link" in this context?
2. Can you clarify what is meant by "history of their previous generations"?
Clarified requirement: Some Gradio apps, especially those that generate videos or 3D objects, may take minutes to run. In such cases, users should have the ability to save the results of their generations to prevent loss, even if they navigate away from the page or generate something else. This can be achieved by allowing users to click on a download button before the generation is complete for auto-downloading, providing them with a deep-link to their Space before completion, and saving runs of a Gradio app (essentially their corresponding deep links) in the settings for users to view their history of previous generations.


Clarify this requirement: It would be informative to users to know whether there is a long queue for a Space (or their estimated ETA) before they even run the function. Particularly for non-Zero GPU Spaces.
Ambiguous terms: informative, long, estimated, non-Zero
Questions:
1. What is considered a "long queue" for a Space?
2. What is meant by "non-Zero GPU Spaces"?
Clarified requirement: Users should be informed of the queue length or estimated ETA for a Space before running the function, especially for GPU Spaces that are not empty.


Clarify this requirement: Some ideas:

* Provide users info on how many recent invocations of that event resulted in an error so that they have some idea of whether the error is "their fault" or whether the app is broken
* Strategically provide some information from the logs, i.e. some more details than just error. We should be careful not to expose any sensitive information so this needs to be thought through 
* On Spaces, be able to "report" an error --> clicking on this should open up a Discussions issue with the user's input (i.e. a deep link)
Ambiguous terms: careful, some, strategically, more details, sensitive, thought through, report, deep link
Questions:
1. What specific information should be provided to users regarding the recent invocations of the event?
2. How should the system determine whether an error is "their fault" or if the app is broken?
Clarified requirement: Provide users with information on the number of recent invocations of the event that resulted in an error to help them determine if the error is due to their actions or if the app is malfunctioning. Additionally, display non-sensitive details from the logs to give users more context without exposing any confidential information. Allow users to report an error on Spaces by clicking a button that opens a Discussions issue with their input, creating a deep link.


Clarify this requirement: For functions with many inputs, many of them minor parameters, it can clutter the UI to have a large dataset with many columns. Users should be able to hide certain columns in `gr.Examples`. Also, by default, `additional_inputs` in `gr.Interface` should correspond to hidden columns
Ambiguous terms: many, minor, large, certain, default
Questions:
1. What determines if a parameter is considered minor?
2. Can you clarify what you mean by "correspond to hidden columns" in `gr.Interface`?
Clarified requirement: For functions with numerous inputs, including some parameters that are considered less important, the UI may become cluttered with a dataset containing numerous columns. Users should have the ability to hide specific columns in `gr.Examples`. Additionally, the `additional_inputs` in `gr.Interface` should by default align with the hidden columns.


Clarify this requirement: Often users provide instructions / README-type content into a Gradio app by dumping the content into a `gr.Markdown()`, which looks quite bad from a UI perspective. An improvement would be to use the `gr.Sidebar` component so at least the text can be hidden by closing the sidebar. But can we provide an even nicer way for users to link an associated readme?
Ambiguous terms: nicer
Questions:
1. What specific aspects of the current method are considered not nice from a UI perspective?
2. Can you provide examples of what would be considered a nicer way for users to link an associated readme?
Clarified requirement: Often users provide instructions/README-type content into a Gradio app by dumping the content into a `gr.Markdown()`, which looks quite bad from a UI perspective. An improvement would be to use the `gr.Sidebar` component so at least the text can be hidden by closing the sidebar. But can we provide a more aesthetically pleasing and user-friendly way for users to link an associated readme?


Clarify this requirement: For complex Gradio applications, it would be useful to support guided walkthroughs or onboarding flows. This feature would allow developers to sequentially highlight specific components or interface sections while dimming the rest of the UI, and display tooltip descriptions or instructions.

Here's what the Python syntax could look like: 

```py
import gradio as gr

with gr.Blocks() as demo:
    
    with demo.walkthrough(step=0, description="First put in your name and age"):
            with gr.Row():
                name = gr.Textbox(label="Name")
                age = gr.Number(label="Age")
    
    with demo.walkthrough(step=1, description="Then click the button")
          greet_btn = gr.Button("Submit")

    output = gr.Textbox(label="Greeting")
```

The walkthrough should only appear when a user first visits the Gradio app from a device (although they should be able to retrigger it from the settings menu if they want).
Ambiguous terms: complex, useful, guided, walkthroughs, onboarding, flows, highlight, specific, components, interface, sections, tooltip, descriptions, instructions, sequential, rest of the UI, first visits, retrigger, settings menu
Questions:
1. What specific actions or interactions trigger the guided walkthrough or onboarding flow in the Gradio application?
2. How does the user access the settings menu to retrigger the walkthrough?
Clarified requirement: For complex Gradio applications, developers should be able to implement a feature that provides guided walkthroughs or onboarding flows to users. This feature should allow developers to sequentially highlight specific components or interface sections while dimming the rest of the UI, and display tooltip descriptions or instructions. The walkthrough should only be triggered when a user first visits the Gradio app from a device, but users should also have the option to retrigger it from the settings menu.


Clarify this requirement: As a small QoL improvement, we should preload the input and output if a user has enabled cached examples so that they load when the page first loads. For example, we could add a `preload: bool | int` parameter to `gr.Examples`, which is `True` by default, which loads the first cached example (or a user can provide an integer index if they want to load a particular example).
Ambiguous terms: small, improvement, preload, cached, first, particular
Questions:
1. What does "QoL" stand for?
2. Can you clarify what is meant by "cached examples"?
Clarified requirement: Implement a feature where, if a user has enabled cached examples, the input and output should be preloaded when the page first loads. This can be achieved by adding a `preload: bool | int` parameter to `gr.Examples`, which defaults to `True` and loads the first cached example unless a specific integer index is provided by the user.


Clarify this requirement: Users will likely want to create private Spaces to use as MCP tools. We should allow users to pass in their HF_TOKEN in the header to access their private Spaces. 

Note: this will likely require https://github.com/modelcontextprotocol/python-sdk/pull/380 to be merged in.
Ambiguous terms: likely, private, allow, access, require
Questions:
1. What is meant by "private Spaces"?
2. What specific actions should users be able to perform with their HF_TOKEN in the header?
Clarified requirement: Users should be able to create restricted access Spaces for personal use and utilize their HF_TOKEN in the header to perform authorized actions within these Spaces.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
When adding historical chat interactions to `Chatbot`, the launched session starts at the top. Ideally it should start with the last provided message. I wasn't able to figure out the correct Javascript to implement this behavior.

Using 
```
gradio             5.27.1
gradio-client      1.9.1
```

Example I'm working with

```python
    history = load_history()

    bot = gr.Chatbot(value=history, type="messages")

    with gr.Blocks(theme=gr.themes.Base()) as demo:
        gr.ChatInterface(
            fn=process_prompt,
            type="messages",
            chatbot=bot,
        )

        demo.launch()
```

**Describe the solution you'd like**  
The `autoscroll` function should account for initial values
Ambiguous terms: ideally, correct, figure out, correct
Questions:
1. What does "launched session starts at the top" mean in the context of adding historical chat interactions to `Chatbot`?
2. Can you clarify what you mean by "autoscroll function should account for initial values"?
Clarified requirement: The `autoscroll` function should handle initial values.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

It would be great if `gr.Dataframe` had a way to hide certain columns from the UI while keeping them in the data when it's passed to functions. For example, columns like id might be used in the function, but they are not useful for end users.
Ambiguous terms: great, certain, useful
Questions:
1. What do you mean by "certain columns"?
2. How do you define columns that are "not useful for end users"?
Clarified requirement: It would be helpful if `gr.Dataframe` had a feature to hide specific columns from the UI while retaining them in the data for function usage. For instance, columns like id may be necessary for functions but unnecessary for end users.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

I want to use `gr.ImageEditor` to draw a binary mask on a given image. Currently, you can set the pen opacity, but when you draw over the same spot multiple times, the strokes accumulate and make it look darker. But this behavior is a bit confusing for this use case. Also, it makes it harder to check if there's no missing spot.


https://github.com/user-attachments/assets/846b9dfb-a213-4a69-97ad-e4c6328c1f76


For example, it would be useful if users could:
- Select a brush color that contrasts well with the background object.
- Draw a mask over the target object using a semi-transparent brush.
- Afterwards, change the opacity (or even the color) of the overlay to verify that the entire object has been properly covered.
- Regardless of the color or transparency settings chosen by the user, the final output would still be a clean binary mask.
Ambiguous terms: confusing, harder, useful, well, semi-transparent, properly, clean
Questions:
1. What specific aspect of the current behavior with the pen opacity is confusing for this use case?
2. Can you clarify what you mean by a "clean binary mask"?
Clarified requirement: I want to use `gr.ImageEditor` to draw a binary mask on a given image. Currently, when drawing with the pen opacity, multiple strokes over the same spot accumulate and darken the image, which is confusing for this use case. The goal is to allow users to select a brush color that contrasts with the background, draw a semi-transparent mask over the target object, and then adjust the overlay's opacity or color to ensure complete coverage of the object. The final output should always be a binary mask, regardless of the user's chosen settings.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


Currently, it's possible to name layers using the `layers` parameter in `gr.LayerOptions`, but users still can change the layer order.
Layers are passed to a function as a list, so the layer order shouldn't be changed when layers are named.

Or, returning layers as a `dict` where the keys are the layer names, instead of a list might be better. I think this would be easier for developers as they wouldn't have to worry about which list index corresponds to which layer.

https://github.com/user-attachments/assets/50b074e4-d22f-4302-9ca8-22fe8e9b8b35

```py
import gradio as gr


def fn(editor):
    return editor["layers"]


with gr.Blocks() as demo:
    editor = gr.ImageEditor(
        label="Mask",
        type="numpy",
        sources=("upload",),
        transforms=(),
        image_mode="L",
        height=500,
        brush=gr.Brush(default_color=("#00ff00", 0.6)),
        layers=gr.LayerOptions(allow_additional_layers=False, layers=["Foreground mask", "Unknown mask"]),
    )
    out = gr.Gallery()
    editor.change(fn=fn, inputs=editor, outputs=out)
demo.launch()
```
Ambiguous terms: better, easier
Questions:
1. What specific issues are users facing with the current layer naming and order functionality?
2. Can you provide more details on how returning layers as a `dict` with layer names as keys would address the current challenges?
Clarified requirement: - Currently, users can name layers using the `layers` parameter in `gr.LayerOptions`, but they can still change the layer order. Layers are passed to a function as a list, so the layer order shouldn't be changed when layers are named. Considering returning layers as a `dict` where the keys are the layer names, instead of a list, might provide a solution. This change aims to simplify the development process by removing the need to track list indices corresponding to specific layers.


Clarify this requirement: ### Describe the bug

I can't get the Chatbot to display the content of a Dataframe in a ChatMessage. 
Am I trying to do something unsupported or is this a bug? 

![Image](https://github.com/user-attachments/assets/c306cf0a-cc2b-4a5c-9f08-bf8efc0f64fd)

To be noted there is an error in the Table.js code.
![Image](https://github.com/user-attachments/assets/568f5927-ab9d-4aca-b8be-9a590b4eeefc)



### Have you searched existing issues?  🔎

- [x] I have searched and found no existing issues

### Reproduction

```python
import gradio as gr
import pandas as pd

df = pd.DataFrame({
    "date": pd.date_range(start="2020-01-01", periods=100, freq="ME"),
    "value": range(100)
})

history = [
    {"role": "user", "content": "Can you show me the table?"},
    {"role": "assistant", "content": gr.DataFrame(value=df, type="pandas", visible=True, label="Cool Data")},
]

with gr.Blocks() as demo:
    gr.Chatbot(history, type="messages")

demo.launch()
```



### Screenshot

_No response_

### Logs

```shell

```

### System Info

```shell
gradio 5.23.2
python 3.11
Chrome 134.0.6998.167
```

### Severity

Blocking usage of gradio
Ambiguous terms: unsupported, bug, error, issue, response
Questions:
1. What specific behavior are you expecting from the Chatbot when trying to display the content of a Dataframe in a ChatMessage?
2. Can you clarify the role of Table.js in this context and how it relates to the issue?
Clarified requirement: Describe the issue where the Chatbot is unable to display the content of a Dataframe in a ChatMessage, potentially due to unsupported functionality, a bug, or an error in the Table.js code.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

Currently, when a dataframe contains `null` value, it's displayed as the string `null`, but users might want to customize how they are shown. For example, I would prefer to replace them with empty strings so that the cells appear empty.
(Converting the datatype to `str` doesn't solve this because it changes sorting behavior as well.)

Also, it seems that `null` is treated as `0` when sorting, but this behavior is unexpected, especially when there are negative numbers in the table.
I think `null` should be excluded from sorting and always put at the bottom of the table for both ascending and descending sort.

https://github.com/user-attachments/assets/fda4eb42-3f05-49f7-a1ef-d0d6fdbb3a7d
Ambiguous terms: customize, prefer, empty, unexpected, ascending, descending
Questions:
1. What specific customization options do users want for displaying `null` values in the dataframe?
2. Can you clarify what is meant by `null` being treated as `0` when sorting?
Clarified requirement: Additionally, the current behavior where `null` is treated as `0` during sorting is causing unexpected results, especially when negative numbers are present in the table. To address this, it is suggested that `null` values should be excluded from sorting and always placed at the bottom of the table for both ascending and descending sort orders.


Clarify this requirement: `sklearn` and its relatives like `scikit-image` are still widely used -- it would be an easy lift if users could easily create Gradio apps from certain kinds of `sklearn` models. (i.e. it would probably be more useful for the non-numerical models), thanks @davidberenstein1957 for the suggestion
Ambiguous terms: widely used, easily, certain kinds, more useful, non-numerical
Questions:
1. What specific types of `sklearn` models are considered non-numerical?
2. How would the ease of creating Gradio apps be defined in this context?
Clarified requirement: "`sklearn` and its relatives like `scikit-image` are still commonly utilized. It would be beneficial if users could effortlessly develop Gradio apps from select non-numerical `sklearn` models."


Clarify this requirement: Suggested by @davidberenstein1957 for developers who may have created an endpoint that deploys a model which is super cool but very scary and inapproachable through CURL/Python/TS, so would benefit from a UI overlay
Ambiguous terms: super cool, scary, inapproachable, UI overlay
Questions:
1. What makes the model "super cool" and "scary"?
2. What is meant by "inapproachable" in this context?
Clarified requirement: Suggested by @davidberenstein1957 for developers who may have created an endpoint that deploys a model with advanced features, but is intimidating to interact with using CURL/Python/TS, and would benefit from a user interface overlay.


Clarify this requirement: Lets say I have LoRAs in gr.Dropdown 

When I type LoRA name into gr.Textbox if matches it can auto complete?

Or it can scan files in set folder and auto complete name if matching?

That would be super amazing cool feature for Gradio

e.g.

this is dynamic LoRA format `<lora:lora_name.safetensors,1.0>`

When user types `<lora:my_lor` it will auto complete either from set folder or lets say from gr.Dropdown
Ambiguous terms: auto complete, matching, super amazing cool feature
Questions:
1. Can you clarify what you mean by "auto complete" in this context?
2. Are you expecting the auto complete feature to work based on user input matching existing LoRA names or files in a set folder?
Clarified requirement: Lets say I have LoRAs in gr.Dropdown. When I type a LoRA name into gr.Textbox, if it matches an existing LoRA name or file in a set folder, the system should provide auto complete suggestions. This feature would enhance the user experience in Gradio. For example, when the user types "<lora:my_lor", the system should auto complete from either the set folder or the gr.Dropdown.


Clarify this requirement: I've noticed that when the autoscroll parameter is set to True, the chat window automatically scrolls to the bottom. However, if I manually scroll up within the conversation (i.e., not at the very bottom), and then switch away from the chat and return, it doesn't automatically scroll back to the bottom. At the same time, I observed that a new button appears, with the class name "Scroll-down-button-contanier". Clicking this button immediately scrolls to the bottom, which is excellent.

However, the trigger condition for this button seems too limited. It only appears in the specific scenario I described above. I believe the logic for displaying this button should be more granular and precise. For example, the button should appear whenever the user scrolls upward, or more generally, whenever the chat window is not already at the very bottom. This would make it consistently available when needed.

![Image](https://github.com/user-attachments/assets/ff873159-4a1f-468f-868a-cb9a5ffa727f)
Ambiguous terms: granular, precise, more generally, consistently
Questions:
1. What specific conditions trigger the appearance of the "Scroll-down-button-container"?
2. Can you provide more details on what you mean by making the logic for displaying the button more granular and precise?
Clarified requirement: The chat window should display the "Scroll-down-button-container" whenever the user scrolls upward or whenever the chat window is not at the very bottom, instead of only appearing in the scenario described.


Clarify this requirement: From @hysts:

Currently, new messages contain text and files keys, but history is a list of dict with role and content. Also, in message, files is a list of paths, but in history, text and files are split into separate elements.
For example, when passing multiple images to this app,

```py
import gradio as gr


def fn(message, history):
    print(message)
    print(history)
    print()
    return "aaa"


gr.ChatInterface(fn=fn, type="messages", multimodal=True, textbox=gr.MultimodalTextbox(file_count="multiple")).launch()
the message and history look like this:
{'text': 'How many cats and dogs are in these images?', 'files': ['/tmp/gradio/0c94d52abfb8bc764345734c8d469f53c0789919f4d5b3e315c43276503005f1/cats.jpg', '/tmp/gradio/3327296d9d700130facb51479a116014060b62e97ab8a47db0ce1b4a93a60037/dogs.jpg']}
[]

{'text': 'x', 'files': []}
[{'role': 'user', 'metadata': None, 'content': ('/tmp/gradio/0c94d52abfb8bc764345734c8d469f53c0789919f4d5b3e315c43276503005f1/cats.jpg',), 'options': None}, {'role': 'user', 'metadata': None, 'content': ('/tmp/gradio/3327296d9d700130facb51479a116014060b62e97ab8a47db0ce1b4a93a60037/dogs.jpg',), 'options': None}, {'role': 'user', 'metadata': None, 'content': 'How many cats and dogs are in these images?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'aaa', 'options': None}]
Due to this inconsistency, you need to write two separate functions to process a new message and history.
Also, in OpenAI API or Claude API, (though the formats are slightly different), user messages and assistant messages are alternating, and when a user passed multiple images with text, they are included in the content list, like this:
messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": to_base64(image1),
                },
            },
            {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": to_base64(image2),
                },
            },
            {
                "type": "text",
                "text": "How many cats and dogs are in these images?",
            },
        ],
    }
]
```

But as the text and images are split into separate elements in the history of gr.ChatInterface, if you want to create a chat interface for these kind of APIs, you need to reorganize the flatten history into an alternating one. It's easy to flatten a nested list, but reorganizing a flatten list to a nested list is a bit cumbersome.
Recently, I made a [Space](https://huggingface.co/spaces/huggingface-projects/gemma-3-12b-it) for Gemma 3, and messages and history are processed like [this](https://huggingface.co/spaces/huggingface-projects/gemma-3-12b-it/blob/8378e4a9922c1ae97ec00e72a43a09d18b0d0419/app.py#L130-L161), but I feel that it's kind of unnecessarily complex and confusing. Also, I find it unintuitive to check if an element in the history is text or a file by checking if it's an instance of str or tuple.
Ambiguous terms: list, dict, role, content, files, elements, flatten, nested, alternating, flattening, nested list
Questions:
1. What exactly is meant by "flatten history into an alternating one"?
2. How does the current structure of messages and history in the ChatInterface differ from the desired structure?
Clarified requirement: The requirement is to reorganize the history structure in the ChatInterface from a flattened list to an alternating nested list to align with the format used in APIs like OpenAI or Claude API. This involves ensuring that text and images are grouped together in alternating user and assistant messages.


Clarify this requirement: Gradio is an excellent and convenient project for deploying model frontends. I really like it and have been using it for a long time. However, there is one issue that has troubled me for a while. I want to make this project look better, but finding the style names of each component to modify many parameters is extremely difficult and troublesome. Additionally, there are many inline styles for which I can't even find the style names (although this might be due to my oversight). Therefore, I sincerely hope that in the documentation for each component, at the bottom or somewhere, the CSS section for that component could be provided. Even just a small portion would be very helpful. Thank you very much.
Ambiguous terms: excellent, convenient, better, troubled, difficult, troublesome, many, inline, small, helpful
Questions:
1. What specific parameters or aspects of the project's style are difficult to modify due to the lack of CSS information?
2. Can you provide an example of an inline style that you are unable to modify because you can't find the corresponding style name?
Clarified requirement: Provide CSS information at the bottom or in the documentation for each component in the Gradio project to make it easier for users to modify specific style parameters and inline styles.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
With the development of new TTS models like Zonos from Zyphra I can see a future where locally hosting speech conversion is practical for people. Being able to click a speaker icon on a chatobject/message would be great. 

![Image](https://github.com/user-attachments/assets/0c93131d-3c42-48db-aaea-a380cdb76afe)

**Describe the solution you'd like**  
I would like a speaker icon next to the copy button. Either having a path the the audio file in the metadata or having it be its own field. Clicking this button would play the referenced audio file. 

**Additional context**  
Shoutout to Zonos https://github.com/Zyphra/Zonos
Ambiguous terms: practical, great
Questions:
1. What does "locally hosting speech conversion" entail?
2. Can you clarify the functionality of the speaker icon in relation to the audio file?
Clarified requirement: - [x] I have searched to see if a similar issue already exists. I envision a feature where a speaker icon is added next to the copy button in a chat object/message. The feature should allow for playing an audio file referenced either in the metadata or a separate field when the speaker icon is clicked.


Clarify this requirement: I wanted to create a `gr.Barplot` that plots multiple `y` columns for each `x` value, but it seems like this is not possible with our `gr.Barplot`. We do support the ability to stack bars like this:

<img width="639" alt="Image" src="https://github.com/user-attachments/assets/bd436d9b-afb1-4aca-a48c-c2dba646e40a" />

But not have them side by side. The API I would expect is to be able to pass a list of columns for the `y` parameter, not just a single column name
Ambiguous terms: multiple, not possible, support, ability, stack, side by side, expect, list
Questions:
1. What specific functionality are you looking for when you mention "stack bars"?
2. Can you clarify what you mean by "side by side" in this context?
Clarified requirement: I want to create a `gr.Barplot` that can plot multiple `y` columns stacked on top of each other for each `x` value. The desired API functionality should allow passing a list of columns for the `y` parameter instead of just a single column name.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**

I'm facing difficulties managing user sessions for non-deepcopy-able objects in Gradio because the `gr.Request` object is not available in the `authenticate` function. This limitation forces me to use the username as a key for session management, which raises security concerns about potential user impersonation.

**Describe the solution you'd like**

I would like the `gr.Request` object to be included in the `authenticate` function. This would allow me to securely manage user-specific instances without relying solely on the username. Additionally, I would appreciate clarification on whether using the username as a key is safe, assuming the username is unique.

**Additional context**

I am implementing a session management system similar to the `session_hash` dictionary described in the Gradio documentation ([link](https://www.gradio.app/guides/state-in-blocks#session-state)). My current workaround involves using the username to store user-specific instances, but I need to ensure that an authenticated user cannot change the `request.username` to impersonate another user.

Here is a code example illustrating the issue:

```python
import gradio as gr

class NonDeepCopyable:
    def __init__(self):
        from threading import Lock
        self.counter = 0
        self.lock = Lock()  # Lock objects cannot be deepcopied

    def increment(self):
        with self.lock:
            self.counter += 1
            return self.counter

# Global dictionary to store user-specific instances
instances = {}

def authenticate(username, password):
    print(f"Authenticating {username} with {password}")
    if username == password:  # Testing... authentication would use firebase in this case.
        print("Authentication successful")
        instances[username] = NonDeepCopyable()
        return True
    else:
        return False

def initialize_instance(request: gr.Request):
    if request.username in instances: # Is this safe, or can someone potentially change the request.username header?
        # instances[request.username] = NonDeepCopyable()
        return "Session initialized!"
    else:
        return "Error: Authentication failed"


def cleanup_instance(request: gr.Request):
    if request.username in instances:
        del instances[request.username]


def increment_counter(request: gr.Request):
    if request.username in instances:
        instance = instances[request.username]
        return instance.username, instance.increment()
    return "Error: Session not initialized"


with gr.Blocks() as demo:
    output = gr.Textbox(label="Status")
    username = gr.Textbox(label="Username")
    counter = gr.Number(label="Counter Value")
    increment_btn = gr.Button("Increment Counter")
    increment_btn.click(increment_counter, inputs=None, outputs=[username, counter])

    # Initialize instance when page loads
    demo.load(initialize_instance, inputs=None, outputs=output)
    # Clean up instance when page is closed/refreshed
    demo.close(cleanup_instance)

demo.launch(auth=authenticate)
Ambiguous terms: securely, safe, potentially, clarification, similar, difficulties, user-specific, unique, manage, relying solely on, raising security concerns, impersonation, instance, global dictionary
Questions:
1. What specific security concerns are raised by using the username as a key for session management?
2. Can you provide more details on how an authenticated user might potentially change the `request.username` header?
Clarified requirement: - [x] I have searched to see if a similar issue already exists.


Clarify this requirement: - [ ] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
When components on the same row have descriptions of significantly different length the interactive parts of the components are not aligned as expected. An image speaks a thousand words:

![Image](https://github.com/user-attachments/assets/760f9f8a-ec97-4085-a834-304e2624d25c)

I would like:

![Image](https://github.com/user-attachments/assets/6cff5461-6872-45d2-9fee-8c32b57963c6)

**Describe the solution you'd like**  
A clear and concise description of what you want to happen.

**Additional context**  
Add any other context or screenshots about the feature request here.
Ambiguous terms: significantly, aligned, expected, clear, concise
Questions:
1. What specifically do you mean by "aligned as expected" in this context?
2. Can you provide more details on what you mean by a "clear and concise description"?
Clarified requirement: - [ ] I have searched to see if a similar issue already exists. When components on the same row have descriptions of different lengths, the interactive parts of the components do not line up properly. An image is provided for reference. The desired outcome is to have the components aligned like the second image provided. The solution should include a specific description of the desired alignment. Additional context or screenshots can be added to support the feature request.


Clarify this requirement: Can I cache only some examples from the list? Scenario: I have some examples that can only be run locally on a good GPU and others that can be run on huggingface's Zero GPU.

I thought of something like "example_labels" something like "examples_enable_cache" = [True, False, True, False ....]
Ambiguous terms: some, good, others
Questions:
1. What criteria determine which examples can only be run locally on a good GPU?
2. How should the examples be labeled to indicate whether they can be cached or not?
Clarified requirement: "Can examples be selectively cached based on their ability to run on different GPUs? For example, some examples require a good GPU for local execution, while others can run on huggingface's Zero GPU. The examples should be labeled with a parameter like 'examples_enable_cache' to indicate whether caching is enabled for each example."


Clarify this requirement: - [X] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  
I want to use a slider with a logarithmic scale, but currently, the steps can only be constant.

**Describe the solution you'd like**  
Add support for a slider with a logarithmic scale or allow custom step sizes.

**Additional context**  
Related issue: https://github.com/embeddings-benchmark/mteb/issues/2149
Ambiguous terms: constant, custom
Questions:
1. What do you mean by "constant" steps in the current slider?
2. Can you provide an example of what you mean by "custom step sizes" in the slider?
Clarified requirement: - [X] I have searched to see if a similar issue already exists. I want to use a slider with a logarithmic scale, but the current slider only supports steps that are the same size. I am requesting support for a slider with a logarithmic scale or the ability to set custom step sizes. Additional context can be found in the related issue: https://github.com/embeddings-benchmark/mteb/issues/2149.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
omni parser v2 and many other opens models would benifit with a browser inside spaces that could run these computer use agent models within the spaces enviroment using the zero gpu or other gpu spaces. 

**Describe the solution you'd like**  
maybe implemented something from browserbase into gradio?

@AK391 @abidlabs @gradio-pr-bot @pngwn @aliabd @freddyaboulton @dawoodkhan82 @aliabid94 @hannahblair @omerXfaruq @whitphx
Ambiguous terms: many, benefit, browser, inside, run, computer use agent models, environment, zero gpu, other gpu, maybe, implemented, something, gradio
Questions:
1. What do you mean by "computer use agent models"?
2. Can you clarify what you mean by "zero gpu" and "other gpu"?
Clarified requirement: Possibly integrate a feature similar to Browserbase into Gradio for this purpose.


Clarify this requirement: Basically adding a "Download video" to the audio component 

![Image](https://github.com/user-attachments/assets/eb40b89e-c2e6-4f52-a96d-898453d9f763)

thanks @apolinario for the suggestion
Ambiguous terms: Basically, user-friendly
Questions:
1. What specific actions should the "Download video" feature perform?
2. Who is the target audience for this feature?
Clarified requirement: Adding a "Download video" feature to the audio component to allow users to download videos.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  

I would like to disable auto correct in input since it shows the red dots on the text

<img src="https://github.com/user-attachments/assets/6156e0a1-2e0e-4e83-81fc-7167ebaa5824" width=500>

**Describe the solution you'd like**  
Add option to disable any input html attribute or autocorrect=False

**Additional context**  

"gradio>=5.15.0",
Ambiguous terms: disable, user-friendly
Questions:
1. Can you clarify what you mean by "disable any input html attribute"?
2. What specifically do you mean by "autocorrect=False"?
Clarified requirement: I would like to have the option to disable autocorrect in input fields by adding an attribute like autocorrect=False.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  

When creating out-painting demos, the end user will need to either crop or resize the image, or upload an image that al;ready has a clear border.

**Describe the solution you'd like**  

It would nice if a developer could set an `inset` kwarg to decide how large default border should be outpainting  demos, then when a user uploads an image it would already have that border set. I think this would provide a much nicer experiemnce.

**Additional context**  
Add any other context or screenshots about the feature request here.
Ambiguous terms: nice, clear, large, much nicer
Questions:
1. What is meant by "clear border" in the context of out-painting demos?
2. Can you provide a specific example of how the `inset` kwarg would work in setting the default border size?
Clarified requirement: Add any other context or screenshots about the feature request here.


Clarify this requirement: gr_custom_model_file.upload(
            fn=update_convert_btn,
            inputs=None,
            outputs=[gr_convert_btn],
        )
        gr_custom_model_file.select(
            fn=update_convert_btn,
            inputs=None,
            outputs=[gr_convert_btn],
        )
.select is supposed to be fired once the user selected a file to upload and .upload once the upload starts right?
Ambiguous terms: supposed, selected, file, upload, starts
Questions:
1. What does "fn=update_convert_btn" refer to in the context of these functions?
2. Can you clarify what is meant by "once the upload starts"?
Clarified requirement: The function gr_custom_model_file.upload should be triggered when the user initiates the upload process after selecting a file. Similarly, the function gr_custom_model_file.select should be triggered when the user selects a file to upload.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
I want to create or edit an xml with llm but tags are not displayed in gradio. I tried to escape the text with `html.escape(text)` so tags are displayed in gradio but copy button of chatbot copied the escaped text. 

**Describe the solution you'd like**  
Adding `html.escape()` support to chatbot and `html.unescape()` support to copy button of chatbot. Or at least for only copy button. 

**Additional context**  
I tried `sanitize_html=False` but it is not what I wanted. Also it would be good to know if it is possible to change behavior of copy button by overriding some functions.
Ambiguous terms: good
Questions:
1. What is "llm" referring to in the context of creating or editing an xml?
2. Can you clarify what you mean by "tags are not displayed in gradio"?
Clarified requirement: - [x] I have searched to see if a similar issue already exists.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
Currently, as an interactive component used as an input, the gr.Gallery has several areas that could be improved. For instance, it should support pasting images from the clipboard, allow users to upload new images after the initial upload, and provide the ability to remove specific images.

**Describe the solution you'd like**  
I achieved the functionality I wanted by using additional gr.Image and gr.Button components, as shown below.

```py
with gr.Column(variant="panel"):
    # Create an Image component for uploading images
    image_input = gr.Image(label="Upload an Image or clicking paste from clipboard button", type="filepath", sources=["upload", "clipboard"], height=150)
    gallery = gr.Gallery(columns=5, rows=5, show_share_button=False, interactive=True, height="500px", label="Gallery that displaying a grid of images")
    with gr.Row():
        upload_button = gr.UploadButton("Upload multiple images", file_types=["image"], file_count="multiple", size="sm")
        remove_button = gr.Button("Remove Selected Image", size="sm")

# Define the event listener to add the uploaded image to the gallery
image_input.change(add_images_to_gallery, inputs=[gallery, image_input], outputs=gallery)

# When the upload button is clicked, add the new images to the gallery
upload_button.upload(add_images_to_gallery, inputs=[gallery, upload_button], outputs=gallery)
# Event to update the selected image when an image is clicked in the gallery
selected_image = gr.Textbox(label="Selected Image", visible=False)
gallery.select(get_selection_from_gallery, inputs=gallery, outputs=[selected_image, sorted_general_strings, rating, character_res, general_res])
# Event to remove a selected image from the gallery
remove_button.click(remove_image_from_gallery, inputs=[gallery, selected_image], outputs=gallery)

def get_selection_from_gallery(gallery: list, selected_state: gr.SelectData):
    if not selected_state:
        return selected_state

    tag_result = { "strings": "", "rating": "", "character_res": "", "general_res": "" }
    if selected_state.value["image"]["path"] in tag_results:
        tag_result = tag_results[selected_state.value["image"]["path"]]

    return (selected_state.value["image"]["path"], selected_state.value["caption"]), tag_result["strings"], tag_result["rating"], tag_result["character_res"], tag_result["general_res"]

def add_images_to_gallery(gallery: list, images):
    if gallery is None:
        gallery = []
    if not images:
        return gallery
    
    # Combine the new images with the existing gallery images
    if type(images) is str:
        gallery.append(images)
    else:
        gallery.extend(images)
    return gallery

def remove_image_from_gallery(gallery: list, selected_image: str):
    if not gallery or not selected_image:
        return gallery

    selected_image = eval(selected_image)
    # Remove the selected image from the gallery
    if selected_image in gallery:
        gallery.remove(selected_image)
    return gallery
```
![image](https://github.com/user-attachments/assets/6934d97b-1274-437f-a9c9-c38fb1437bbf)


**Additional context**  
Although the custom implementation mentioned above achieves the desired functionality, it is clearly lacking in integration. If Gradio could implement these features as built-in functionality within the gr.Gallery component, it would be extremely useful.

Thank to the gradio team!
Ambiguous terms: improved, support, allow, provide, achieved, additional, clearly, extremely
Questions:
1. What specific improvements are needed in the gr.Gallery component?
2. How should the gr.Gallery component support pasting images from the clipboard?
Clarified requirement: The requirement outlines the need for enhancements in the gr.Gallery component, such as supporting pasting images from the clipboard, enabling users to upload new images, and allowing the removal of specific images. The solution provided involves using additional gr.Image and gr.Button components for achieving the desired functionality.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

While files can be added using the upload button,

![](https://github.com/user-attachments/assets/3e621815-681d-480a-8879-6d2e0808f0c4)

it seems drag-and-drop doesn't work.

https://github.com/user-attachments/assets/ac984935-7ce3-474f-b812-3908716819b8

I used this code to take the screenshot and recordings.
```py
import gradio as gr

with gr.Blocks() as demo:
    files = gr.File(file_count="multiple", allow_reordering=True)
demo.launch()
```
Ambiguous terms: multiple, allow_reordering
Questions:
1. What does "multiple" refer to in the context of the code?
2. What does "allow_reordering" mean in relation to the files?
Clarified requirement: The code snippet provided is used to capture screenshots and recordings, and it involves allowing the user to upload multiple files and reorder them.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
My Gradio app has many tabs, and each tab has quite a few functionalities. 
And I'm increasingly finding that the loading speed is too slow because it loads all tabs every time.

**Describe the solution you'd like**  
Add lazy loading functionality, so that tabs are only loaded when they are needed/accessed.

**Additional context**  
I tried to implement it this way, but it doesn't work:

```
import gradio as gr

def toggle_render():
    return gr.update(render=True)


def lazy_load():
    with gr.Blocks() as demo:
        with gr.Accordion(render=False) as tabs:
            print("this has loaded...")
            text1 = gr.Textbox()

        # Load event to show the accordion
        demo.load(fn=toggle_render,  outputs=tabs)

    return demo

```
Ambiguous terms: slow, fast, user-friendly, many, quite a few, too slow, lazy loading, needed, accessed
Questions:
1. What specifically do you mean by "too slow" in terms of the loading speed?
2. Can you clarify what you mean by "tabs are only loaded when they are needed/accessed"?
Clarified requirement: ```


Clarify this requirement: Gradio is an excellent project, and I really enjoy using it to develop apps. However, I’ve encountered a problem: **due to user privacy concerns, my server is not allowed to store user input and output files** (e.g., images and audio) on the disk.

To address this issue, I hope Gradio can support in-memory byte transfer functionality. This would **allow the communication of files like images or audio directly in memory**, avoiding storage on the server's disk and ensuring compliance with privacy policies.

I’ve spent some time studying Gradio's codebase, but the project is quite large for me, and I haven’t made much progress. I would deeply appreciate it if any developer could provide assistance with this.

Thank you for your consideration!
Ambiguous terms: excellent, user privacy concerns, allow, support, functionality, communication, directly, compliance, large, assistance
Questions:
1. What specifically do you mean by "communication of files directly in memory"?
2. Can you clarify what kind of assistance you are seeking from other developers?
Clarified requirement: Gradio is unable to store user input and output files on the server's disk due to privacy concerns. To address this, the project needs support for in-memory byte transfer functionality to enable direct communication of files like images or audio without storing them on disk. The requester is seeking assistance from developers to implement this feature.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  
When using dictionaries as event inputs in Gradio, we can only use component objects themselves as dictionary keys. This makes it difficult to separate event handling functions from component creation code, as the functions need direct access to the component objects.

**Describe the solution you'd like**  
Allow specifying custom string keys when using dictionaries as event inputs.
Ambiguous terms: difficult, custom
Questions:
1. What specifically makes it difficult to separate event handling functions from component creation code in this context?
2. Can you provide an example of what you mean by "custom string keys" in this case?
Clarified requirement: Allow the specification of user-defined string keys when using dictionaries as event inputs.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  
I frequently use the `gr.JSON` component to display data dictionaries and JSON (as text). However, the component does not allow editing the dictionary that the component displays. The capability to edit may be desirable in some use-cases.

For example, while a `gr.Dataframe` component can render a Polars data frame and even allows it to be edited, the Polars dataframe may contain the data type `Struct`. This type of data is best rendered through the `gr.JSON` component, when viewed per row. Editing the Polars data frame then necessitates editing the rendered JSON for columns that Polars parses as `Struct`.

**Describe the solution you'd like**  
I do not have a well thought out solution to this. I think one clear problem will be data validation.

One solution (to data validation) could be to detect the data type of every dictionary key and and its corresponding value (excluding nested tuples, lists and dictionaries) and typecast the newly edited data to the detected data type. On the other hand, if the dictionary being displayed is the output (i.e., `model_dump`) of a Pydantic model then use the Pydantic validator to depend on any complex validation that needs to take place on the edited data.

**Additional context**  
Check the "Dataset" tab at https://huggingface.co/spaces/anirbanbasu/gradio-experiments. Try to upload some data as CSV, JSON or Parquet to render it as a Polars dataframe. Click any row of the displayed data frame to see the row rendered as JSON. The ability to edit the data through the JSON component ensures that it can still be edited even if columns of the data frame are not simple types.
Ambiguous terms: desirable, may be, best, clear, problem, solution, well thought out, one solution, could be, complex, depends on
Questions:
1. What specific editing capabilities are desired for the `gr.JSON` component?
2. Can you provide more details on how the data validation process should work for the edited data?
Clarified requirement: - [x] I have searched to see if a similar issue already exists. The `gr.JSON` component needs to be enhanced to allow editing of the displayed data dictionaries and JSON. The editing capabilities should include detecting data types for keys and values, typecasting edited data, and utilizing Pydantic validation for data output from Pydantic models.


Clarify this requirement: Hi,
I would like to get the camera position and rotation of the current view in a Model3D, when used as an input for a function.
Currently there is only access to the 3d file itself.

Thanks
Ambiguous terms: current view, function
Questions:
1. What is meant by "current view" in the context of a Model3D?
2. What kind of function is being referred to in this requirement?
Clarified requirement: I would like to retrieve the camera position and rotation of a Model3D's current perspective to use as input for a specific function. Currently, only access to the 3D file itself is available.


Clarify this requirement: ### Describe the bug

Hi Gradio Development Team,  

I suspect there may be an issue with the `Examples` mechanism when using the `gr.Gallery` component. The same `Examples` implementation works perfectly with the `gr.Image` component. Here's a detailed explanation of the issue:  

Recently, I updated my Gradio application by replacing the `gr.Image` component with `gr.Gallery`. However, this resulted in a `PermissionError: [Errno 13] Permission denied: 'C:\\my\\path'`. 

Upon investigation, it appears that the issue may be related to the `component.as_example(ex)` function in `gradio\components\dataset.py`.  

To debug, I added a print statement in the `__init__` method of `dataset.py`. Below are the console logs for comparison:  

**When using `gr.Image`, the console log shows:**  

<details>  

component:<gradio.components.image.Image object at 0x00000215AB195E40>  
ex:power.jpg  
component.as_example(ex):path='power.jpg' url=None size=None orig_name='power.jpg' mime_type=None is_stream=False meta={'_type': 'gradio.FileData'}

</details>  

**When using `gr.Gallery`, the console log shows:**  

<details>  

component:<gradio.components.gallery.Gallery object at 0x000001CEE1667070>
ex:power.jpg
component.as_example(ex):root=[GalleryImage(image=FileData(path='p', url=None, size=None, orig_name='p', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='o', url=None, size=None, orig_name='o', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='w', url=None, size=None, orig_name='w', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='e', url=None, size=None, orig_name='e', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='r', url=None, size=None, orig_name='r', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='.', url=None, size=None, orig_name='', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='j', url=None, size=None, orig_name='j', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='p', url=None, size=None, orig_name='p', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None), GalleryImage(image=FileData(path='g', url=None, size=None, orig_name='g', mime_type=None, is_stream=False, meta={'_type': 'gradio.FileData'}), caption=None)]

Traceback (most recent call last):
  File "C:\my\path\app.py", line 469, in <module>
    main()
  File "C:\my\path\app.py", line 449, in main
    gr.Examples(
  File "C:\my\path\venv\lib\site-packages\gradio\helpers.py", line 56, in create_examples
    examples_obj = Examples(
  File "C:\my\path\venv\lib\site-packages\gradio\helpers.py", line 264, in __init__
    self.dataset = components.Dataset(
  File "C:\my\path\venv\lib\site-packages\gradio\component_meta.py", line 179, in wrapper
    return fn(self, **kwargs)
  File "C:\my\path\venv\lib\site-packages\gradio\components\dataset.py", line 117, in __init__
    processing_utils.move_files_to_cache(
  File "C:\my\path\venv\lib\site-packages\gradio\processing_utils.py", line 516, in move_files_to_cache
    return client_utils.traverse(
  File "C:\my\path\venv\lib\site-packages\gradio_client\utils.py", line 1009, in traverse
    new_obj.append(traverse(item, func, is_root))
  File "C:\my\path\venv\lib\site-packages\gradio_client\utils.py", line 1004, in traverse
    new_obj[key] = traverse(value, func, is_root)
  File "C:\my\path\venv\lib\site-packages\gradio_client\utils.py", line 1000, in traverse
    return func(json_obj)
  File "C:\my\path\venv\lib\site-packages\gradio\processing_utils.py", line 490, in _move_to_cache
    temp_file_path = block.move_resource_to_block_cache(payload.path)
  File "C:\my\path\venv\lib\site-packages\gradio\blocks.py", line 347, in move_resource_to_block_cache
    temp_file_path = processing_utils.save_file_to_cache(
  File "C:\my\path\venv\lib\site-packages\gradio\processing_utils.py", line 277, in save_file_to_cache
    temp_dir = hash_file(file_path)
  File "C:\my\path\venv\lib\site-packages\gradio\processing_utils.py", line 206, in hash_file
    with open(file_path, "rb") as f:
PermissionError: [Errno 13] Permission denied: 'C:\\my\\path'

</details>  

Could you please help investigate and confirm this behavior? Thank you!

### Have you searched existing issues?  🔎

- [X] I have searched and found no existing issues

### Reproduction

```python
import gradio as gr


def main():
    with gr.Blocks() as demo:
        with gr.Column():
            #image = gr.Image(type="pil", image_mode="RGBA", label="Input")
            gallery = gr.Gallery(columns=5, rows=5, show_share_button=False, interactive=True, height="500px", label="Input")

        gr.Examples(
            [["power.jpg"]], 
            inputs=[
                gallery,
            ],
        )

    demo.queue(max_size=10)
    demo.launch(inbrowser=True)

if __name__ == "__main__":
    main()
```


### Screenshot

_No response_

### Logs

_No response_

### System Info

```shell
The testing environment is Windows 10 with Python 3.10.9 and Gradio 5.6.0.
```


### Severity

Blocking usage of gradio
Ambiguous terms: issue, mechanism, issue, function, debug, print statement, console logs, comparison, as_example, component, GalleryImage, traceback, PermissionError, investigate, confirm, behavior
Questions:
1. What specific behavior or functionality is expected when using the `gr.Gallery` component in the Gradio application?
2. How is the `component.as_example(ex)` function supposed to handle input examples when using the `gr.Gallery` component?
Clarified requirement: Describe the unexpected `PermissionError` issue encountered when using the `gr.Gallery` component in a Gradio application, and investigate the behavior of the `component.as_example(ex)` function in relation to input examples for the `gr.Gallery` component.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Describe the solution you'd like**  
Please add support for displaying FBX files in `Model3D`, since FBX is one of the most commonly used formats of 3D assets.

**Additional context**  
> The FBX format is used to provide interoperability between digital content creation applications and game engines such as Blender, Maya, Autodesk, Unity, Unreal and many others. It supports many features such as 3D models, scene hierarchy, materials, lighting, animations, bones and more.

It seems that three.js supports FBX format: [FBX Loader - Three.js Tutorials](https://sbcode.net/threejs/loaders-fbx/).
Ambiguous terms: support, displaying, commonly used, many features
Questions:
1. What specifically do you mean by "support for displaying FBX files in `Model3D`"?
2. Can you clarify what you mean by "many features" of the FBX format?
Clarified requirement: The FBX format is commonly used for interoperability between digital content creation applications and game engines like Blender, Maya, Autodesk, Unity, and Unreal. It supports a wide range of features essential for 3D assets. It has been noted that three.js already supports loading FBX files: [FBX Loader - Three.js Tutorials](https://sbcode.net/threejs/loaders-fbx/).


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

I think many would agree that it would be convenient to place some tabs in different locations. For example, the "Settings" tab could be located on the right, and the "INFO" tab could be on the left. The main tabs could be placed in the center or in another convenient location for users.
It would also be nice to have the ability to arrange tabs in a column instead of in a single line.

These changes could significantly improve some interfaces and make them more user-friendly.
Ambiguous terms: convenient, nice, user-friendly
Questions:
1. What specific interface or software are these tabs referring to?
2. Are there any constraints or limitations to consider when rearranging the tabs?
Clarified requirement: I have searched to see if a similar issue already exists. I think many would agree that it would be convenient to place some tabs in different locations within a specific interface or software. For example, the "Settings" tab could be located on the right, and the "INFO" tab could be on the left. The main tabs could be placed in the center or in another convenient location for users. It would also be nice to have the ability to arrange tabs in a column instead of in a single line. These changes could significantly improve the interface's user-friendliness.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  
Currently, when using `gr.render()` for dynamic rendering, there is no support for custom loading UI. The default loading indicator does not meet specific design needs and may not align with the overall UI style, which can impact the user experience, especially in more complex applications.

**Describe the solution you'd like**  
I would like `gr.render()` to support custom loading UIs. This would allow users to implement a loading indicator or animation that fits their design, instead of being limited to the default one.

**Additional context**  
For example, it would be helpful if we could pass a custom component or loading animation as an argument when calling `gr.render()`, which would replace the default loading state display. This would greatly enhance flexibility for developers and improve UI consistency.
Ambiguous terms: custom, specific, default, more complex, fits their design, flexibility, improve UI consistency
Questions:
1. What specific aspects of the default loading indicator do not align with certain design needs?
2. Can you provide an example of how passing a custom component or loading animation as an argument would work in the context of calling `gr.render()`?
Clarified requirement: For example, allowing the ability to pass a custom loading component or animation as an argument when calling `gr.render()` would provide developers with more flexibility to enhance UI consistency.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  
Not a problem with gradio, although perhaps related to a problem with society and sharing online images. Watermarking helps to: 
- Mark content so that people know how synthetic it is / whether it's synthetic at all: Content can be marked as fully synthetic (AI-generated), such as DeepFakes; non-synthetic (such as images from a camera); and anywhere in between. 
- Mark ownership (of all kinds of content).
- Mark content with a resource to get more information (such as with a watermark QR code).

**Describe the solution you'd like**  
`watermarked_image = gr.Image(image, watermark=watermark_file)`

**Additional context**  
Currently, `gr.Video()` can take a `watermark` argument, with a path to a watermark image file, in order to watermark the video.
I propose making a parallel functionality in `gr.Image()`.
Ambiguous terms: fast, user-friendly, synthetic, ownership, resource, more information
Questions:
1. What is meant by "making a parallel functionality" in this context?
2. Can you clarify what is meant by "watermarking helps to mark ownership of all kinds of content"?
Clarified requirement: - The feature request is to add a watermarking functionality to the `gr.Image()` method in Gradio, similar to the existing functionality in `gr.Video()`. Watermarking in this context means marking content as fully synthetic (AI-generated), non-synthetic, or anywhere in between, marking ownership of content, and providing a resource for more information through a watermark QR code. The proposed solution is to create a `watermarked_image` object using `gr.Image(image, watermark=watermark_file)`.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
A [recent update](https://github.com/gradio-app/gradio/pull/9199) to the Tab component means that any tabs that cannot fit in a single row are now forced into a small menu. This results in the tabs being hidden and not easily found for new users of an application, creating a UX issue. The previous behavior allowed for overflow of tabs into a second row, which was much clearer for users.

**Describe the solution you'd like**  
Restore the ability to choose the overflow behavior - either hiding any additional tabs in the menu (the new behavior), or ensuring all tabs are displayed across multiple rows (the original behavior).

**Additional context**  
This issue is preventing me from upgrading multiple applications to gradio v5. Please restore the functionality - there are multiple people who have requested this ([example](https://github.com/gradio-app/gradio/issues/9682#issuecomment-2419983344))
Ambiguous terms: fast, user-friendly, easily found, clearer
Questions:
1. What specific actions or interactions are considered "fast" in this context?
2. Can you provide more details on what makes something "user-friendly" or "easily found" for new users?
Clarified requirement: This issue is preventing the upgrade of multiple applications to gradio v5. Please restore the functionality as requested by multiple users.


Clarify this requirement: Hello Gradio Team,

I have a feature request that I believe would significantly enhance the functionality of Gradio's native components. Currently, Gradio provides a robust framework for building interactive interfaces, and I've found it incredibly useful for my projects.

However, I've encountered a scenario where I'd like to have more control over the state of native components within my application. Specifically, I'm interested in the possibility of enhancing the event listeners for these components to optionally return the current state of the component.

For example, consider the Audio component. It would be incredibly beneficial if the event listeners could return not only the event details but also the current audio's URL, its duration, and the current playback time. This additional information would allow for more dynamic and responsive applications, especially in scenarios where real-time feedback or control over media playback is necessary.

Here's a more detailed breakdown of the functionality I'm proposing:

Audio Component: When an event listener is triggered (e.g., on play, pause, end, etc.), it could return an object containing:
The Path(or FileData) of the currently loaded audio file.
The total duration of the audio.
The current playback position (time).
This feature would not only benefit developers working with media but also enhance the overall interactivity and responsiveness of applications built with Gradio.

I understand that this is a feature request and I'm excited about the potential it holds for the Gradio community. I'd be more than happy to provide further details or examples if needed.

Thank you for considering this request. I look forward to seeing how Gradio continues to evolve and support developers in building interactive applications.
Ambiguous terms: enhance, more control, optionally, beneficial, dynamic, responsive, real-time, necessary, more detailed, proposing, benefit, interactive, excited
Questions:
1. What specific event listeners are currently available for Gradio's native components?
2. Can you provide an example of how the current state of a native component would be used in an application?
Clarified requirement: I am requesting a feature that would allow event listeners for Gradio's native components to return additional information about the current state of the component. Specifically, for the Audio component, I propose that event listeners return an object containing the path or file data of the loaded audio file, the total duration of the audio, and the current playback position (time). This enhancement aims to provide more detailed information for developers working with media and improve interactivity and responsiveness in applications built with Gradio. Thank you for considering this request.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
The Dataset is resistant to being used outside of the internal `gr.Examples` use case. I would like this to not be the case.

The main issue is that it has no value, so passing dataset into a function is an exercise in pointlessness. _Updating_ the Dataset works relatively well, although it doesn't get angry sometimes without explanation. I was able to figure it out but our users would probably have less success.

**Describe the solution you'd like**  

I think we just need to align this component's API with ours others and do a little more testing.

Specifically i think we should combine `samples` and `sample_labels` into a single `value` that we can access in python and JS function. We should also make sure the component works with partial components updates (when return a new `gr.Dataset` from a backend function).

**Additional context**  
The context here is I was trying to hack together a `localstorage` history viewer thing, like examples but with localstorage.

in principle something like this should work:

```python
with gr.Blocks() as demo:
    prompt = gr.Text(
        label="Prompt",
        show_label=False,
        max_lines=1,
        placeholder="Enter your prompt",
        container=False,
    )

    result = gr.Image(label="Result", show_label=False)

    ex = gr.Dataset(
        label="History",
        samples=[],
        components=[prompt],
        sample_labels=[],
    )

    prompt.submit(
        fn=infer,  # do the inference
        inputs=prompt,
        outputs=result,
    )
    result.change(
        js=js_after_run,  # set the localstorage
        fn=None,  # we can do this all in the frontend
        inputs=[result, ex],  # we need the current history to update it
        outputs=ex,  # the updated history
    )
    demo.load(
        js=js_load,  # load the history from localstorage
        fn=None,
        inputs=None,
        outputs=ex,
    )

demo.launch()
```

Needs some event listeners setting up but this is the gist.
Ambiguous terms: little more testing, should combine, works relatively well, less success, should work
Questions:
1. What specific issues arise when the Dataset is used outside of the internal `gr.Examples` use case?
2. Can you provide more details on what aligning the component's API with others entails?
Clarified requirement: The context involves attempting to create a `localstorage` history viewer similar to examples but utilizing local storage. The provided Python code snippet demonstrates the intended functionality, requiring event listeners to be set up for full implementation.


Clarify this requirement: I have searched to see if a similar issue already exists. But none of them is identical to my needs.

I would like to request a feature in Gradio that allows users to visualize audio waveforms with dynamically defined regions based on time-aligned information. This feature would enhance the functionality of the gr.Audio component, making it suitable for applications such as transcription, audio annotation, and pronunciation assessment.

Currently, while the gr.Audio component utilizes Wavesurfer.js for audio playback, it lacks the ability to display time-aligned regions that are essential for various applications. For example, in tasks like speech recognition and pronunciation evaluation, having clear visual cues of aligned segments can significantly improve user interaction and understanding of the audio content.

**Feature Description**

1. Input:

-     An audio file (uploaded or recorded).
-     Time-alignment information in the form of start and end times for each region.

2. Output:

-     A visual representation of the audio waveform with highlighted regions corresponding to the provided time-alignment information.
-     The regions should be editable, allowing users to modify the timings directly through the interface.

**Use Cases**

1.     Transcription: Users can see the specific segments of the audio that need attention during transcription, aiding accuracy.
2.     Pronunciation Assessment: Highlighting regions of interest can help in evaluating pronunciation accuracy at specific times in the audio.
3.     Audio Annotation: Facilitates easy marking of segments for further processing or analysis.

Some visualized examples [click here](https://github.com/katspaugh/wavesurfer.js/issues/1260)

Sincerely,
Ambiguous terms: suitable, clear, significant, improve, enhance, editable, specific, easy
Questions:
1. What specific functionalities are currently lacking in the gr.Audio component that this feature aims to address?
2. How would users interact with the highlighted regions in the visual representation of the audio waveform?
Clarified requirement: I have searched for existing similar issues but found none identical to my needs. I would like to request a feature in Gradio that allows users to visualize audio waveforms with dynamically defined regions based on time-aligned information. This feature aims to address the lack of ability in the gr.Audio component to display time-aligned regions essential for tasks like transcription and pronunciation assessment. The feature should allow users to upload or record an audio file and input time-alignment information with start and end times for each region. The output should be a visual representation of the audio waveform with highlighted regions corresponding to the provided time-alignment information, which users can edit directly through the interface. The feature is intended to aid in transcription accuracy, pronunciation assessment, and audio annotation.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.

I've looked at both the blog and other GitHub issues, but there does not appear to be a clean solution for gracefully closing the Gradio Chatbot interface and killing the thread. Currently, I'm using a ```os._exit(0)``` workaround, but I was hoping for the ability to call a function via a ```gradio.Button``` to handle the exit. ```gradio.close_all()``` similarly left the application running and did not shut down the app.
Ambiguous terms: gracefully, clean, gracefully, clean, handle, similarly
Questions:
1. What specifically do you mean by "gracefully closing" the Gradio Chatbot interface?
2. Can you clarify what you mean by "handle the exit" in the context of calling a function via a `gradio.Button`?
Clarified requirement: I have searched to see if a similar issue already exists. I've looked at both the blog and other GitHub issues, but there does not appear to be a clear solution for closing the Gradio Chatbot interface and ending the thread. Currently, I'm using `os._exit(0)` as a workaround, but I was hoping to implement a function call through a `gradio.Button` to manage the exit. The `gradio.close_all()` method did not effectively shut down the application.


Clarify this requirement: ### Describe the bug

[/usr/local/lib/python3.10/dist-packages/gradio/external.py](https://localhost:8080/#) in from_model(model_name, hf_token, alias, **kwargs)
    368         fn = client.image_to_image
    369     else:
--> 370         raise ValueError(f"Unsupported pipeline type: {p}")
    371 
    372     def query_huggingface_inference_endpoints(*data):

ValueError: Unsupported pipeline type: image-text-to-text

### Have you searched existing issues?  🔎

- [X] I have searched and found no existing issues

### Reproduction

```python
import gradio as gr

gr.load("models/meta-llama/Llama-3.2-90B-Vision-Instruct").launch()
![image](https://github.com/user-attachments/assets/28470dd0-fdf9-44f1-80b7-5ea611772e57)


```


### Screenshot

https://github.com/user-attachments/assets/28470dd0-fdf9-44f1-80b7-5ea611772e57

### Logs

```shell
Fetching model from: https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

<ipython-input-10-8dcbad077325> in <cell line: 3>()
      1 import gradio as gr
      2 
----> 3 gr.load("models/meta-llama/Llama-3.2-90B-Vision-Instruct").launch(debug=True)

2 frames

/usr/local/lib/python3.10/dist-packages/gradio/external.py in from_model(model_name, hf_token, alias, **kwargs)
    368         fn = client.image_to_image
    369     else:
--> 370         raise ValueError(f"Unsupported pipeline type: {p}")
    371 
    372     def query_huggingface_inference_endpoints(*data):

ValueError: Unsupported pipeline type: image-text-to-text
```


### System Info

```shell
Gradio Environment Information:
------------------------------
Operating System: Linux
gradio version: 4.44.0
gradio_client version: 1.3.0

------------------------------------------------
gradio dependencies in your environment:

aiofiles: 23.2.1
anyio: 3.7.1
fastapi: 0.115.0
ffmpy: 0.4.0
gradio-client==1.3.0 is not installed.
httpx: 0.27.2
huggingface-hub: 0.24.6
importlib-resources: 6.4.5
jinja2: 3.1.4
markupsafe: 2.1.5
matplotlib: 3.7.1
numpy: 1.26.4
orjson: 3.10.7
packaging: 24.1
pandas: 2.1.4
pillow: 9.4.0
pydantic: 2.9.2
pydub: 0.25.1
python-multipart: 0.0.9
pyyaml: 6.0.2
ruff: 0.6.5
semantic-version: 2.10.0
tomlkit==0.12.0 is not installed.
typer: 0.12.5
typing-extensions: 4.12.2
urllib3: 2.0.7
uvicorn: 0.30.6
authlib; extra == 'oauth' is not installed.
itsdangerous; extra == 'oauth' is not installed.


gradio_client dependencies in your environment:

fsspec: 2024.6.1
httpx: 0.27.2
huggingface-hub: 0.24.6
packaging: 24.1
typing-extensions: 4.12.2
websockets: 12.0
```


### Severity

Blocking usage of gradio
Ambiguous terms: Unsupported, pipeline, type
Questions:
1. What does "pipeline type" refer to in this context?
2. Can you clarify what is meant by "image-text-to-text"?
Clarified requirement: Describe the bug where a ValueError is raised due to an unsupported pipeline type, specifically "image-text-to-text".


Clarify this requirement: - [O] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  

Currently there is no way to stop an inference function that is running, WITHOUT spawning them as a thread (See https://github.com/gradio-app/gradio/issues/7593#issuecomment-1977350223)

I fully understand the rationale behind this decision, but at the same time it would be nice if Gradio had a built-in way to do this WITHOUT making it the default.

I think anyone who has used Gradio for building inference UI would have thought about this at some point so just this little feature would go a long way. For example, Automatic1111 also has a cancel feature, but IMO these features should be a part of the framework (even if it's not exposed by default).

**Describe the solution you'd like**  

By default it works the same way, but when calling a function there might be an optional flag you can set to make it run as a thread, which can be easily canceled, without the developer having to know how to do threads, etc.
Ambiguous terms: nice, little, long way, easy, easily, etc.
Questions:
1. What does "spawning them as a thread" mean in this context?
2. Can you clarify what you mean by "cancel feature" in the context of Automatic1111?
Clarified requirement: - [O] I have searched to see if a similar issue already exists. The feature request is to have a built-in way in Gradio to stop an inference function that is running without requiring it to be spawned as a thread. The solution should include an optional flag that can be set when calling a function to run it as a thread, which can then be easily canceled without the developer needing to understand threading.


Clarify this requirement: One thing that confuses first-time gradio users is that gradio does *not* run your entire script every time the page loads. Among other issues, this has meant that certain abstractions that chat users use to store chat histories don't reset every time a user loads the page, which means that chat histories can get shared among users. 

As an example, see the "Handling Concurrent Users with Threads" section in https://www.gradio.app/guides/creating-a-chatbot-fast/. Our current suggested workaround is quite complicated. I suppose the right thing to do would be create a function that that is run upon `demo.load()` and to store all resulting variables to `gr.State` objects, but this is quite cumbersome to do.

As an alternative, perhaps something like this could work:

```py
import gradio as gr

with gr.State():
  # any code here is re-run every time the page loads
  # and any of these variables can easily be referenced 
  # in the demo below

with gr.Blocks() as demo:
  ...

demo.launch()
```
Ambiguous terms: confuses, issues, certain, complicated, cumbersome, alternative
Questions:
1. What specific aspects of gradio's behavior confuse first-time users?
2. Can you clarify what is meant by "abstractions that chat users use to store chat histories"?
Clarified requirement: One issue that confuses first-time gradio users is that gradio does not rerun the entire script every time the page loads. This behavior affects the storage of chat histories, potentially leading to shared chat histories among users. To address this, a suggested workaround involves creating a function that is executed upon `demo.load()` and storing resulting variables in `gr.State` objects. An alternative approach could involve using the provided code snippet with `gr.State` and `gr.Blocks` to easily reference variables in the demo.


Clarify this requirement: ### Describe the bug

https://www.gradio.app/guides/controlling-layout -> "The widths of elements in a Row can be controlled via a combination of scale and min_width arguments that are present in every Component."

This is not true for Markdown and HTML components. I don't know if this applies to others as well.

It's nice to use these as "labels" (bit of text) for various bits of an app. However, the lack of these params means it becomes very difficult to style the app simply (without resorting to CSS, etc.). At the moment Textbox acts as a better "label" component in non-interactive mode, but the styling in non-interactive mode makes it look editable, so that's not great either.

### Have you searched existing issues?  🔎

- [X] I have searched and found no existing issues

### Reproduction

View documentation.


### Screenshot

_No response_

### Logs

_No response_

### System Info

```shell
Latest version (docs are incorrect and code also shows the params are missing).
```


### Severity

I can work around it
Ambiguous terms: nice, difficult, simply, better, great
Questions:
1. Which specific elements in the Row are affected by the absence of the scale and min_width arguments?
2. Are there any specific styling issues that arise from the lack of these parameters for Markdown and HTML components?
Clarified requirement: Describe the bug where the widths of elements in a Row cannot be controlled using the scale and min_width arguments for Markdown and HTML components, potentially causing styling issues and difficulties in achieving a desired layout without resorting to CSS.


Clarify this requirement: I just checked with latest GPT-4 strawberry and seems like still we don't have

If we have how we make it? What I want is, have a button to select folder and copy its path to the input field

Like below screenshot

![image](https://github.com/user-attachments/assets/b933fd71-ddcf-4f03-a4af-d6eecdb28fe1)
Ambiguous terms: latest, button, select, folder, copy, path, input field
Questions:
1. What do you mean by "latest GPT-4 strawberry"?
2. Can you clarify what you mean by "copy its path to the input field"?
Clarified requirement: Ensure that there is a button that allows the user to select a folder, and the path of that folder should be automatically inserted into an input field, as shown in the provided screenshot.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.
Yes

**Is your feature request related to a problem? Please describe.**  
When you load a very large file into the audio player, ti takes a long time to load. During this time the user has no idea that the file is still loading.
It would also be nice to a have a single audio interface fro the audio component. Just have the player and add the "drop"  function to it. Now we have two interfaces that change when you load a file and thus changes the layout.

**Describe the solution you'd like**  
Add an event to the audio component that the file is loading or triggered when it completes the loading process or add a "rotating" icon for "being busy".  Large files are when you do TTS or STT.
Ambiguous terms: long time, nice, single, just, nice, two, changes, layout, event, loading process, rotating, busy, large
Questions:
1. What is considered a "long time" for loading a file into the audio player?
2. Can you clarify what you mean by "single audio interface" and how it differs from the current setup?
Clarified requirement: Add an event to the audio component to indicate when the file is loading or when the loading process is complete. Alternatively, include a "rotating" icon to signify that the system is busy during the loading of large files, such as with TTS or STT.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.
Yes, Even tried a custom FileExplorer but could not get the "refresh" solved.

**Describe the solution you'd like**  
A file explorer component shows the local file structure, but sometimes the underlying file structure changes due to file addition, renaming and deletion. So there must be a way to toggle a refresh.

**Additional context**  
Currently I am overcoming the refresh by toggling the "glob" or "ignore_glob" parameters in the traditional way with success, but it would be nice to have a refresh parameter/method. Looking at the source code of the FIleExplorer is could be done by adding a refresh flag to the [Key] trigger list. The problem is I can not figure out the part thereafter and how the [key] are used to update the interface.
Ambiguous terms: refresh, local file structure, underlying file structure, file addition, renaming, deletion, toggle a refresh, traditional way, refresh parameter/method, refresh flag, update the interface
Questions:
1. What specific functionality are you looking for when you mention "toggle a refresh" in the context of the file explorer component?
2. Can you clarify how the [Key] trigger list is related to updating the interface in the file explorer component?
Clarified requirement: Currently, I am able to work around the refresh issue by adjusting the "glob" or "ignore_glob" parameters. However, I believe adding a refresh parameter/method or flag to the [Key] trigger list in the source code of the FileExplorer could provide a more efficient solution for updating the interface.


Clarify this requirement: - [ Yes ] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
1. Currently, auth in launch is returning a fixed message “Incorrect Credentials” if the specified function (def) returns False. 
Here, I want to output a different error message to the frontend in case of False, contextually.
Then, depending on the context, the login page can check permissions etc. to match the user ID and provide additional information such as “not authorized”, “PW is incorrect”, etc.
Right now, it just outputs “Incorrect Credentials” so I don't know what is preventing the user from logging in.
Obviously, showing information like incorrect PW, using a non-existent ID, etc. could be a security concern, but I think it would be helpful to customize it for your own business needs.

2. I want to use request: gr.Request in the function I specify in launch.(auth=).
I want to branch based on user IP on the login page, but I can't, and it's hard to meet my business needs.


**Describe the solution you'd like**  
1. I don't want launch.(auth=) to only accept bool(), I want it to accept bool(), str() and print the value of the returned str() variable if the value of bool is False.

2. Make sure that the function you specify in launch.(auth=) accepts request: gr.Request as a parameter. (This will allow you to check the user IP, etc. and take further action).

**Additional context**  

Please forgive my poor English. (__)
Ambiguous terms: contextually, additional information, customize, business needs, hard, poor
Questions:
1. Can you provide more specific examples of the different error messages you want to output in the frontend?
2. What specific actions or checks do you want to perform based on the user IP on the login page?
Clarified requirement: Please forgive any language barriers.


Clarify this requirement: If I want to execute several functions consecutively so I can update the components after each function finishes I use then. And we have success in case we don't want the rest to execute if there was an error. However there is not way to stop the chain of events. (or I have not found it anywhere).

My situation is this: I have a slider. If the user moves the slider I want certain behaviour to always happen and update other components. Then there are following functions which I want to run only if some conditions are met. Right now I don't see any other way to stop them from executing than throwing an error (which is not ideal since user will see an error message even though he didnt do anything wrong) or to have an internal state which I will check in each of the following functions and skip them. 
That becomes impractical and messy and user can see that gradio rerenders the components that would be updated in the conditioned funtions.

I would like a way to interrupt the chain of events without throwing an error. For examples the event listener could have argument 'run_if' or 'stop_if' or something like that.
```
def is_valid():
     return True
slider = gr.Slider(...)
slider.change(fn = foo, inputs = inputs, outputs = outputs).then(fn = foo2, inputs = inputs2, outputs = outputs2, run_if = is_valid)
```
Ambiguous terms: certain, ideal, impractical, messy, like, something like that
Questions:
1. What specific behaviors do you want to happen when the user moves the slider?
2. Can you provide examples of conditions that need to be met for the following functions to run?
Clarified requirement: If the user moves the slider, there are specific behaviors that should always occur and update other components. Following this, there are functions that should only run if certain conditions are met. The goal is to find a way to interrupt the chain of events without resorting to throwing an error.


Clarify this requirement: - [x] I have searched to see if a similar issue already exists.


**Is your feature request related to a problem? Please describe.**  
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

For a chatbot, I would like to add an "Export Chat History" button, when the user clicks the button, it should call something like `generate_chat_history(chatbot)` and auto download the content into a JSON/HTML file.

**Describe the solution you'd like**  
A clear and concise description of what you want to happen.

```python
def _export():
    fname = 'hello.txt'
    text = "hello"
    with open(fname, 'w') as f:
        f.write(text)
    return fname

with gr.Blocks() as demo:
    download_btn = gr.DownloadButton("Export chat history")
    download_btn.click(_export, [], [download_btn])
demo.queue().launch(server_name='0.0.0.0')
```

Something like the above code should work. When a user click the Button, a text file is generated and downloaded.

**Additional context**  
Add any other context or screenshots about the feature request here.
Ambiguous terms: clear, concise, like, should, something like
Questions:
1. What specific format should the exported chat history be in (JSON/HTML)?
2. Can you provide an example of what the chat history content might look like?
Clarified requirement: Add any other context or screenshots about the feature request here.


Clarify this requirement: As the span group is meant to support different groups of spans, would be more useful to enable displacy supporting other span keys at the same time?



```
import spacy
from spacy import displacy
from spacy.tokens import Span

text = "Welcome to the Bank of China."

nlp = spacy.blank("en")
doc = nlp(text)

doc.spans["dc"] = [
    Span(doc, 3, 6, "ORG")
]
doc.spans["sc"] = [
    Span(doc, 5, 6, "GPE"),
]

displacy.render(doc, style="span")
```
Ambiguous terms: supporting, useful, enable, other, more, same time
Questions:
1. What exactly is meant by "span group" in this context?
2. Can you clarify what you mean by "displacy supporting other span keys at the same time"?
Clarified requirement: "As the span group in the code is intended to support different groups of spans, it would be beneficial to have displacy support additional span keys simultaneously."


Clarify this requirement: **Description** 

Build a custom component to:

1. identify coordinations in a document
2. split the coordinations
3. return a new `Doc` object with the split coordinations
Ambiguous terms: identify, split
Questions:
1. Can you provide more details on what is meant by "coordinations" in this context?
2. How should the component handle splitting the coordinations?
Clarified requirement: 3. return a new `Doc` object with the split coordinations


Clarify this requirement: First of all, thank you for maintaining a well type annotated library. It's a joy to use!

This bug is a minor issue when using spacy with `mypy --no-implicit-reexport`. I do not know if you care about `--no-implicit-reexport`, so feel free to ignore if you don't.

**Brief explanation of the switch (in case):** mypy's --no-implicit-reexport allows modules to be more specific about what in its namespace is part of the public API. Using it, by default, a module doing `from foo import X` does not, for type checking purposes, export the symbol `X` to importing modules, i.e. the import is assumed to be private by default. I believe the canonical way to explicitly reexport an imported symbol is the slightly funny looking `from thinc.api import prefer_gpu as prefer_gpu`.

## How to reproduce the behaviour

1. Install mypy 1.8.0
2. Create a file `bug.py` with the contents

```python
import spacy

spacy.prefer_gpu()
```

3. run `mypy --strict --no-implicit-reexport bug.py`

**Expected outcome:**

There are no errors from mypy.

**Actual outcome:**

mypy reports

`bug.py:3: error: Module "spacy" does not explicitly export attribute "prefer_gpu"  [attr-defined]`

## Info about spaCy

- **spaCy version:** 3.7.2
- **Platform:** Linux-6.2.0-1018-lowlatency-x86_64-with-glibc2.37
- **Python version:** 3.11.4
- **mypy version:** 1.8.0
Ambiguous terms: minor, more specific, slightly funny looking, canonical, expected, actual
Questions:
1. What specific behavior is considered a bug when using spacy with `mypy --no-implicit-reexport`?
2. Can you clarify the expected outcome when running `mypy --strict --no-implicit-reexport bug.py`?
Clarified requirement: Thank you for maintaining a well type annotated library. The bug occurs when using spacy with `mypy --no-implicit-reexport`. To reproduce the behavior, install mypy 1.8.0, create a file `bug.py` with specific contents, and run `mypy --strict --no-implicit-reexport bug.py`. The expected outcome is no errors from mypy.


Clarify this requirement: ### Discussed in https://github.com/explosion/spaCy/discussions/13036

<div type='discussions-op-text'>

<sup>Originally posted by **sztal** October  2, 2023</sup>
Hi!

First, thanks for all the great work at Explosion! I wonder whether there are any plans for implementing the extension attribute mechanism for span groups? 

Span groups seem to be opening some very interesting possibilities for modeling text at the level between tokens and sentences, so being able to enhance them with additional methods would be super useful.</div>
Ambiguous terms: interesting, additional, super useful
Questions:
1. What is the extension attribute mechanism for span groups?
2. Can you provide examples of the additional methods that could enhance span groups?
Clarified requirement: Discuss plans for implementing the extension attribute mechanism for span groups and how additional methods could enhance span groups for modeling text between tokens and sentences.


Clarify this requirement: Even though [TPL_ENT](https://github.com/explosion/spaCy/blob/master/spacy/displacy/templates.py#L51) can be overridden using `template` option of a renderer there is no way to override [TPL_ENTS](https://github.com/explosion/spaCy/blob/2d4fb94ba0a23523cc9adb65e0dcf92bbf6177b6/spacy/displacy/templates.py#L46) template which might be useful in some cases. I believe it is valid for other renderes as well, not only for `EntityRenderer`.
Ambiguous terms: useful, some cases, valid, other renderers, believe
Questions:
1. What does it mean for a template to be "overridden" in this context?
2. Can you clarify what you mean by "useful" and "valid" in this requirement?
Clarified requirement: Even though [TPL_ENT](https://github.com/explosion/spaCy/blob/master/spacy/displacy/templates.py#L51) can be replaced with a custom template using the `template` option of a renderer, there is currently no way to replace the [TPL_ENTS](https://github.com/explosion/spaCy/blob/2d4fb94ba0a23523cc9adb65e0dcf92bbf6177b6/spacy/displacy/templates.py#L46) template. This functionality could be beneficial in various scenarios and should be applicable to other renderers besides just the `EntityRenderer`.


Clarify this requirement: At the time of writing it is not possible to seamlessly access the prediction scores for an Entity Linking model (spaCy 3.4). This impacts the ability to conduct misclassification analyses, improve model results or implement user specific thresholds/heuristics.

Ideally, all scores should be stored and available across viable KB candidates for any one mention (rather than e.g. just the top score) for at least the previous/current epochs, as well as during prediction with a trained model. This should also be compatible with bespoke candidate generation functions. 

If the suggestion is implemented it might be useful to include some config parameters to turn the feature off (e.g. to avoid memory restraints). It would also be helpful if the documentation was updated, and if the tutorial code ([nel notebook](https://github.com/explosion/projects/blob/v3/tutorials/nel_emerson/notebooks/notebook_video.ipynb)) was extended to include this or other major updates to the NEL pipeline.


Thank you
Ambiguous terms: seamlessly, viable, bespoke, useful, updated, major
Questions:
1. What specific prediction scores are being referred to for the Entity Linking model?
2. Can you clarify what is meant by "compatible with bespoke candidate generation functions"?
Clarified requirement: At the time of writing, there is a need to access and store all prediction scores for an Entity Linking model (spaCy 3.4). This is essential for conducting misclassification analyses, improving model results, and implementing user-specific thresholds or heuristics. The stored scores should be available for all Knowledge Base candidates related to a mention, not just the top score, for the previous/current epochs and during prediction with a trained model. Additionally, the system should support bespoke candidate generation functions. To manage memory restraints, there should be configuration parameters to enable/disable this feature. It is also requested that the documentation be updated and the tutorial code in the NEL notebook extended to cover these updates.


Clarify this requirement: I recently started a new spaCy project and decided not to create a separate Python module with all the custom code. While I can pass a comma-separated list of code paths to the [spacy package](https://spacy.io/api/cli#package) command, other CLI commands such as [spacy train](https://spacy.io/api/cli#train) and [spacy assemble](https://spacy.io/api/cli#assemble) only accept a single value for the `--code` option. This makes it impossible to build a project with more than one code file, even though it's possible to assemble one with multiple files.

It would be really helpful if all the spaCy CLI commands accepted a comma-separated list for the `--code` option. Otherwise, all the code has to be stuffed into a single file.

The `--code` option exists in the following commands:

* [debug](https://spacy.io/api/cli#debug)
* [train](https://spacy.io/api/cli#train)
* [pretrain](https://spacy.io/api/cli#pretrain)
* [evaluate](https://spacy.io/api/cli#evaluate)
* [assemble](https://spacy.io/api/cli#assemble)
* [package](https://spacy.io/api/cli#package) (accepts comma-separated list)

## How to reproduce the behaviour

**OK**:

```sh
spacy package --code file_a.py,file_b.py …
```

The comma-separated value to the `--code` option is split and all the code files are loaded ([package.py#L48](https://github.com/explosion/spaCy/blob/18ffe5bbd6a554920107ff48d1387df34c3f872a/spacy/cli/package.py#L48)).

**Not OK**:

```sh
spacy assemble --code file_a.py,file_b.py …

Path to Python code not found
```

The comma-separated value to the `--code` option is used as the literal path, which fails to load ([assemble.py#L41](https://github.com/explosion/spaCy/blob/18ffe5bbd6a554920107ff48d1387df34c3f872a/spacy/cli/assemble.py#L41)).

## Your Environment

* Operating System: macOS Ventura 13.1 (22C65)
* Python Version Used: 3.10.9
* spaCy Version Used: 3.4.3
* Environment Information:
Ambiguous terms: impossible, really helpful, all, stuffed, OK, Not OK, literal
Questions:
1. What specific issue arises when attempting to use multiple code files with the current spaCy CLI commands?
2. How does the current behavior differ between the `--code` option usage in the `package` command compared to other commands?
Clarified requirement: "I recently started a new spaCy project and found that while the `package` command allows for a comma-separated list of code paths to be passed to the `--code` option, other CLI commands like `train` and `assemble` only accept a single value for the `--code` option. This limitation prevents building a project with multiple code files. It is requested that all spaCy CLI commands, including `debug`, `train`, `pretrain`, `evaluate`, `assemble`, and `package`, should support accepting a comma-separated list for the `--code` option to enable using multiple code files."


Clarify this requirement: This is related to https://github.com/explosion/spaCy/discussions/8782

Currently spacy support the argument n_process, but it does not distribute the work to different GPUs. Suppose I have four GPUs on a machine, it would be nice if I could start a process with each using a different GPU, like the following code (I am not sure if it is the correct way to do it though): 
```

from joblib import Parallel, delayed
import cupy

rank = 0

def chunker(iterable, total_length, chunksize):
    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))

def flatten(list_of_lists):
    "Flatten a list of lists to a combined list"
    return [item for sublist in list_of_lists for item in sublist]

def process_chunk(texts):
    global rank
    with cupy.cuda.Device(rank):
        import spacy
        from thinc.api import set_gpu_allocator, require_gpu
        set_gpu_allocator("pytorch")
        require_gpu(rank)
        preproc_pipe = []
        for doc in nlp.pipe(texts, batch_size=20):
            preproc_pipe.append(lemmatize_pipe(doc))
        rank+=1
        return preproc_pipe

def preprocess_parallel(texts, chunksize=100):
    executor = Parallel(n_jobs=4, backend='multiprocessing', prefer="processes")
    do = delayed(process_chunk)
    tasks = (do(chunk) for chunk in chunker(texts, len(texts), chunksize=chunksize))
    result = executor(tasks)
    return flatten(result)

preprocess_parallel(texts = ["His friend Nicolas J. Smith is here with Bart Simpon and Fred."*100], chunksize=1000)
```
Ambiguous terms: nice, different, correct, not sure, fast, user-friendly
Questions:
1. What specific functionality is expected when distributing the work to different GPUs?
2. How should the process with each GPU be managed in terms of resource allocation?
Clarified requirement: The task is to modify the existing code to distribute the workload to four GPUs on a machine, ensuring that each GPU is utilized for processing a specific chunk of data, and managing resource allocation for each GPU.


Clarify this requirement: <!-- Describe the problem or suggestion here. If you've found a mistake and you know the answer, feel free to submit a pull request straight away: https://github.com/explosion/spaCy/pulls -->

Currently the evaluate CLI has fixed list of metrics which are reported as part of the evaluation output. This is limiting when one wishes to make note of other metrics/scores that are part of custom pipeline components in their evaluation outputs. My suggestions is to allow users to pass a list of metrics that they wish to add to the existing set of metrics that are part of the evaluate CLI script.

## Which page or section is this issue related to?
<!-- Please include the URL and/or source. -->

https://github.com/explosion/spaCy/blob/master/spacy/cli/evaluate.py#L79-L97
Ambiguous terms: custom, other, list, wish, add, part
Questions:
1. What specific metrics are currently included in the evaluate CLI output?
2. Can you provide an example of the custom pipeline components and metrics that users might want to add to the evaluation output?
Clarified requirement: The evaluate CLI currently includes a fixed list of metrics in its output. To allow users to include additional metrics from custom pipeline components, the suggestion is to enable users to specify a list of metrics to add to the existing set in the evaluate CLI script.


Clarify this requirement: The workflow for setting up a pipeline component in code sometimes feels a bit rough. This came up while I was investigating #6958.

Let's say we have some pipeline component that assumes its `.initialize()` method will be called before it's in a valid state, as the transformer does --- but the component doesn't necessarily need to be _trained_, as such, before it's in a functional state. We have the following:

```python

import spacy

nlp = spacy.blank("en")
transformer = nlp.add_pipe("transformer")
```

So now we need to call `transformer.initialize()`. How to do that?

* Maybe I should use `nlp.initialize()`? That does work --- but if I were adding the component in addition to _other_ components, I'll have problems, as I'll wipe their weights.
* Maybe I should use `nlp.resume_training()`? It seemed like that ought to work, even though it's not the most obvious. It doesn't though, because it doesn't call `.initialize()` on the components, as it can't know what weights that would reset.
* Okay so maybe I should call `transformer.initialize(get_examples=lambda: [], nlp=nlp)`. However, this runs into an error in `validate_get_examples`, which complains the list is empty. The component does support an empty list though.
* `transformer.initialize(nlp=nlp)`? This doesn't work, even though the docstring refers to it as an "optional `get_examples` callback".
* Okay so what I need to do is construct at least one `Example` object, so that I can return it in `get_examples`. Kind of a hassle.
* Alternatively I could be sneaky and do `transformer.model.initialize()`. This happens to work, but if the component requires other initialization it won't in this instance, so it's not a generalizable solution.

A quick improvement is to add an argument to `validate_get_examples` indicating whether the component can work with no examples. I'm not sure how to help components that do need some data though. 

Maybe some components should check whether they're initialized, and do that on first usage if necessary? It does feel dirty, though.
Ambiguous terms: rough, bit, sometimes, feels, a bit, necessarily, functional, maybe, ought to, most obvious, kind of, at least, hassle, quick, not sure, dirty
Questions:
1. What specific issues are encountered when calling `transformer.initialize()`?
2. How does the current process of initializing pipeline components affect the functionality of the components?
Clarified requirement: Improve the process of initializing pipeline components to ensure that the `.initialize()` method is called correctly and that components can function properly without the need for training.


Clarify this requirement: ## How to reproduce the behaviour
I was planning to have a look at the [example projects](https://github.com/explosion/projects/blob/v3/pipelines/tagger_parser_ud/project.yml) and quickly found that these are very Linux oriented. The commands are all Linux commands (`mv`, `mkdir`, etc.). Of course, there are ways around (WSL, other CLIs), but generally, these commands do not work well on Windows. This is not really a bug (it is expected) but I wasn't sure how to tag this differently.

Preferably, all commands in `script` are cross-platform so that they can be run on any platform. These should be able to be replaced by Python `-c` commands to ensure cross-compatibility. I am aware that these are intended as example projects, but especially for new users it would be great if these "just work" cross-platform. Something like the following should work I think (untested). 

```
python -c "from pathlib import Path; Path('corpus/${vars.treebank}').mkdir(exist_ok=True)"
python -c "from pathlib import Path; Path('corpus/${vars.treebank}/${vars.train_name}.spacy').rename('corpus/${vars.treebank}/train.spacy)'"
python -c "from pathlib import Path; Path('corpus/${vars.treebank}/${vars.dev_name}.spacy').rename('corpus/${vars.treebank}/dev.spacy)'"
python -c "from pathlib import Path; Path('corpus/${vars.treebank}/${vars.test_name}.spacy').rename('corpus/${vars.treebank}/test.spacy)'"
```

## Info about spaCy

- **spaCy version:** 3.0.1
- **Platform:** Windows-10-10.0.19041-SP0
- **Python version:** 3.8.2
Ambiguous terms: cross-platform, just work, cross-compatibility
Questions:
1. What specific platforms should the commands be compatible with?
2. Can you provide more clarity on what "just work" means in this context?
Clarified requirement: How to reproduce the behavior: Ensure that all commands in the `script` section of the example projects are compatible with Windows and can be replaced by Python `-c` commands for cross-compatibility. The goal is to make these commands work seamlessly on Windows and other specified platforms without issues.


Clarify this requirement: Would'nt usage of Mmap could really speed up data loading and reduce memory usage in multiprocess environment ?

1. In our webserver we use different process. Each process load three languages models and take a good chunk of memory !

2. While developing with Django, django constantly restart, making our object models load each time we need them (and we them a lot for some functionality). This take a while. (with mmap, main process could keep file mapped in memory)

It seems to me that :

1. the model does not move in a typical environment, so a read-only mmap access is ok
2. mmap would speed-up new process model loading (already in memory)
3. mmap would only use one image of the model (shared memory)

Maybe there are some technical difficulties (I don't know about low level representation of models in spacy) but it seems worth it if its feasible. (if it needs a specific non compressed on disk format to be able to mmap, it maybe ok however)

This feature request was already submitted https://github.com/explosion/spaCy/issues/100 but it was in the old time, I imagine it's worth thinking again ?

## Your Environment

- Operating System: Debian 10
- Python Version Used: Python 3.7
- spaCy Version Used: 2.1.3
- Environment Information:
Ambiguous terms: speed up, reduce, good chunk, a while, typical, feasible, specific, old time, worth thinking
Questions:
1. What specific challenges or bottlenecks are currently being faced in the data loading process that mmap is expected to address?
2. Can you provide more details on how the current memory usage is distributed among the different processes in the webserver?
Clarified requirement: Would using mmap significantly improve data loading speed and reduce memory usage in a multiprocess environment where different processes in the webserver load three language models each, consuming a significant amount of memory? Additionally, can you elaborate on the current memory distribution among processes and the specific issues that mmap is expected to resolve?


Clarify this requirement: With options options = {"fine_grained" : True} it is possible to render the stts-Tags under the Token visualisation. But is it also possible to visualize the stts-Tags and POS Tags with Displacy?  


## Your Environment
SpaCy nightly
<!-- Include details of your environment. If you're using spaCy 1.7+, you can also type `python -m spacy info --markdown` and copy-paste the result here.-->

- Operating System:
- Python Version Used: 3.7
- spaCy Version Used: Nightly
- Environment Information: Debian
Ambiguous terms: fine_grained, possible, visualize
Questions:
1. What does "fine_grained" specifically refer to in this context?
2. What does it mean to visualize the stts-Tags and POS Tags with Displacy?
Clarified requirement: With the option `options = {"fine_grained" : True}`, it is possible to render the stts-Tags under the Token visualization. The requirement is to determine if it is also possible to display both the stts-Tags and POS Tags using Displacy.


Clarify this requirement: ## Feature description

The [Matcher](https://spacy.io/api/matcher) supports `!`, `?`, `+`, and `*` [operators and quantifiers](https://spacy.io/usage/rule-based-matching#quantifiers). I have text where it would be useful to have something like the regex lookaround patterns, where a pattern should or should not be matched, but is not included as part of the matched range.

For example, consider the following text.

```
Haul from AB CD site to XY site.
```

I want to create patterns for `AB CD site` and `XY site` and label them as source and destination spans. The `from` and `to` tokens are needed to distinguish between `AB CD site` and `XY site`, but should not be part of the match.

```python
from spacy.lang.en import English
from spacy.matcher import Matcher

nlp = English()

m = Matcher(nlp.vocab)
m.add("from_loc", None, [{"ORTH": "from"}, {"ORTH": {"NOT_IN": ["to"]}, "OP": "+"}, {"ORTH": "site"}])
m.add("to_loc",   None, [{"ORTH": "to"}, {"ORTH": {"NOT_IN": ["from"]}, "OP": "+"}, {"ORTH": "site"}])

doc = nlp.make_doc("Haul from AB CD site to XY site.")
matches = m(doc)

for match_id, start, end in matches:
  print(doc[start:end])
```

```
from AB CD site
to XY site
```

The first match span the tokens for `from AB CD site`. I want just `AB CD site` back as the match. Same for the second match.

## Proposal

The Matcher should support the following new ops, roughly based on the regex counterparts.

| Op | Name | Description |
|---|---|---|
| `?=` | Positive lookaround | The token pattern matches, but is not part of the match result. |
| `?!` | Negative lookaround | The token pattern does not match, and is not part of the match result. |

Zero or more lookaround can be used as the start and end of the pattern. A lookaround operator cannot be surrounded on both sides by non-lookaround operators in a pattern.

While there is a distinction between lookahead and lookbehind in regex, these operators are just positive/negative matchers that are not included in the result.

```python
m = Matcher(nlp.vocab)
m.add("from_loc", None, [{"ORTH": "from", "OP": "?="}, {"ORTH": {"NOT_IN": ["to"]}, "OP": "+"}, {"ORTH": "site"}])
m.add("to_loc",   None, [{"ORTH": "to", "OP": "?="}, {"ORTH": {"NOT_IN": ["from"]}, "OP": "+"}, {"ORTH": "site"}])

doc = nlp.make_doc("Haul from AB CD site to XY site.")
matches = m(doc)

for match_id, start, end in matches:
  print(doc[start:end])
```

```
AB CD site
XY site
```

The `from` and `to` tokens are matched by not part of the match range. 

## Could the feature be a [custom component](https://spacy.io/usage/processing-pipelines#custom-components) or [spaCy plugin](https://spacy.io/universe)?

No.
Ambiguous terms: roughly, just, while
Questions:
1. What are the new ops that the proposal suggests adding to the Matcher?
2. How are the positive and negative lookaround operators defined in the context of the proposal?
Clarified requirement: The feature proposal suggests adding new ops to the Matcher, specifically `?=` for positive lookaround and `?!` for negative lookaround, which define token patterns that are not part of the match result.


Clarify this requirement: ## Feature description
<!-- Please describe the feature: Which area of the library is it related to? What specific solution would you like? -->

Similar to the token-based orthographic variants, it would be useful to add data augmentation options for character-based orthographic variants. Examples are the Romanian variants discussed in #4736 and German ß.
Ambiguous terms: useful, character-based, discussed
Questions:
1. What specific types of data augmentation options are being requested for character-based orthographic variants?
2. In what context were the Romanian variants and German ß discussed in issue #4736?
Clarified requirement: Similar to the token-based orthographic variants, the feature should include specific data augmentation options for character-based orthographic variants. Examples include the Romanian variants and German ß that were mentioned in issue #4736.


Clarify this requirement: ## How to reproduce the behaviour
I would expect the two sentences below to be tokenized the same way. However, in the second, the special cases for "won't" and "can't" do not work.

    >>> import en_core_web_sm
    >>> nlp = en_core_web_sm.load()
    >>> [token.text for token in nlp("I can't / won't tolerate that.")]
    ['I', 'ca', "n't", '/', 'wo', "n't", 'tolerate', 'that', '.']
    >>> [token.text for token in nlp("I can't/won't tolerate that.")] 
    ['I', "can't", '/', "won't", 'tolerate', 'that', '.']

## Your Environment

* **spaCy version:** 2.3.0
* **Platform:** Darwin-18.7.0-x86_64-i386-64bit
* **Python version:** 3.7.4
Ambiguous terms: special cases, work
Questions:
1. What are the special cases for "won't" and "can't" that are expected to work in the tokenization?
2. What specific behavior is expected when the special cases for "won't" and "can't" work in the tokenization?
Clarified requirement: The expectation is that when tokenizing the sentence "I can't / won't tolerate that," the special cases for "won't" and "can't" should be handled correctly, resulting in the tokens being split in a specific way.


Clarify this requirement: ## Feature description

Typically pickling in Python creates a large `bytes` object with types, functions, and data all packed in to allow easy reconstruction later. Originally pickling was focused on reading/writing to disk. However these days it is increasingly using as a serialization protocol for objects on the wire. In this case the copies of data required to put everything in a single `bytes` object hurts performance and doesn't offer much (as the data could be shipped along in separate buffers without copying).

For these reasons, Python added support for [out-of-band buffers in pickle]( https://docs.python.org/3/library/pickle.html#out-of-band-buffers ), which allows the user to flag buffers of data for pickle to extract and send alongside the typical `bytes` object (thus avoiding unneeded copying of data). This was submitted and accepted as [PEP 574]( https://www.python.org/dev/peps/pep-0574/ ) and is part of Python 3.8 (along with [a backport package for Python 3.5, 3.6, and 3.7]( https://github.com/pitrou/pickle5-backport )). On the implementation side this just comes down to implementing `__reduce_ex__` instead of `__reduce__` (basically the same with a `protocol` version argument) and placing any `bytes`-like data (like NumPy arrays and `memoryview`s) into [`PickleBuffer` objects]( https://docs.python.org/3/library/pickle.html#pickle.PickleBuffer ). For older pickle protocols this step can simply be skipped. Here's [an example]( https://docs.python.org/3/library/pickle.html#example ). The rest is on libraries using protocol 5 (like Dask) to implement and use.

## Could the feature be a [custom component](https://spacy.io/usage/processing-pipelines#custom-components) or [spaCy plugin](https://spacy.io/universe)?
If so, we will tag it as [`project idea`](https://github.com/explosion/spaCy/labels/project%20idea) so other users can take it on.

<br>

I don't think so as this relies on changing the pickle implementations of spaCy objects. Though I could be wrong :)
Ambiguous terms: fast, user-friendly, large, easy, increasingly, much, typical, needed, old, simple, rest, custom
Questions:
1. What specific changes are required in the pickle implementations of spaCy objects for this feature?
2. Are there any dependencies or compatibility issues with implementing this feature as a custom component or spaCy plugin?
Clarified requirement: The feature involves adding support for out-of-band buffers in pickle to avoid unnecessary copying of data in Python 3.8, with a backport package available for Python 3.5, 3.6, and 3.7. The implementation requires using `__reduce_ex__` instead of `__reduce__` and placing `bytes`-like data into `PickleBuffer` objects. This change impacts the pickle implementations of spaCy objects and may not be suitable for integration as a custom component or spaCy plugin.


Clarify this requirement: ## Feature description
<!-- Please describe the feature: Which area of the library is it related to? What specific solution would you like? -->

Decide how to handle `is_sentenced` and sentence boundaries that may come from multiple components (Sentencizer, SentenceRecognizer, Parser).

Some ideas:

* have an `is_sentenced` property more like `is_parsed` that can be set by components
* have a way to set finalized sentence boundaries (all 0 to -1):
  * have an extra option for each component
  * have an extra pipeline component (e.g., `finalize_sentences`?) that can be inserted at the right point in the pipeline
* also have a component that resets all sentence boundaries?
* modify Sentencizer to only set sentence starts, not all tokens?

Check that no spacy components clobber sentence boundaries and that `is_sentenced` works consistently when sentence boundaries come from multiple sources. If a component after the parser changes sentence boundaries, make sure the required tree recalculations are done (a related issue: #4497).

Potentially add warnings when non-zero `sent_start` is changed by any component?

I think the default behavior could be that any pipeline component can add sentence boundaries but that components won't remove any sentence boundaries. The idea would be that the Sentencizer or SentenceRecognizer add punctuation-based boundaries (typically high precision, although the Sentencizer less so) and the Parser can add phrase-based boundaries (improving recall). I don't know if this works as cleanly as envisioned in practice, especially with the Sentencizer. Most likely people using the Sentencizer aren't using other components so it's less of an issue, but I could imagine SentenceRecognizer + Parser as a common combination.
Ambiguous terms: potentially, some, most likely, cleanly, common
Questions:
1. What specific behavior is expected when multiple components provide sentence boundaries?
2. How should the system handle changes to sentence boundaries by components after the parser?
Clarified requirement: Decide on the handling of `is_sentenced` and sentence boundaries originating from multiple components (Sentencizer, SentenceRecognizer, Parser). This may involve implementing an `is_sentenced` property similar to `is_parsed`, allowing finalized sentence boundaries to be set uniformly, potentially introducing a pipeline component for finalizing sentences, and ensuring that no components overwrite existing sentence boundaries. Additionally, consider adding warnings for changes to non-zero `sent_start` values by components. The default behavior should allow any pipeline component to add sentence boundaries without removing any, with the Sentencizer and SentenceRecognizer focusing on punctuation-based boundaries and the Parser on phrase-based boundaries.


Clarify this requirement: Hi, I'm using Spacy 2.2.2 to train new tagger and parser models for the Italian language.
My training data set is quite big (about 2.3 GB for the train and 580 MB for the dev) and is saved in two JSONL files.
I'm experiencing an unexpected memory usage when running the `debug-data` command: memory usage starts low and then grows up to consuming my 32GB of RAM as well as the whole swap (about the same size).
Before upgrading my RAM to 128 GB (which I suspect might be useless), I'm interested in your opinion about:
* hints about data set structure: for instance, comments in issue #4700 suggested to reduce the sentence length on average, but I've no clue about what values might be optimal; is there any rule of thumb to properly dimension the data set?
* possible optimizations to the source code to reduce memory footprint (for instance by improving the lazy loading of the data set); I'm willing to contribute to Spacy if anyone would kindly point me to the problematic parts (if any, of course)

## Info about spaCy

* **spaCy version:** 2.2.2
* **Platform:** Linux-4.4.0-112-generic-x86_64-with-debian-stretch-sid
* **Python version:** 3.7.4
Ambiguous terms: big, low, optimal, properly, possible, improving, kindly
Questions:
1. What specific values are considered "low" and "big" in terms of memory usage?
2. What exactly is meant by "properly dimension the data set"?
Clarified requirement: Using Spacy 2.2.2 to train tagger and parser models for Italian with a large training dataset (2.3 GB for train, 580 MB for dev) saved in JSONL files. Experiencing memory usage issues during `debug-data` command, with RAM and swap fully consumed. Seeking advice on optimal data set structure (e.g., sentence length) and code optimizations to reduce memory footprint. Interested in contributing to Spacy for identified issues.


Clarify this requirement: ## How to reproduce the behaviour

    import spacy
    nlp = spacy.load('de')
    s1 = 'Der schöne Garten'                                                                                                                                                             
    doc = nlp(s1)                                                                                                                                                                        
    [(t, t.lemma_) for t in doc]                                                                                                                                                         
     >> [(Der, 'der'), (schöne, 'schöne'), (Garten, 'Garten')]

    s2 = 'Ein schöner Garten'  
    doc = nlp(s2)                                                                                                                                                                        
    [(t, t.lemma_) for t in doc]                                                                                                                                                         
    >> [(Ein, 'Ein'), (schöner, 'schön'), (Garten, 'Garten')]


## My Environment

* **spaCy version:** 2.2.2
* **Platform:** Linux-5.0.0-25-generic-x86_64-with-LinuxMint-19.2-tina
* **Python version:** 3.6.7
* **Models:** de

## Reason

As far as I can see, all forms of German adjectives ending on `e` in  `spacy-lookups-data/spacy_lookups_data/data/de_lemma_lookup.json` are capitalized, e.g.: 

    "Dekorative": "dekorativ",
    "Weiße": "Weiß",
    "Schöne": "Schönes",
Ambiguous terms: beautiful, capitalized
Questions:
1. What specific behavior or issue are you trying to reproduce?
2. Are you looking to verify the lemma lookup behavior for German adjectives ending in 'e' in spaCy?
Clarified requirement: The goal is to reproduce and verify the lemma lookup behavior for German adjectives ending in 'e' in spaCy, specifically focusing on how they are capitalized in the lookup data file.


Clarify this requirement: feature request:

Sentencepiece is the tokenizer used in XLNet.   
I think if `Language` tokenize text with `sentencepiece`, the alignment process can be skipped and it make model efficient.
Ambiguous terms: efficient
Questions:
1. What specific aspect of the model's efficiency would be improved by skipping the alignment process?
2. Can you clarify what you mean by the "alignment process" in the context of tokenizing text with `sentencepiece`?
Clarified requirement: Feature request: When `Language` tokenizes text with `sentencepiece`, skipping the alignment process should improve the efficiency of the model.


Clarify this requirement: I want to customize `Doc.tensor` property by `user_hooks` like `Doc.vector`, because sometimes calculation of the tensor is expensive (e.g. [tok2vec pipe in spacy-transformers](https://github.com/explosion/spacy-transformers/blob/378d6aa9c33acaf8970e607733b85f83bf8a61f5/spacy_transformers/pipeline/tok2vec.py#L197))
Ambiguous terms: customize, expensive
Questions:
1. What specific customizations does the user want to apply to the `Doc.tensor` property?
2. Can the user provide examples of the type of expensive calculations involved in the tensor calculation?
Clarified requirement: The user wants to apply customizations to the `Doc.tensor` property using `user_hooks` similar to `Doc.vector`, as the calculation of the tensor can be computationally expensive.


Clarify this requirement: ## Feature description

Here is the background: in order to use a spacy document it is necessary to have the correct Vocab/StringStore. But when documents are created/processed in a distributed/multiprocessing way, different subsets of documents will get processed, linked to the vocab of the process's 
vocab (in nlp). In order to save a processed document efficiently, one uses "to_disk" to save it without the vocab. 
When resuming processing or just when one wants to load the document later, a vocab is needed that has all the entries from all the parallel processes combined in order to ensure the document can be deserialised.


## Could the feature be a custom component

I do not think so.
Ambiguous terms: efficiently, later
Questions:
1. What does "efficiently" mean in the context of saving a processed document?
2. Can you clarify what "later" refers to when mentioning loading the document?
Clarified requirement: I do not think so.


Clarify this requirement: ## Feature description

The parser section of `spacy debug-data` should show a warning when there are no/few documents with multiple sentences in the training data.

Potentially add a simple converter to `spacy convert` to group sentences, similar to `-n` with the IOB converters. A bit of variety in document lengths is probably a good idea here, too, rather than just `-n N`, but I don't know if it makes that much difference in the model performance.
Ambiguous terms: few, simple, similar, bit of variety, probably, good idea, much difference
Questions:
1. What is considered "few" documents with multiple sentences in the training data?
2. Can you clarify what is meant by "a bit of variety in document lengths"?
Clarified requirement: The parser section of `spacy debug-data` should display a warning when there are a small number of documents with multiple sentences in the training data. Additionally, consider adding a straightforward converter to `spacy convert` for grouping sentences, similar to the `-n` option in the IOB converters. It is suggested to introduce some diversity in document lengths, rather than just specifying a fixed number with `-n N`, although the impact on model performance is uncertain.


Clarify this requirement: Hi! 

Is it possible to define a custom loss function when training spacy's transformers? Specifically, I'm asking because the classes in my dataset are imbalanced, and I'd like to weight each class differently. In pytorch, you could define a weight for each class in various loss functions, such as `nn.CrossEntropyLoss(weight=...)` 

How would that work in spacy-transformers?

Thanks in advance for your answer! :-)

Cheers,
Felix
Ambiguous terms: custom, weight differently, various
Questions:
1. What specific type of custom loss function are you looking to define?
2. How do you want to weight each class differently in the custom loss function?
Clarified requirement: Hi! Is it possible to define a custom loss function when training spacy's transformers in a way that allows for weighting each class differently based on specific criteria? Specifically, I'm asking because the classes in my dataset are imbalanced, and I'd like to assign different weights to each class in the loss function. In pytorch, you could define a weight for each class in various loss functions, such as `nn.CrossEntropyLoss(weight=...)`. How would that functionality work in spacy-transformers?


Clarify this requirement: The new Entity Linking code has not been tested/adapted to GPU yet, cf Matt's comment [here](https://github.com/explosion/spaCy/pull/3864#issuecomment-504370194).
Ambiguous terms: tested/adapted, GPU
Questions:
1. What does "tested/adapted" specifically refer to in the context of the Entity Linking code?
2. Can you clarify what is meant by "GPU" and how it relates to the Entity Linking code?
Clarified requirement: The new Entity Linking code needs to be tested and optimized for GPU usage as per Matt's comment [here](https://github.com/explosion/spaCy/pull/3864#issuecomment-504370194).


Clarify this requirement: Hi 
Thansk for this nice work. @honnibal I am interested to use any of the pre-trained language model to calculate Perplexity score of a sentence.  Is there any way to achieve that using this repo?

Thanks
Ambiguous terms: nice, interested, any, pre-trained, calculate, Perplexity score, sentence, achieve
Questions:
1. What specific language models are available in the repository?
2. What do you mean by "achieve" in this context?
Clarified requirement: Utilize any of the language models available in the repository to calculate the Perplexity score of a sentence.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:
Add support of the prompt template syntax for prompt fragments ({{prompt:<fragmentName>}}) to also be usable in the chat. This feature will remove any confusion about the usage between prompt templates and the chat. Moreover, this will provide the flexibility to have a single button for copying a prompt fragment to both the chat and prompt template in the MCP config view, which was changed in https://github.com/eclipse-theia/theia/pull/15364.

- [ ] Allow prompt template syntax to be used in chat
- [ ] Make single button in config view
Ambiguous terms: clear, relevant, confusion, flexibility, single
Questions:
1. What is the prompt template syntax for prompt fragments?
2. How is the chat currently different from prompt templates?
Clarified requirement: Add support for using the prompt template syntax ({{prompt:<fragmentName>}}) in the chat, allowing users to easily copy prompt fragments to both the chat and prompt templates in the MCP config view with a single button. This change will align the usage of prompt templates and the chat interface, as well as simplify the copying process for users.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:
The proposal is to introduce workspace specific user settings. This would involve settings defined in the user's home folder, but are only activated for a specific workspace or folder. This feature is already present when using workspace files and the workspace settings are added to the workspace file. However, we might want to support the situation where the user merely has a folder open, and not force the user to use a workspace file.

The need for these settings stems from scenarios where there could be certain settings (examples include tokens, pythonPaths, etc.) that a user wants to be specific to a folder, but not added to the folder settings ((.vscode/.theia)/setttings.json) as they may be customized to the user's setup or even private.

On a similar note, it is suggested that we should consider splitting the workspace/folder features more clearly, as their current setup could confuse users. For instance, in the settings view, the folder settings ((.vscode/.theia)/setttings.json) are displayed under the tab workspace when only a folder is open, but under folder when a workspace is open.

This idea may need another issue to discuss it, but the points to be discussed in this issue are dependent on the outcome of this. The main ponder here is whether we want to encourage users to open a folder or if we want them to primarily use a workspace.
Ambiguous terms: specific, certain, customized, private, more clearly, confuse, encourage, primarily
Questions:
1. Can you provide examples of the specific settings that users might want to define for a workspace or folder?
2. How would the proposed feature impact the user experience in terms of managing these settings?
Clarified requirement: The proposal is to introduce workspace specific user settings to allow users to define settings in their home folder that are only activated for a specific workspace or folder. This feature aims to address scenarios where users may need settings like tokens or pythonPaths to be specific to a folder without adding them to the folder settings file. Additionally, there is a suggestion to clarify the distinction between workspace and folder features to avoid confusion for users. The main consideration is whether to prioritize users opening a folder or using a workspace.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:
Currently, all MCP Tool calls are accessible and need to be added manually to prompt templates. Users should have the ability to control which tool calls are available, ask for confirmations before executing certain calls, and be more confident working with MCP server.

- In the MCP config view, there can be an option field to allow/disallow certain tool calls.
- Introduce the following options for tool calls:
  1. allowed: tool call can be executed anytime.
  2. onConfirmation: the tool call needs to be confirmed before its being run (this should probably be the default).
  3. disallowed: never run this tool call, do not show it in auto-completion, etc.
  We can utilize the shortcut to add all the tool calls to the prompt template, as added with https://github.com/eclipse-theia/theia/pull/15270. Similarly, the MCP config view introduced in https://github.com/eclipse-theia/theia/pull/15280 can be used to incorporate these changes.

Bear in mind, this will likely require reworks to the tool invocation mechanism but it would also enable the reuse of the same approach for internal tools if desired.
Ambiguous terms: control, more confident, certain, introduce, probably, never, etc., likely, reworks, enable, desired
Questions:
1. What specific tool calls are currently accessible and need to be added manually to prompt templates?
2. How will users interact with the option field in the MCP config view to allow/disallow certain tool calls?
Clarified requirement: The feature request is to enhance the MCP Tool functionality by allowing users to control which tool calls are available. This can be achieved by introducing options for tool calls such as allowing them to be executed anytime, requiring confirmation before execution, or disallowing them entirely. This feature should be accessible through an option field in the MCP config view, enabling users to customize their tool call preferences. Additionally, the implementation may require adjustments to the tool invocation mechanism to support these changes.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:
We should establish comprehensive guidelines for the usage of z-index values across our project to ensure consistency and maintainability. The goal is to create a clear mapping of z-index ranges for different UI components. So as an example (list to be extended and adjusted):

Base Layer: 0-100
Side Panels: 500-600
Modal Dialogs: 700-800
Menus: 800-900
Hover Elements: 1000+

Additionally, we need to consider z-index values from third-party libraries, such as the Monaco Editor, to prevent conflicts, by either overwriting them or cosnidering their values as given.

TODO:

- [ ] Propose and finalize z-index ranges: Collaborate on determining specific ranges for different UI components.
- [ ] Establish as variables: Implement these z-index values as variables (possibly in a CSS/SCSS file) so they can be reused throughout the application, allowing for easier adjustments.
- [ ] Review existing z-index usages: Create a pull request to adjust all current z-index values according to the new guidelines, ensuring we identify any components that might have inappropriate default values.

Please share your suggestions or additional z-index ranges you think are necessary!
Ambiguous terms: comprehensive, clear, specific, appropriate, necessary
Questions:
1. What is meant by "considering z-index values from third-party libraries as given"?
2. Can you provide an example of how z-index ranges for different UI components might be adjusted based on the guidelines?
Clarified requirement: Define clear z-index ranges for different UI components in the project, establish them as variables for reuse, review and adjust existing z-index values accordingly, and consider z-index values from third-party libraries without conflicts.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:

In VSCode, we can adjust the position of the `Activity bar` (for accessibility and/or preference reasons):

![activitybar-position](https://github.com/user-attachments/assets/5c4c1331-7163-437a-b855-8dc16dfaf463)


Please add this kind of setting in the Eclipse Theia `Activity Bar` as well. Actually, it is very inflexible to stick to only one position. It should be possible to set it at the `top`, `right`, `left` (default) or `bottom`.
Ambiguous terms: clear, adjust, possible, top, right, left, default, bottom
Questions:
1. What specific options for positioning are currently available in the Eclipse Theia `Activity Bar`?
2. Can you clarify what you mean by "inflexible" in the context of the current positioning of the `Activity Bar` in Eclipse Theia?
Clarified requirement: Please add settings in the Eclipse Theia `Activity Bar` that allow users to adjust the position to the `top`, `right`, `left` (current default), or `bottom`, similar to how it can be done in VSCode.


Clarify this requirement: ### Feature Description

**Problems:**

1. **Workspace-Specific Layouts:**  
   Currently, layouts are tied to individual workspaces, requiring manual adjustments for each workspace. This process is repetitive and inefficient when trying to maintain uniformity.

2. **No Default Layout Option:**  
   There is no mechanism to define or save a default layout that can be:
   - Automatically applied to new workspaces.
   - Easily updated across existing workspaces to match a preferred layout.

This makes managing layouts across multiple workspaces cumbersome and time-consuming.

---

**Ideas:**

1. **Unified Layout System:**  
   Introduce a unified layout that applies globally across all workspaces. This simplifies maintenance and ensures consistency across workspaces with minimal effort, but lacks the ablity to have a layout per workspace.

2. **Toggle Between Global and Workspace-Specific Layouts:**  
   Provide a setting that lets users choose between:
   - A global layout applied universally.
   - Workspace-specific layouts for custom configurations.  
   *(Note: Workspace-specific layouts still have the same issues mentioned above.)*

3. **Save and Apply Layouts:**  
   Add functionality to:
   - Save layouts and apply them to selected workspaces as needed.
   - Support a default layout that is:
     - Automatically applied to new workspaces.
     - Optionally used to update existing workspaces.

The ideal solution probably is somewhere in the middle or something i haven't thought about so input is very much appreciated.
Ambiguous terms: global, workspace-specific, uniformity, preferred, cumbersome, time-consuming, minimal, custom, ideal
Questions:
1. What specific characteristics differentiate a "global" layout from a "workspace-specific" layout?
2. Can you provide examples of what would constitute a "preferred layout" in this context?
Clarified requirement: The ideal solution probably is somewhere in the middle or something I haven't thought about so input is very much appreciated.


Clarify this requirement: <!-- Please fill out the following content for a feature request. -->

<!-- Please provide a clear description of the feature and any relevant information. -->
### Feature Description:

The settings page (User, Workspace) can be very overwhelming and searching for user-made settings can be tedious. It would be nice to add a `hint`(= badge) next to the settings group title showing the number of custom settings:

![Screenshot at Dec 02 10-54-44](https://github.com/user-attachments/assets/95570764-649d-49bb-b39e-bc4a5ca71244)

This `hint` may also be a "link hint", i.e. if you click on it, only the settings of the group that are currently adjusted (i.e. differ from the default settings) are displayed.
Ambiguous terms: overwhelming, nice, custom, tedious, number, link hint, adjusted, default settings
Questions:
1. What is meant by "custom settings" in this context?
2. Can you clarify what is meant by "link hint" and "adjusted" settings?
Clarified requirement: The settings page (User, Workspace) should display a badge next to the settings group title indicating the number of user-made settings. Clicking on this badge should show only the settings that differ from the default settings in the group.


Clarify this requirement: ### Feature Description:

In VS Code, I can view extensions and select "Add to Workspace Recommendations" to quickly add the extension ID to my `.vscode/extensions.json` file. This is a great QoL feature as extension IDs are often a bit awkward to find otherwise. It also easily ensures I don't accidentally add duplicate values.

Similarly, extensions already added to `extensions.json` have a "Remove from Workspace Recommendations" context menu item, which feels valuable for completeness.

![add to workspace](https://github.com/user-attachments/assets/b5208e76-52cf-40ae-9e81-d1c1a28fbca8)

![remove from workspace](https://github.com/user-attachments/assets/b4db1b7b-fc7d-447b-a1ad-ad3f48111e24)
Ambiguous terms: quickly, great, awkward, easily, valuable, completeness
Questions:
1. What does "QoL" stand for in the context of this requirement?
2. Can you clarify what is meant by "completeness" in the context of the "Remove from Workspace Recommendations" feature?
Clarified requirement: Feature Description: In VS Code, users can easily manage extensions by adding or removing them from the `.vscode/extensions.json` file using the "Add to Workspace Recommendations" and "Remove from Workspace Recommendations" options respectively. This feature helps users avoid duplicate values and ensures a seamless extension management process.


Clarify this requirement: Add options to sync configurations settings (Fonts, themes, extensions, for example)
Ambiguous terms: options, sync, configurations, settings, Fonts, themes, extensions, for example
Questions:
1. What specific options are expected to be added for syncing configuration settings?
2. Are there any specific requirements for how Fonts, themes, and extensions should be synced?
Clarified requirement: Add specific options for syncing configuration settings such as Fonts, themes, and extensions.


Clarify this requirement: > Link to the discussion thread: https://features.jellyfin.org/posts/3282.

Copy pasting the description here as well:

At the time of writing this feature request, there are 27 country wise ratings availabe here in master branch: https://github.com/jellyfin/jellyfin/tree/master/Emby.Server.Implementations/Localization/Ratings.

I am from India and recently faced problem related to parental control, realized the root cause is that Indian rating system are not supported yet by jellyfin.

TMDB has an API for the same with meaning of each rating, and this API currently has 52 countries: https://developer.themoviedb.org/reference/certification-movie-list

I am willing to contribute to all the remaining countries here!
Ambiguous terms: fast, user-friendly
Questions:
1. What specific feature or functionality is being requested in relation to the country-wise ratings?
2. How does the user plan to contribute to adding support for the remaining countries?
Clarified requirement: The user is requesting support for Indian rating systems in Jellyfin, and is willing to contribute to adding support for all remaining countries listed in the TMDB API for movie certifications.


Clarify this requirement: Currently, by default, popular tools such as [Restic] will happily back up the cache folder. I propose to implement the [Cachedir] RFC to avoid this issue out of the box.
It would involve simply creating the textfile in the cache directory marking it for exclusion from backups.

[Restic]: https://restic.net/
[Cachedir]: https://bford.info/cachedir/
Ambiguous terms: simply, avoid this issue, out of the box
Questions:
1. What does the term "simply" refer to in this context?
2. Can you clarify what is meant by "out of the box" in this proposal?
Clarified requirement: Currently, popular tools such as Restic will back up the cache folder by default. The proposal is to implement the Cachedir RFC to address this issue. This would involve creating a text file in the cache directory to mark it for exclusion from backups.


Clarify this requirement: ### This issue respects the following points:

- [x] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [x] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [x] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [x] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [x] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

When adding new series/movies to the libraries, the automated choice for primary pictures is always the worst.
It uses "Unrated" pictures that aren't as good as others, that also have a ranking.
The same can be seen, when you "edit the pictures" via the three-dot menu.

Two examples:
![Image](https://github.com/user-attachments/assets/4451b0b8-0416-4cd0-baab-ddc7df7664d3)

![Image](https://github.com/user-attachments/assets/2dad5c54-43d5-44c7-ab14-15087a090c10)

You can see, that the first pics in the row have a rating of "Unrated" or at least a lower rating and the better ones (with rating 8.0) are later on in the list - so they aren't used in the first place.

It seems to work just fine on logos, thumbnais and backgrounds.

It also should consider the language of the user (in my case 'de').
So the order should be:
- highest rated to lowest rated in the current language
- highest rated to lowest rated in the default or unknown language (perhaps always consider 'en', because most of the stuff is 'en')
- Unrated  in the current language
- Unrated  in the default or unknown language

### Reproduction steps

1. go to your library (movies or series)
2. use the three-dot menu on an item
3. "edit pictures"
4. click on the search icon below "primary" picture

### What is the current _bug_ behavior?

==> no particularly order of the pictures, so the first one, that is taken, can be the worst...

### What is the expected _correct_ behavior?

The best rated primary picture (in the current language) should be first in list and automatically used when a new series/movie is found in the library.

### Jellyfin Server version

10.10.0+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

10.10.3.0

### Specify the build version

 10.10.3

### Environment

```markdown
- OS: Debian GNU/Linux 12 (bookworm)
- Linux Kernel: Linux rpi4-1 6.1.21-v8+ #1642 SMP PREEMPT Mon Apr  3 17:24:16 BST 2023 aarch64 GNU/Linux
- Virtualization: none
- Clients: Web, Kodi on nVIDIA Shield
- Browser: Chrome, always updated
- FFmpeg Version: ffmpeg version 7.0.2-Jellyfin Copyright (c) 2000-2024 the FFmpeg developers
- Playback Method: native
```

### Jellyfin logs

```shell
Nothing in the logs for that issue.
I can provide logs, when it makes sense (extra debug logs) - just need to know how to produce them.
```

### FFmpeg logs

```shell

```

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

_No response_
Ambiguous terms: best, worst, consider, should, always, perhaps, just fine, current, correct, expected
Questions:
1. What specific criteria define the "best" and "worst" primary pictures in this context?
2. Can you clarify what is meant by considering the language of the user in determining the order of pictures?
Clarified requirement: This bug report addresses the issue where the automated choice for primary pictures when adding new series/movies to libraries does not prioritize the highest rated pictures in the user's language. The expected behavior is for the best rated primary picture in the current language to be first in the list and automatically used for new series/movies.


Clarify this requirement: ### Description of the bug

Cast info from metadata xml file is not picked up by Jellyfin.

The file is a download from youtube. The metadata was added with Subler app for macOS.

<details>
  <summary>ffprobe</summary>


ffprobe version 7.1 Copyright (c) 2007-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x1427064b0] stream 0, timescale not set
Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'no_cast.mp4':
  Metadata:
    major_brand     : mp42
    minor_version   : 512
    compatible_brands: isomiso2avc1mp41
    title           : Young Jazz Giants - Newport a Paris
    artist          : Young Jazz Giants
    comment         : https://www.youtube.com/watch?v=DwHcotVfoeA
    genre           : Jazz
    date            : 1973
    description     :  'Young Jazz Giants' at Newport a Paris Festival 1973. 
    encoder         : Lavf58.39.101
    iTunMOVI        : <?xml version="1.0" encoding="UTF-8"?>
                    : <!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
                    : <plist version="1.0">
                    : <dict>
                    : 	<key>cast</key>
                    : 	<array>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Joe Henderson</string>
                    : 		</dict>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Jimmy Owens</string>
                    : 		</dict>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Gary Burton</string>
                    : 		</dict>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Cedar Walton</string>
                    : 		</dict>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Larry Ridley</string>
                    : 		</dict>
                    : 		<dict>
                    : 			<key>name</key>
                    : 			<string>Roy Haynes</string>
                    : 		</dict>
                    : 	</array>
                    : </dict>
                    : </plist>
                    : 
  Duration: 00:27:24.07, start: 0.000000, bitrate: 777 kb/s
  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 640x480 [SAR 1:1 DAR 4:3], 643 kb/s, 25 fps, 25 tbr, 12800 tbn (default)
      Metadata:
        handler_name    : ISO Media file produced by Google Inc.
        vendor_id       : [0][0][0][0]
  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)
      Metadata:
        handler_name    : ISO Media file produced by Google Inc.
        vendor_id       : [0][0][0][0]
  Stream #0:2[0x0]: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 480x360 [SAR 1:1 DAR 4:3], 90k tbr, 90k tbn (attached pic)


</details>

The file is here (30 days):
https://upload.disroot.org/r/bGGAXTv5#FRzAyyKu4SBvFc6+MVXvrHwC+OUHoUINhCoRQsL/bxs=

### Reproduction steps

Add file to library folder, wait for jellyfin to pick up on it.

### What is the current _bug_ behavior?

A few elements do show:

- Artwort or cover
- Description

Other info is missing:

- Cast
- Genre

### What is the expected _correct_ behavior?

Not sure what's missing for Jellyfin to pick up on all of the metadata information. Would be great to have Cast and Genre show as well.

### Jellyfin Server version

10.10.0+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

_No response_

### Specify the build version

10.10.3

### Environment

```markdown
- OS: Synology NAS, Docker Setup
- Browser: Firefox 133
- FFmpeg Version: 7.0.2-1
```

### Jellyfin logs

```shell
[2024-12-07 00:25:14.626 +01:00] [INF] [55] Emby.Server.Implementations.IO.LibraryMonitor: "Young Jazz Giants - Newport a Paris" ("/drive/folder/Young Jazz Giants - Newport a Paris (1973) (480p H264 128kbit AAC).mp4") will be refreshed.
[2024-12-07 00:25:23.336 +01:00] [INF] [55] MediaBrowser.MediaEncoding.Encoder.MediaEncoder: Starting "/usr/lib/jellyfin-ffmpeg/ffprobe" with args "-analyzeduration 200M -probesize 1G -i file:\"/drive/folder/Young Jazz Giants - Newport a Paris (1973) (480p H264 128kbit AAC).mp4\" -threads 0 -v warning -print_format json -show_streams -show_chapters -show_format"
```

### FFmpeg logs

```shell

```

### Client / Browser logs

_No response_

### Relevant screenshots or videos

![Image](https://github.com/user-attachments/assets/4d12480e-207f-4890-9869-5f78d8b5f86d)

### Additional information

_No response_
Ambiguous terms: missing, great
Questions:
1. What specific metadata information is considered "missing" by Jellyfin?
2. Can you clarify what you mean by "great to have Cast and Genre show as well"?
Clarified requirement: _No


Clarify this requirement: ### This issue respects the following points:

- [x] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [x] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [x] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [x] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [x] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

When adding an album to a playlist, the tracks are sorted by ItemIDs rather than track numbers, resulting in an apparent random ordering.

### Reproduction steps

1. Add an album to a playlist.

### What is the current _bug_ behavior?

Tracks from album added to playlists are in an apparent random order.

### What is the expected _correct_ behavior?

Tracks should be added to playlist in album order, sorted by track numbers.

### Jellyfin Server version

10.10.0+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

_No response_

### Specify the build version

10.10.3

### Environment

```markdown
- OS: Debian 
- Linux Kernel: 6.6.51
- Virtualization: none
- Clients: Android
- Browser: n/a
```

### Jellyfin logs

```shell
N/A
```

### FFmpeg logs

```shell

```

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

As discussed in Jellyfin Forums here: [https://forum.jellyfin.org/t-album-tracks-shuffle-when-added-to-playlists](https://forum.jellyfin.org/t-album-tracks-shuffle-when-added-to-playlists)
Ambiguous terms: bug, random, apparent, correct, expected
Questions:
1. What is meant by "apparent random ordering" in the bug description?
2. Can you clarify the distinction between the terms "correct behavior" and "expected behavior"?
Clarified requirement: As discussed in Jellyfin Forums here: [https://forum.jellyfin.org/t-album-tr


Clarify this requirement: ### This issue respects the following points:

- [X] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [X] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [X] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [X] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [X] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

I renamed several of my files (namely the Star Wars movies (episodes 1 through 9). They were previously in a collection named "Star Wars", but since renaming them, rescanning, and re-adding the new instances of the movies to the collection, whenever I browse to the "Collections" page, I get the following errors referencing their **old** names:

```
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 3 - Revenge of the Sith (2005).1080p.bluray.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 6 - Return of the Jedi (1983).1080p.bluray.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 1 - The Phantom Menace (1999).1080p.bluray.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 7 - The Force Awakens (2015).1080p.bluray.x264.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 5 - The Empire Strikes Back (1980).1080p.bluray.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 9 - The Rise of Skywalker.2020.1080p.web-dl.x264.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 4 - A New Hope (1977).1080p.bluray.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 8 - The Last Jedi (2017).1080p.bluray.x264.mkv
app_1  | [21:56:16] [WRN] [145] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 2 - Attack of the Clones (2002).1080p.bluray.mkv
```

Are movies linked to a collection by their file paths?  It would be great if they would be linked by their ID, or just get removed from the collection if the file disappears. Is there any way I can remove these "phantom* files from my collection?

### Reproduction steps

1. Create a collection
2. Add a movie
3. Rename the movie's media file
4. Browse to the "Collections" page while viewing the logs.

### What is the current _bug_ behavior?

I see entries in the log stating that the oldl-named files were unable to be found. This is correct, the old names are gone, but why are the old-named files still in the collection?

### What is the expected _correct_ behavior?

Either update the collection to contain the updated, renamed entity, or remove it from the collection.

### Jellyfin Server version

10.9.11+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

_No response_

### Specify the build version

10.9.11

### Environment

```markdown
- OS: Debian 11
- Docker container with "ghcr.io/jellyfin/jellyfin:latest" container.
```


### Jellyfin logs

```shell
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 3 - Revenge of the Sith (2005).1080p.bluray.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 6 - Return of the Jedi (1983).1080p.bluray.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 1 - The Phantom Menace (1999).1080p.bluray.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 7 - The Force Awakens (2015).1080p.bluray.x264.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 5 - The Empire Strikes Back (1980).1080p.bluray.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 9 - The Rise of Skywalker.2020.1080p.web-dl.x264.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 4 - A New Hope (1977).1080p.bluray.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 8 - The Last Jedi (2017).1080p.bluray.x264.mkv
app_1  | [22:05:38] [WRN] [95] MediaBrowser.Controller.Entities.BaseItem: Unable to find linked item at path /media/Movies/Sci Fi & Fantasy/Star Wars/Star Wars Ep. 2 - Attack of the Clones (2002).1080p.bluray.mkv
```
```


### FFmpeg logs

_No response_

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

_No response_
Ambiguous terms: old
Questions:
1. Are movies linked to a collection by their file paths in Jellyfin?
2. What does it mean by "phantom files" in the context of this bug report?
Clarified requirement: The bug report indicates that after renaming files and adding them to a collection in Jellyfin, old file names are still referenced in the collection causing errors. The user is seeking clarification on whether movies are linked to a collection by their file paths and how to remove these old-named files from the collection, referred to as "phantom files."


Clarify this requirement: ### This issue respects the following points:

- [X] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [X] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [X] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [X] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [X] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

when adding albums to my music library with Japanese names they dont show up. only english characters are shown in the a-z and #, the album is there if i search but wont be displayed in the library

### Reproduction steps

added the album [ゑでぃまぁこん (Eddie Marcon)]
綿の煙の招待状 (Invitation)
nothing is added

### What is the current _bug_ behavior?

the album is not added to the librarys browse view

### What is the expected _correct_ behavior?

in plex i have # a-z and then an asian font symbol 

### Jellyfin Server version

10.9.11+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

_No response_

### Specify the build version

10.9.11

### Environment

```markdown
- OS:mac osx
- Linux Kernel:apple m1 max
- Virtualization: no
- Clients:atv, ios, web
- Browser:opera
- FFmpeg Version:7.0.2 
- Playback Method:
- Hardware Acceleration:no
- GPU Model:apple m1 max
- Plugins:
- Reverse Proxy:
- Base URL:
- Networking:
- Storage:
```


### Jellyfin logs

```shell
none that mentions this
```


### FFmpeg logs

_No response_

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

_No response_
Ambiguous terms: bug, up to date, latest version, single issue
Questions:
1. What is meant by "up to date version of Jellyfin Server stable, unstable or master"?
2. Can you clarify what is expected in terms of the bug behavior and the correct behavior?
Clarified requirement: No response.


Clarify this requirement: ### This issue respects the following points:

- [X] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [X] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [X] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [X] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [X] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

When you get the information from TMDB using the default plugin, you should be able to perform a fallback translation in the language.

### Reproduction steps

1. Create new Programs Library with Spanis-Latam language and Mexico Country.
2. Create new folder: BLEACH (2004) [tmdbid-30984] > Season 01
3. Put any video for any episode S01E01.mp4
4. Scan Library.

### What is the current _bug_ behavior?

If you search for information in Spanish (Mexico) and it doesn't exist, you should search for the information in the Spanish parent. (From es-MX to es)

This way you get the correct record since TMDB has configured that if the name is the same, you should leave the information for Spanish-Mexico blank and save the values ​​in Spanish-Spain.

Instead, you are saving the keyword that TMDB uses to omit information, in this case: Episode ##, and leaving the overview blank

![imagen](https://github.com/user-attachments/assets/03b1c483-f43d-44ad-aa18-4645b637da28)

You should skip the keyword used by TMDB (Episode ##) and get the texts with the parent language (ES)
![imagen](https://github.com/user-attachments/assets/63f4d35c-21f0-41c5-a8e3-ec95a24ae0ad)



### What is the expected _correct_ behavior?

To be able to obtain information about the parent language when the language with country code does not exist.

Example:
Language "es-MX" dont exist
Get language "es" for Spain,

### Jellyfin Server version

10.9.11+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

_No response_

### Specify the build version

10.9.11

### Environment

```markdown
- OS: DEBIAN
- Virtualization: DOCKER
- Clients: Android TV, WEB
- Browser: FIREFOX, Chrome
- Plugins: Official TMDB
```


### Jellyfin logs

```shell
-NONE-
```


### FFmpeg logs

_No response_

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

_No response_
Ambiguous terms: bug, up to date, latest version, single issue, correct, parent language, expected behavior
Questions:
1. What is meant by "parent language" in the context of this requirement?
2. Can you clarify what is considered the "latest version" of Jellyfin Server?
Clarified requirement: - [X] This report addresses only a single bug; If you encounter multiple issues, kindly create separate reports for each one.


Clarify this requirement: ### This issue respects the following points:

- [X] This is a **bug**, not a question or a configuration issue; Please visit our forum or chat rooms first to troubleshoot with volunteers, before creating a report. The links can be found [here](https://jellyfin.org/contact/).
- [X] This issue is **not** already reported on [GitHub](https://github.com/jellyfin/jellyfin/issues?q=is%3Aopen+is%3Aissue) _(I've searched it)_.
- [X] I'm using an up to date version of Jellyfin Server stable, unstable or master; We generally do not support previous older versions. If possible, please update to the latest version before opening an issue.
- [X] I agree to follow Jellyfin's [Code of Conduct](https://jellyfin.org/docs/general/community-standards.html#code-of-conduct).
- [X] This report addresses only a single issue; If you encounter multiple issues, kindly create separate reports for each one.

### Description of the bug

I recently changed metadata providers and ran a scan to update missing metadata, however, our internet connection is very limited and the scan is triggering hundreds of simultaneous requests, flooding the network connection and making it unusable. This most certainly isn't nice behavior for our metadata providers. There should be a sane default for the maximum number of outbound requests to a provider and hopefully be able to be adjusted for those of us on very slow connections.

### Reproduction steps

Scan for missing metadata on a library with a lot of missing metadata. Watch the active number of connections increase to very high levels.

### What is the current _bug_ behavior?

I've seen over 256 active simultaneous requests at a time. This is causing failures as sockets time out due to being flooded by too much traffic.

### What is the expected _correct_ behavior?

Less simultaneous requests and so we can make slow, steady progress

### Jellyfin Server version

10.9.8+

### Specify commit id

_No response_

### Specify unstable release number

_No response_

### Specify version number

10.9.8

### Specify the build version

10.9.8

### Environment

```markdown
- OS: Ubuntu 24.04
- Linux Kernel: 6.8
- Virtualization: None
- Clients: Browser
- Browser: Firebox
- FFmpeg Version: 6.0.1-Jellyfin
- Playback Method: Depends
- Hardware Acceleration: None
- GPU Model: None
- Plugins: None
- Reverse Proxy: None
- Base URL: None
- Networking: Host
- Storage: Local
```


### Jellyfin logs

```shell
Example output when things timeout

[WRN] [174] Emby.Server.Implementations.Library.LibraryManager: Cannot fetch image from https://image.tmdb.org/t/p/original/HASH_HERE.jpg. Http status code: null
```


### FFmpeg logs

_No response_

### Client / Browser logs

_No response_

### Relevant screenshots or videos

_No response_

### Additional information

Thank you all very much for the wonderful software. I really appreciate your time and consideration for my report.
Ambiguous terms: bug, nice, sane, very slow, less, slow, steady
Questions:
1. What specific actions trigger the flood of network requests?
2. Can the user manually adjust the maximum number of outbound requests to a provider?
Clarified requirement: This bug report addresses the issue where changing metadata providers and running a scan to update missing metadata triggers hundreds of simultaneous requests, flooding the network connection. The user suggests implementing a default maximum number of outbound requests to a provider and allowing manual adjustment for users with slow internet connections.


Clarify this requirement: ### Please describe your bug

This issue is based on the closing recommendation of issue #12272 to split the described problems into separate issues, namely recommendation 2 and 3. I decided to combine these two recommendations into one issue, as I lack the knowledge of the backend and cannot reasonably decompose the problems further, but can only describe my observations. Feel free to have a look into said issue, as it might give a better complete picture of the problems in the track selector.

This issue focuses on the influence of different localisation settings that can be made on the user side and the server side. The main issue is, that as a user I would expect the audio and subtitle track selection to be localised based on the user localisation setting. The resulting strings in the selector are however mainly influenced by **several** server settings, that may be inaccessible to said user.

### Reproduction Steps

The following example uses German as the language for localisation. However this should be reproducable with any other language.

Starting from an all English setup with the following GUI options:
- Administration > Dashboard > General > Preferred display language: English (United Kingdom)
- User > Settings > Display > Display language: English (United Kingdom)

and the following environment variables set for the Docker container:
```
LC_ALL=en_UK.UTF-8
LANG=en_UK.UTF-8
LANGUAGE=en
```

the track selector looks like:
![1_server-en_gui-en_environment-en](https://github.com/user-attachments/assets/32fb59f3-f9c5-4e8a-a56c-2d3a43711b75)
Now we will gradually change to a German localisation by changing several settings and see the outcome.

### User setting: Display language
Changing the user display language under _User > Settings > Display > Display language_ to German yields
![2_server-en_gui-de_environment-en](https://github.com/user-attachments/assets/0e3b5637-6ca5-41de-a2fd-e82f259e107f)
Only the labels for the categories are localised ("Subtitle" -> "Untertitel"). However, the string of the selector itself remains untouched.

### Server setting: Preferred display language
Changing the preferred server display language under _Administration > Dashboard > General > Preferred display language_ to German yields
![3_server-de_gui-de_environment-en](https://github.com/user-attachments/assets/855043ec-19b0-4adb-a075-4348d2ac47b9)
localising only the _default_ flag of the string in the track selector ("Default" -> "Standard"). (Though only for the subtitle track, refer to issue #12276).
 
### Server environment: Environment variables
Only when we change the environment variables of the server itself - which I consider even a level above the server settings you can set in Jellyfin's GUI - to
```
LC_ALL=de_DE.UTF-8
LANG=de_DE.UTF-8
LANGUAGE=de:en
```
the strings in the selector are fully localised:
![4_server-de_gui-de_environment-de](https://github.com/user-attachments/assets/66f8e156-907c-45c9-8ac6-ff8fb53ae156)
where the language flags are successfully localised ("German" -> "Deutsch").

### Summary
As @felix920506 suggested in his closing recommendation of #12272, the selector should be made into a client string, instead of a server string for better localisation support. On that note, I would propose that the localisation of the track selection should be controlled by only **one** setting, namely the user display language, since it is a crucial item of GUI interaction with the user. Furthermore, it is the only setting a restricted user can set by itself, without any admin rights.

### Jellyfin Version

10.9.0

### if other:

_No response_

### Environment

```markdown
- OS: DSM 7.2.1-69057 Update 5
- Linux Kernel: unknown
- Virtualization: Docker
- Clients: universal
- Browser:
- FFmpeg Version:
- Playback Method:
- Hardware Acceleration:
- GPU Model:
- Plugins:
- Reverse Proxy:
- Base URL:
- Networking:
- Storage:
```


### Jellyfin logs

```shell
No actions are taken, thus no log file should be of any use here.
```


### FFmpeg logs

_No response_

### Please attach any browser or client logs here

_No response_

### Please attach any screenshots here

_No response_

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct
Ambiguous terms: several, mainly, fully, better, only, crucial
Questions:
1. What does the term "several" refer to in the context of server settings?
2. Can you clarify what is meant by "fully" in the statement about the strings in the selector being fully localized?
Clarified requirement: Please describe the bug related to the influence of different localization settings on the user and server side. The bug involves the expectation that audio and subtitle track selection should be localized based on user localization settings, but the strings in the selector are primarily influenced by server settings that may not be accessible to the user. The bug should be reproducible by changing various settings as outlined in the reproduction steps.


Clarify this requirement: ### Confirm this is a feature request for the Python library and not the underlying OpenAI API.

- [X] This is a feature request for the Python library

### Describe the feature or improvement you're requesting

Currently the client.beta.threads.runs.create_and_poll() function and client.beta.threads.runs.stream() function do not accept a pydantic model as their "response_format". currently they only accept the old {"type": "json_object"} value.

### Additional context

```Python
class Meal(BaseModel):
    meal: str
    slug: str
    recipe_id: str
    calories_per_serving: int
    protein_per_serving: int
    fat_per_serving: int
    carbs_per_serving: int
    servings: int

class Meals(BaseModel):
    breakfast: Optional[Meal]
    lunch: Optional[Meal]
    dinner: Optional[Meal]

class DayLog(BaseModel):
    date: str  # You can change this to 'date' type if needed
    total_calories: int
    total_carbs: int
    total_fat: int
    total_protein: int
    meals: Meals

class WeekLog(BaseModel):
    Monday: DayLog
    Tuesday: DayLog
    Wednesday: DayLog
    Thursday: DayLog
    Friday: DayLog
    Saturday: DayLog
    Sunday: DayLog

completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {"role": "system", "content": "my prompt for structured data"


             },
        ],
        response_format=WeekLog,
    )
```

Currently the above works without issue, but the below throws a TypeError:

```Python
assistant = client.beta.assistants.create(
        name="Meal Planner Nutritionist",
        instructions="some instructions",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4o-2024-08-06",
    )
    thread = client.beta.threads.create()
    message = client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content= "my prompt for structured data"
         )
    run = client.beta.threads.runs.create_and_poll(
        thread_id=thread.id,
        assistant_id=assistant.id,
        instructions="repeat instructions",
        response_format=WeekLog
    )
```

and the below works, but isnt usable for my purposes:

```Python
assistant = client.beta.assistants.create(
        name="Meal Planner Nutritionist",
        instructions="some instructions",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4o-2024-08-06",
    )
    thread = client.beta.threads.create()
    message = client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content= "my prompt for structured data"
         )
    run = client.beta.threads.runs.create_and_poll(
        thread_id=thread.id,
        assistant_id=assistant.id,
        instructions="repeat instructions",
        response_format={"type": "json_object"}
    )
```
Ambiguous terms: old, accept, usable
Questions:
1. What is meant by "old" in the context of the response_format value?
2. Can you clarify what is meant by "usable for my purposes" in the provided code snippets?
Clarified requirement: The provided Python code snippets demonstrate an issue where using a pydantic model as the "response_format" in certain functions throws a TypeError, while using {"type": "json_object"} works but is not suitable for the intended purposes.


Clarify this requirement: ### Confirm this is a feature request for the Python library and not the underlying OpenAI API.

- [X] This is a feature request for the Python library

### Describe the feature or improvement you're requesting

It would be nice to be able to be able to log the body of the requests.
I needed to see what was sent over the wire, so I checked how to log body requests.
Turns out, there's no way.

I needed to modify this, in order to do it.
https://github.com/openai/openai-python/blob/58bec2ffe5274b37fed3adad8da188f0cbc5406c/src/openai/_base_client.py#L447-L448

Could you add support to log body requests?

I'm not sure if this is the only place that has to change.
In fact, I just ended capturing network traffic just to be sure.
Having to resort to this kind of technique, is not nice.

I'm aware that you can log request/response using a custom httpx client with a custom transport: https://github.com/encode/httpx/discussions/3073

EDIT: the same applies to responses body


### Additional context

_No response_
Ambiguous terms: nice, needed, modify, support, sure, kind, aware, custom
Questions:
1. What specifically do you mean by "log the body of the requests"?
2. Can you clarify what you mean by "modify this" and "support to log body requests"?
Clarified requirement: Confirm this is a feature request for the Python library and not the underlying OpenAI API. The request is to add functionality that allows for logging the body of requests being sent and received within the Python library. This feature should enable users to track the content of requests and responses for debugging and monitoring purposes.


Clarify this requirement: ### Confirm this is a feature request for the Python library and not the underlying OpenAI API.

- [X] This is a feature request for the Python library

### Describe the feature or improvement you're requesting

Functionality to adjust exponential backoff associated with max_retries option. Looking in the documentation it's stated that certain errors are automatically retried 2 times by default, with a short exponential backoff, if it's possible it's ideal to control the value of the exponential backoff either manually or should be dynamically associated with rate limited duration in case of a 429 error since just short exponential backoffs are not helpfull in this case!

### Additional context

_No response_
Ambiguous terms: adjust, ideal, short, helpful
Questions:
1. What is meant by "adjust" in the context of the exponential backoff?
2. Can you clarify what is considered a "short" exponential backoff?
Clarified requirement: Confirm this is a feature request for the Python library and not the underlying OpenAI API. The request is for functionality to adjust the exponential backoff associated with the max_retries option. The goal is to have control over the value of the exponential backoff either manually or dynamically associated with rate limited duration, especially in the case of a 429 error where short exponential backoffs are not effective.


Clarify this requirement: ### Confirm this is a feature request for the Python library and not the underlying OpenAI API.

- [X] This is a feature request for the Python library

### Describe the feature or improvement you're requesting

It would be nice to start data transfer as soon as it becomes available for the real-time voice recognition.
We already have a similar feature for tts: https://platform.openai.com/docs/guides/text-to-speech/streaming-real-time-audio
Please note, I am not saying that a transcript should be available before the speech ended. But I would like to start the data transfer earlier.

### Additional context

The HTTP supports sending files in chunks without knowing the length in advance.
A WAV header does require the length, however 0xFFFFFFFF (i.e. max length) works fine with Whisper (I checked).
Ambiguous terms: nice, real-time, earlier, chunks, fine
Questions:
1. What specifically do you mean by "start data transfer as soon as it becomes available"?
2. Can you clarify what you mean by "start the data transfer earlier"?
Clarified requirement: Confirm this is a feature request for the Python library and not the underlying OpenAI API. The request is to enable data transfer for real-time voice recognition to begin before the speech has ended, similar to the existing feature for text-to-speech. This should be achieved by allowing the transfer of data in chunks without needing to know the length in advance, with a WAV header using 0xFFFFFFFF as the max length.


Clarify this requirement: ### Confirm this is a feature request for the Python library and not the underlying OpenAI API.

- [X] This is a feature request for the Python library

### Describe the feature or improvement you're requesting

I would like to have shell auto completion support to cli in this python library, which will make cli a more useful tool to play around with openai.

Other examples: 
- GitHub CLI: https://cli.github.com/manual/gh_completion
- Stripe CLI: https://stripe.com/docs/stripe-cli/autocomplete

### Additional context

_No response_
Ambiguous terms: useful, more, useful, play around
Questions:
1. What specifically do you mean by "shell auto completion support"?
2. Can you clarify what you mean by "make cli a more useful tool to play around with openai"?
Clarified requirement: Confirm this is a feature request for the Python library and not the underlying OpenAI API. The feature being requested is to add shell auto completion support to the CLI in the Python library to enhance its usability for interacting with OpenAI.


Clarify this requirement: ### Confirm this is an issue with the Python library and not an underlying OpenAI API

- [X] This is an issue with the Python library

### Describe the bug

`httpx.PoolTimeout` occurs frequently with SyncClient

Recently, we noticed a high number of timeouts.  Many requests were getting stuck on the default timeout of 600. 
This was before we migrated.
We migrated to v1.2.3 to try to mitigate this but the requests were still getting stuck in timeout. 
We have managed to mitigate this a little bit by setting the timeout to 30 seconds and retrying (without our own retry library since the OpenAI retries don't appear to have jitter or exp backoff and were causing problems at scale)
Now we are getting `httpx.PoolTimeout` when using the SyncClient. This is causing downstream issues since tasks start to pile up and we just get tons of `httpx.PoolTimeout`.

I think we will consider using a custom http client, though I noticed this requests being stuck in timeout on the old version of the api as well... which was our original motivation to migrate...

In case it helps this is in a production app doing about 3-6 OpenAI requests per second and seems to line up with busier traffic moments.

### To Reproduce

1. Use SyncClient
2. Make 3-6 requests per second to ChatCompletions endpoint
3. Get httpx.PoolTimeouts

### Code snippets

_No response_

### OS

ubuntu

### Python version

Python v3.10.8

### Library version

OpenAI v1.2.4
Ambiguous terms: frequently, high number, many, tons of, busier, seems to, line up with
Questions:
1. What specific actions trigger the `httpx.PoolTimeout` when using the SyncClient?
2. Can you clarify what you mean by "busier traffic moments" that seem to line up with the issue?
Clarified requirement: Confirm that the issue causing `httpx.PoolTimeout` errors when using the SyncClient is related to the Python library and not the underlying OpenAI API.


Clarify this requirement: ### Confirm this is an issue with the Python library and not an underlying OpenAI API

- [X] This is an issue with the Python library

### Describe the bug

The fix for https://github.com/openai/openai-python/issues/769 involved adding retries for `httpx.ReadTimeout` exceptions which works but as the default timeout is 10 minutes, this can quickly rack up time spent in API requests.

We should figure out a better solution here.

### To Reproduce

N/A

### Code snippets

_No response_

### OS

N/A

### Python version

N/A

### Library version

v1.2.4
Ambiguous terms: quickly, better
Questions:
1. What specific problems arise from the default timeout of 10 minutes in the API requests?
2. What criteria define a "better solution" in this context?
Clarified requirement: Confirm that the issue lies within the Python library and not the underlying OpenAI API. The fix implemented for https://github.com/openai/openai-python/issues/769 added retries for `httpx.ReadTimeout` exceptions. However, the default timeout of 10 minutes leads to excessive time spent in API requests. A more effective solution needs to be identified.


Clarify this requirement: ### Describe the feature or improvement you're requesting

Hello everyone,

When using legacy fine-tuning, I find the `OpenAI CLI` extremely helpful due to its numerous tools. 
For instance, the [Prepare Data Helper](https://platform.openai.com/docs/guides/legacy-fine-tuning/cli-data-preparation-tool) and the [Create Fine-Tuning](https://platform.openai.com/docs/guides/legacy-fine-tuning/create-a-fine-tuned-model) are particularly useful.

However, these tools only apply to legacy models, which consist of JSON with `prompt` and `completion` keys.

I propose the addition of operations to the existing CLI that can perform the same functions for the new chat fine-tuning.

### My Proposal

- For the sake of backwards compatibility, we could create a new subcommand called `chat_fine_tunes`.
  - This subcommand would inherit all operations that `fine_tunes` can perform, such as assisting with data preparation, etc. We can simply replicate the existing operations with minor modifications to suit the new format.

### Additional context

I am open to working on this feature if it is approved.
Ambiguous terms: numerous, helpful, particularly, useful, same, suit, minor
Questions:
1. What specific tools and operations are currently available in the OpenAI CLI for legacy fine-tuning?
2. Can you provide more details on the format and requirements of the new chat fine-tuning that the proposed operations should support?
Clarified requirement: Describe the feature or improvement requested for the OpenAI CLI to add a new subcommand called `chat_fine_tunes` that replicates the existing operations of `fine_tunes` but tailored for the new chat fine-tuning format, with a focus on backwards compatibility and data preparation assistance.


Clarify this requirement: ### Describe the feature or improvement you're requesting

It would be useful if the module provided a function to calculate number of token in a given prompt for a given model, without having to use another 3rd party modules to do so.

One examle when it would be useful is to trim fed history if the entire prompt (+max_tokens) is above a given model limit, before sending the query.

### Additional context

_No response_
Ambiguous terms: useful, module, function, calculate, number, token, prompt, model, 3rd party, trim, limit, query
Questions:
1. What is meant by "given model limit" in this context?
2. Can you clarify what is meant by "trim fed history"?
Clarified requirement: Describe the feature or improvement being requested for the module to include a function that calculates the number of tokens in a given prompt for a specified model, eliminating the need for third-party modules. An example of when this feature would be beneficial is to truncate the input history if the total prompt length exceeds the specified limit for a particular model, before sending the query.


Clarify this requirement: ### Describe the feature or improvement you're requesting

I have this tool I made which I'm using day to day now: https://github.com/backus/ai.sh

It is super useful and I actually like that it is written in pure bash because it is very portable and it is also a testament to just how easy it is to add some AI magic to your application. That said, one thing I'd like to add to the tool is the ability to see why the completion finished generating (did it hit a stop token or did it hit the token limit?).

I could do this to switching to a pure cURL, but I'd love if I could just tell the client to give me JSON instead of just the `.choices[0].text`. Would be really easy then to use [`jq`](https://stedolan.github.io/jq/manual/) to manipulate the response inside of scripts.

### Additional context

_No response_
Ambiguous terms: super useful, like, easy, love, really easy
Questions:
1. What specific information do you want to extract from the tool regarding the completion generation process?
2. How do you envision the JSON response format to be structured for easier manipulation with `jq`?
Clarified requirement: Describe the feature or improvement requested for the tool to include the ability to indicate the reason for completion generation completion (stop token or token limit) and to provide a JSON response format for easier manipulation using `jq`.


Clarify this requirement: ### Describe the bug

When rendering in SSR with `<NoHydration>`, a `<Suspense>` wrapper will reset the context or counter used by `createUniqueId`. This can result in duplicate IDs.

Granted, there is no actual use case for `Suspense` without hydration. But when working with isomorphic JS, it is possible to introduce a component like `Suspense` into pure SSR code via shared components. For example, you might have a generic "Card" component that wraps everything in `Suspense` with a default spinner as a matter of course. So long as no async resource is accessed within any of the `Suspense` children on SSR, I would expect things to keep working as if `Suspense` wasn't there at all.

### Your Example Website or App

https://stackblitz.com/edit/solid-ssr-vite-kfrwzikw?file=src%2Fentry-server.tsx

### Steps to Reproduce the Bug or Issue

Rendering something on the server like this will result in duplicate IDs.

```tsx
function Child() {
  const id = createUniqueId();
  return <div id={id} />;
}

function Parent() {
  return (
      <NoHydration>
        <Child />
        <Child />
        <Suspense fallback={null}>
          <Child />
          <Child />
        </Suspense>
      </NoHydration>
  );
}

renderToString(() => <Parent />);
```

### Expected behavior

As a developer, I'd expect either:

* For `Suspense` to effectively be a noop with hydration off and not reset the `createUniqueId` context
* _Or_ since `Suspense` doesn't really do anything without hydration, for there to be some sort of warning or error.

### Screenshots or Videos

StackBlitz screenshot showing how IDs are unique with hydration on but not with hydration off:

<img width="764" alt="Image" src="https://github.com/user-attachments/assets/5603fddf-99ed-410e-bdfd-4915d2d3d73d" />

### Platform

- Node 18.20.3


### Additional context

_No response_
Ambiguous terms: possible, generic, matter of course, keep working, as if, expect, some sort of, warning, error
Questions:
1. What is the specific behavior expected from the `Suspense` component when used in SSR with `<NoHydration>`?
2. Can you clarify the role of the `createUniqueId` context and how it interacts with the `Suspense` component in this scenario?
Clarified requirement: Describe the bug that occurs when rendering in SSR with `<NoHydration>`, where a `<Suspense>` wrapper may reset the context or counter used by `createUniqueId`, leading to duplicate IDs. The issue arises when using `Suspense` without hydration, even though there may not be a practical use case for it in this context.


Clarify this requirement: ### Describe the bug

Setting `popover={true}` in your JSX will generate `popover="true"` in the HTML. This sort of works in most browsers, but it is invalid and can cause Chrome (with SSR-generated HTML at least) and other tools to complain.

Per https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/popover, the only valid values for `popover` are `""` (same as `"auto"`) , `"manual"`, `"auto"`, and `"hint"` (experimental) .

However, the [TypeScript definitions for this attribute](https://github.com/ryansolid/dom-expressions/blob/7b4608fa74db18b1ec43bd9eb53abf0f708c412e/packages/dom-expressions/src/jsx.d.ts#L911) are `boolean | "manual" | "auto" | undefined`, and setting it to a boolean gives you values of `"true"` and `"false"` instead of `""` or unsetting it.

### Your Example Website or App

https://playground.solidjs.com/anonymous/1748d882-88b6-4aea-b8e2-c792e17c38ea

### Steps to Reproduce the Bug or Issue

Set `popover={true}`, `popover={false}`, or just `popover` as a JSX attribute.

### Expected behavior

As a developer, I expect:
* `popover={true}` and `popover` to generate `popover=""` or just `popover` in the HTML.
* `popover={false}` to unset the attribute
* `popover=""` to validate with TypeScript.

### Screenshots or Videos

_No response_

### Platform

- OS: macOS
- Browser: Chrome
- Version: 133.0.6943.127 


### Additional context

_No response_
Ambiguous terms: most, invalid, complain, experimental, true, false, unset, validate
Questions:
1. What specific issues arise when `popover="true"` is generated in the HTML?
2. How does setting `popover={false}` differ from not setting the `popover` attribute at all?
Clarified requirement: Describe the bug that occurs when setting `popover={true}` in JSX, resulting in `popover="true"` in the HTML, and provide guidance on the valid values and expected behaviors for the `popover` attribute in TypeScript and HTML.


Clarify this requirement: ### Describe the bug

I'd like to extend the `<a>` element and create such an extended element using `<Dynamic>` in solid-js, but right now that's not possible without manually using `document.createElement("a", { is: "customized-link" })`

### Your Example Website or App

https://playground.solidjs.com/anonymous/790f2888-36f6-40fb-9527-0cd30edbde60

### Steps to Reproduce the Bug or Issue

1. Go to the playground link
2. Check the console for "element in dom"
3. see no logs

### Expected behavior

1. Go to the playground link
2. Check the console for "element in dom"
3. See an element being logged

So basically I'd want the `is` property to be passed down when `<Dynamic>` calls `document.createElement` (see [mdn docs](https://developer.mozilla.org/en-US/docs/Web/API/Document/createElement#is))

### Screenshots or Videos

_No response_

### Platform

Latest Firefox on macOS

### Additional context

_No response_
Ambiguous terms: extend, extended, possible, manually, want
Questions:
1. What specific functionality are you looking to add to the `<a>` element by extending it?
2. Can you clarify what you mean by the `is` property being passed down when `<Dynamic>` calls `document.createElement`?
Clarified requirement: Describe the bug where the `<a>` element needs to be extended with specific functionality in solid-js using `<Dynamic>`. Currently, this cannot be achieved without manually using `document.createElement("a", { is: "customized-link" })`. The desired outcome is for the `is` property to be inherited when `<Dynamic>` invokes `document.createElement`.


Clarify this requirement: ### Describe the bug

If you share a store setter from an iframe to its parent and call it via the parent, objects assigned to the store via this method, will not be reactive.

### Your Example Website or App

https://stackblitz.com/edit/github-gerxph-42ncis?file=src%2Froutes%2Findex.tsx

### Steps to Reproduce the Bug or Issue

1. Share a store setter from an iframe with its parent window
2. Listen to all values inside of the store, e.g. with `createEffect(() => console.log(JSON.stringify(state))`
3. Via the parent window, assign a new object to the store 
4. Via the parent window, update a value inside of this new object
5. Notice how this change will not trigger a console.log

### Expected behavior

Objects assigned to a store via a different window should become reactive like any other object.

### Screenshots or Videos

_No response_

### Platform

- OS: [Linux]
- Browser: [Chrome, Firefox]


### Additional context

The reason why objects assigned this way will not be reactive, is the prototype check in https://github.com/solidjs/solid/blob/4d824b08d8534d2a079f9ca4c1ea980684c05582/packages/solid/store/src/store.ts#L75. Different windows have different `Object.prototype` and therefore an object assigned via another window, will not be considered as wrappable by solid store.

Since the prototype check works as intended for normal non-iframe use cases, a sensible way would be to just allow a hook into the check, e.g. something like this:

```ts
const wrappablePrototypes = [Object.prototype];
export const registerWrappablePrototype = (p) => wrappablePrototypes.push(p);

export function isWrappable(obj: any) {
  let proto;
  return (
    obj != null &&
    typeof obj === "object" &&
    (obj[$PROXY] ||
      !(proto = Object.getPrototypeOf(obj)) ||
      wrappablePrototypes.indexOf(proto) >= 0 ||
      Array.isArray(obj))
  );
}
```

`registerWrappablePrototype` would allow advanced developers to add parent/iframe `Object.prototype`, vice-versa.

---

Edit: Alternative: how about we use duck typing to figure out if `proto` is wrappable, if it quacks like a `Object.prototype` it must be one. We would just have to make sure that the duck typing works across realms.
Ambiguous terms: reactive, wrappable, sensible, advanced, wrappablePrototypes, quacks
Questions:
1. What does it mean for an object to be "reactive" in this context?
2. Can you clarify what is meant by "wrappable" in the provided code snippet?
Clarified requirement: Describe a bug where objects assigned to a store via a different window are not reactive as expected due to a prototype check. The suggestion is to allow a hook into the prototype check to enable developers to customize wrappable prototypes.


Clarify this requirement: A memo accept an initial value and the `equals` property via the `options` object to exert finer control over its update logic.  However it does not respect the equals property on its initial execution but it should for consistency.

For the following example, ` 'some value'` should never be assigned to the memo as it is not a valid value.

```ts
import { createEffect, createSignal, createMemo } from 'solid-js';

const [preferences, setPreferences] = createSignal({
  lang: 'en', theme: 'some value', fontSize: 'large',
});

const theme = createMemo(() => preferences().theme, 'light', {
  equals: (prev, curr) => {
    if (prev === curr) return true;
    if (prev === 'dark' && curr === 'light') return false;
    if (prev === 'light' && curr === 'dark') return false;
    return true;
  }
});

createEffect(() => console.log(theme()));
```
Ambiguous terms: fast, user-friendly, finer control, consistency, valid value
Questions:
1. What does it mean for a value to be considered "valid" in this context?
2. Can you provide more clarity on what is meant by "exert finer control over its update logic"?
Clarified requirement: "A memo should accept an initial value and the `equals` property via the `options` object to control its update logic. However, the memo should not respect the equals property on its initial execution for consistency. In the provided example, `'some value'` should never be assigned to the memo as it is not a valid value."


Clarify this requirement: I'm trying to reuse the same dom element, and attach it in different places in the ui.
But even though that element is rendered only in one place at a time, solid's rendering of it is not stable.
Sometimes the element is added correctly, sometimes it's removed from the dom completely and sometimes it appears in the wrong spot.

```tsx
const my_dom_element = document.createElement('div')

return <>
	<div>
		<Show when={something() === 'foo'}>
			{my_dom_element}
		</Show>
	</div>
	<div>
		<Show when={something() === 'bar'}>
			{my_dom_element}
		</Show>
	</div>	
</>
```

Playground link:
https://playground.solidjs.com/anonymous/d2ce885b-d473-4641-94a6-d9c659bc1e22

I know that this can be "solved" by creating new elements and animating them as if they were the old one. But that is besides the point.
This just seems like something that should work.
Ambiguous terms: stable, correctly, completely, wrong
Questions:
1. What do you mean by "solid's rendering of it is not stable"?
2. Can you clarify what you mean by "sometimes the element is added correctly, sometimes it's removed from the dom completely and sometimes it appears in the wrong spot"?
Clarified requirement: I'm attempting to reuse the same DOM element and attach it in different places in the UI. However, the rendering behavior in Solid.js is inconsistent. Sometimes the element is added as expected, other times it is completely removed from the DOM, and occasionally it appears in the incorrect location. The goal is to have the element display reliably in the specified locations.


Clarify this requirement: ### Describe the bug

```tsx
classList={{
  "b-1px b-solid b-red": true,
  "b-1px b-solid b-blue": <reactive value>,
}}
```
After changing reactive value,`b-1px` and `b-solid` tokens will disappear.
This is not critical, because of how CSS works, this kind of expression probably is user's mistake, but behaviour is unexpected. We should better handle this case.

### Your Example Website or App

https://playground.solidjs.com/anonymous/ad8fd905-fb6e-45cb-8bdc-95ad0dd309f7

classList probably should not use `node.classList.toggle` directly, or compare individual tokens
Ambiguous terms: probably, better
Questions:
1. What is meant by "changing reactive value" in this context?
2. Can you clarify what is meant by "classList probably should not use `node.classList.toggle` directly, or compare individual tokens"?
Clarified requirement: Describe the bug where after changing the reactive value, `b-1px` and `b-solid` tokens disappear. This behavior is unexpected and should be handled better. The `classList` should not use `node.classList.toggle` directly or compare individual tokens.


Clarify this requirement: ### Describe the bug

When setting the value of a textarea with a static string, it does not set the property, while if you set the value while calling a function it does get set.

```tsx
function Counter() {
  const [signal] = createSignal("dynamic");
  return (
    <>
      {/* Does not set value */}
      <textarea
        value="static"
        ref={(element) => {
          console.log("1 static:", element.value);
          queueMicrotask(() => console.log("2 static:", element.value));
        }}
      />
      {/* Sets value */}
      <textarea
        value={signal()}
        ref={(element) => {
          console.log("1 dynamic:", element.value);
          queueMicrotask(() => console.log("2 dynamic:", element.value));
        }}
      />
      {/* Sets value too */}
      <textarea
        value={(() => "iife")()}
        ref={(element) => {
          console.log("1 iife:", element.value);
          queueMicrotask(() => console.log("2 iife:", element.value));
        }}
      />
    </>
  );
}
```

### Your Example Website or App

https://playground.solidjs.com/anonymous/54d80eb1-0ae9-4016-8300-e8f058f975d9

### Steps to Reproduce the Bug or Issue

```tsx
<textarea value="static" />
```

### Expected behavior

The value of the textarea to be "static", but instead it is "".

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

_No response_
Ambiguous terms: static, dynamic, iife
Questions:
1. What is meant by "static" in the context of setting the value of a textarea?
2. Can you clarify the term "iife" as used in the code snippet?
Clarified requirement: Describe the bug that occurs when setting the value of a textarea with a static string, a dynamic function call, or an IIFE (Immediately Invoked Function Expression) in a SolidJS component.


Clarify this requirement: ### Describe the bug

I am loading a list of select options from an API so the options get populated a bit after the element is rendered. The value of the select is already set but is not reflected after the list is loaded.

### Your Example Website or App

https://playground.solidjs.com/anonymous/afff844c-d8cb-40ab-b368-7b0fe268ab6d

### Steps to Reproduce the Bug or Issue

1. create a <select> 
2. set its value 
3. use <For> to populate its options from an array
4. load the array of options using a timeout so that is populated after the render

### Expected behavior

I expect the value of the select to be reflect the correct option regardless of when that option is rendered

### Screenshots or Videos

_No response_

### Platform

- Browser: [Chrome]


### Additional context

_No response_
Ambiguous terms: loaded, correct, fast, user-friendly
Questions:
1. What does "loaded" refer to in this context?
2. How is the correct option determined in this scenario?
Clarified requirement: Describe a bug where the value of a select element is set but not reflected after the list of options is loaded asynchronously from an API, causing the select element to not display the correct option regardless of when it is rendered.


Clarify this requirement: ### Describe the bug

Universal Renderer's cleanup method (the return value of `render` function) doesn't remove the existing node, which is inconvenient for using HMR.

### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-ycgqgq?file=src%2Findex.tsx

### Steps to Reproduce the Bug or Issue

1. See the rendered result.

### Expected behavior

I ran the cleanup method and I expected the node to be removed.

### Screenshots or Videos

![image](https://github.com/solidjs/solid/assets/68762426/800c49be-0669-4824-811e-a560451f42bc)


### Platform

- OS: Windows 11
- Browser: Firefox
- Version: 115


### Additional context

I am using solid-js for Firefox XUL, non-standard HTML, for developing a custom browser.
While I making HMR using Vite, I encountered the problem.
Thank you for the good project!
Ambiguous terms: inconvenient
Questions:
1. What specific aspect of the existing node not being removed is inconvenient for using HMR?
2. Can you clarify what HMR stands for in this context?
Clarified requirement: solid-js is being used for Firefox XUL, non-standard HTML, to develop a custom browser. The issue was encountered while implementing HMR using Vite. Thank you for the good project!


Clarify this requirement: ### Describe the bug

See this JSX:
```jsx
 <div>
      <table>
        <thead>
          <tr>Name</tr>
        </thead>
        <tbody>
          <tr>
            <td>iPhone</td>
            <td>
              13
            </td>
          </tr>
        </tbody>
      </table>
    </div>
```
In the template above, a ```<tr/>``` has a text node as its child. As expected, malform syntaxes like this should be blocked in build stage. However this syntax somehow passes the validation, and result in a unclosed template like ```_$template(`<div><table><thead><tr>Name</tr></thead><tbody><tr><td>iPhone`)```. It will cause any insert efforts failed with ```TypeError: Cannot read properties of null (reading 'nextSibling')``` , since the template is not correct and browser explain it to something not expected.

### Your Example Website or App

https://codesandbox.io/p/devbox/great-leaf-tyf99q?file=%2Fsrc%2FApp.tsx%3A21%2C21-21%2C51

### Steps to Reproduce the Bug or Issue

1. Open the devbox and everything should render correctly
2. De-comment Line 15 -17
3. Render will failed and in console a TypeError should be thrown

### Expected behavior

Templates should be correctly generated, or a JSX validation error should be thrown.

### Screenshots or Videos

_No response_

### Platform

- OS: Windows
- Browser: _Not related_
- SolidJs Version: 1.8.14

### Additional context

_No response_
Ambiguous terms: correctly, expected, failed, correct, should, somehow, not correct, not expected
Questions:
1. What specifically should happen when a malform syntax is encountered during the build stage?
2. Can you provide more details on what is considered a correct template generation?
Clarified requirement: _No response_


Clarify this requirement: ### Describe the bug

When using Solid and testing our app with coverage reporting enabled (powered by istanbul/nyc), there are some branches/functions which are uncovered, but they are not branches which exist in our code, instead they are generated by Solid. Because these code paths are generated, we cannot place a `/* istanbul ignore next */` comment before the appropriate section because it doesn't exist anywhere in our source.

A few cases where this occurs (I'm sure there's others):

* `Show`/`Match` components - If the match is never used, there's an unused function because of the `get children()` method which got generated
* Refs - It generates a ternary with `typeof _ref$ === "function"` as the condiiton. Which in most cases will always be true/false so that means there's a branch of the code which never gets hit.

All of these result in an extra uncovered function here, an extra uncovered branch there. And there's no way we can add the appropriate comments before this code to ignore it.

### Your Example Website or App

https://playground.solidjs.com/anonymous/7b917606-9c75-4695-b669-accb486afc92

### Steps to Reproduce the Bug or Issue

N/A

### Expected behavior

When Solid is generating the runtime code, it should relocate the comments appropriately so they keep the same meaning that they have in the source.

Source:

```jsx
{/* istanbul ignore next */}
<Match when={condition()}>
    <div>Hello</div>
</Match>
```

Generated:

```jsx
_$createComponent(Show, {
  get when() {
    return condition();
  },
  /* istanbul ignore next */
  get children() {
    return _tmpl$();
  }
})
```

-----

Source:

```jsx
let ref;
return <div ref={ref}>Hello</div>
```

Generated: (This should always add the appropriate ignore comments since only one branch will ever be hit.)

```jsx
let ref;
return (() => {
  var _el$ = _tmpl$();
  var _ref$ = ref;
  /* istanbul ignore next */
  typeof _ref$ === "function" ? _$use(_ref$, _el$) : ref = _el$;
  return _el$;
})();
```

### Screenshots or Videos

_No response_

### Platform

- OS: N/A
- Browser: N/A
- Version: 1.8.16


### Additional context

It's also impossible currently to write our own plugin to do this since comments will get totally deleted during compilation when placed in certain spots of the JSX.

For example, this input:

```jsx
function Counter() {
  let ref;
  /* istanbul ignore next -- 1 */
  return (
    <>
      {/* istanbul ignore next -- 2 */}
      <div ref={ref}>Hi</div>
    </>
  );
}
```
Gets transformed into: (the second comment is just totally lost so we cannot even attempt to move it with our own plugin after Solid is done compiling)

```jsx
function Counter() {
  let ref;
  /* istanbul ignore next -- 1 */
  return (() => {
    var _el$ = _tmpl$();
    var _ref$ = ref;
    typeof _ref$ === "function" ? _$use(_ref$, _el$) : ref = _el$;
    return _el$;
  })();
}
```

This is a unique problem with Solid which doesn't exist with many other frameworks because Solid generates a lot of code rather than just calling functions from the Solid library. If these same bits of code were instead unconditional function calls to code in node_modules, this wouldn't be an issue.
Ambiguous terms: impossible, appropriate, same, totally
Questions:
1. What specific actions or behaviors are considered "appropriate" in this context?
2. Can you provide more clarity on what you mean by "the same meaning" for relocating comments appropriately?
Clarified requirement: Describe the issue encountered when using Solid with coverage reporting enabled, where generated code paths result in uncovered branches/functions that cannot be ignored with comments due to their non-existence in the source code. The expected behavior is for Solid to adjust the comments in the generated runtime code to maintain their intended meaning from the source code.


Clarify this requirement: ### Describe the bug

I've written a mutable primitive for my lib pota, collected tests for it from solid, oby, vue, + additions/variations I made up. I then ran the tests against the implementations on our libs: solid, oby and pota, to highlight the differences and possible bugs.

There are 240~ tests, I will list below the failing test for solid, around 35~. "by design" implementation details that fail won't count. 

1. object returned by function call in mutable is not observed.  https://playground.solidjs.com/anonymous/4d40b7dd-48a1-4f73-a6ca-bd98c2b8331f - ref 10 mutation: returned object by function call is mutable 

2. writing to an object with setter/getter overwrites getter.  https://playground.solidjs.com/anonymous/4c42006f-c124-4054-a74d-70974e0acbb4 - ref 12 getters: returning object

3. In solid frozen objects are made mutable, when a getter returns a frozen object it throws https://playground.solidjs.com/anonymous/4c62129a-5560-475b-b8fa-45e45a96f2b8 - 14 - getters: returning frozen object

4. setting to undefined shouldn't delete the property https://playground.solidjs.com/anonymous/6f1021b5-8e71-49a9-b376-1b89b64b010d - 22 - setting to undefined shouldnt delete the property

5. deleting key that doesn't exists triggers reactivity https://playground.solidjs.com/anonymous/2d07b152-75de-4ea9-a085-c1c5338a2c8f - 24 - delete non existent key doesnt trigger reactivity - object.keys

6.  delete key with undefined value doesnt trigger reactivity with check "in" https://playground.solidjs.com/anonymous/5c6627a9-4665-446e-96b4-31b697a77018 delete key with undefined value does trigger reactivity - in


7. attempting to set a value when its only a getter access getter https://playground.solidjs.com/anonymous/44d261b9-70de-452d-8eac-9cc9dd9947a0 - 39 - in: getters to not be called 3 
8. access getters more than it should https://playground.solidjs.com/anonymous/fe232aba-ecd7-47ff-83f2-2fbc0633b858 - 40 - in: getters to not be called 3.1
9. access getters more than it should 2 https://playground.solidjs.com/anonymous/cd367536-5769-4083-9cba-90d2ba3c9aa3 - 41 - in: getters to not be called 4 

10. problems with getters defined in classes 

- https://playground.solidjs.com/anonymous/46e40618-0655-426b-81b0-4d313dad470d - 49 - read and set class
-  https://playground.solidjs.com/anonymous/10f2b817-5eff-4ec9-b3c9-e6a5fe15dc26 - 51 - read and set inside class
- https://playground.solidjs.com/anonymous/deb37164-7105-438e-8657-99ab78f11a37 - 52 - read and set inside extended class
- https://playground.solidjs.com/anonymous/488709da-0ea6-4574-aaab-3e1ccf707385 - 53 - read and set inside extended x2 class 

11. doesnt react to hasOwnProperty https://playground.solidjs.com/anonymous/da5b1fb6-2914-4fdb-9bb0-ea65f8bdec38 - 55 - reacts to hasOwnProperty 
12. throws when redefining hasOwnProperty https://playground.solidjs.com/anonymous/78fb154e-388f-4f45-9335-07e855e9d644 - 79 - returns unproxied   properties 



13. deleting test 
- https://playground.solidjs.com/anonymous/8b1eaf25-9e8c-4d1b-b17b-03e542698d7c - 85 - supports not reacting when deleting a shallow property that was undefined
- https://playground.solidjs.com/anonymous/3505ca38-e13e-466e-8005-612353810737 - 88 - supports not reacting when deleting a deep property that was undefined
14. seems like its over reacting https://playground.solidjs.com/anonymous/ea8df396-5b69-402d-89a1-67a149bc53d0 - 94 - supports reacting to own keys deep
15. deleting 
- https://playground.solidjs.com/anonymous/b25dba78-20d8-42f6-a725-37acf763b5de 108 - supports reacting to property checks when value is undefined, deleting 
- https://playground.solidjs.com/anonymous/9e72b099-a67d-4a26-9f2f-9b0938228b4f - 109 - supports reacting to property checks when value is undefined, deleting deep 

16. reacting to adding properties https://playground.solidjs.com/anonymous/d4304507-190a-4097-846d-a4429108e7d9 - 110 - supports reacting to property checks, adding 
17. reacting to adding properties deep https://playground.solidjs.com/anonymous/7c7af674-159c-4707-82be-5a831d30d21d - 111 - supports reacting to property checks, adding deep 
18. throws with frozen objects https://playground.solidjs.com/anonymous/3e6b2e6e-7b78-4730-be4b-7e33ca6160fa - 122 - should not observe non-extensible objects
19. reacting to properties from the prototype https://playground.solidjs.com/anonymous/da7072f0-6a88-4a03-bbb8-b5ab9a642562 - 131 - should observe properties on the prototype chain
20. reacts when value changes from NaN to NaN (they probably should be using equals, but well) https://playground.solidjs.com/anonymous/8986df2c-9631-4f49-880c-c2e819c81aa9 - 147 - should not be triggered when the value and the old value both are NaN
21. splice and object identity https://playground.solidjs.com/anonymous/4a0a23b2-2131-47ef-bb0c-d604abeea1f8 - 175 - array: sliced test
22. infinite loop https://playground.solidjs.com/anonymous/f5403e80-7f3f-438f-8b94-fb3b5c29c81a 187 - array: pushing in two separated effects doesnt loop
23. identity test https://playground.solidjs.com/anonymous/cd68b1b1-6a7d-425e-ad11-e3b901fd77c9 205 - array: observed value should proxy mutations to original 
24. array methods for searching wont find stuff  https://playground.solidjs.com/anonymous/9ded9dba-aa62-43f4-8277-82edd361f523 - 206 - array: identity methods should work
25. more array identity tests https://playground.solidjs.com/anonymous/8f421b42-da3e-4bd1-937a-06d261690a44 - 208 - array: internal array functions should search for the mutable versions of it

27. infinite loop in array https://playground.solidjs.com/anonymous/499412e1-b975-4240-82fc-c440a20325e0 - 224 - array: should avoid infinite recursive loops when use Array.push/unshift/pop/shift

28. array returns past value? something is wrong with batching? https://playground.solidjs.com/anonymous/4e566456-5001-4147-b73c-5e188ac64270 -  226 - array: vue array instrumentation: concat

29. Possible related to batching https://playground.solidjs.com/anonymous/b5d60b40-a558-4828-a586-168b12aed411 -  93 - supports reacting to own keys


### Your Example Website or App

https://pota.quack.uy/Reactivity/mutable-tests

### Steps to Reproduce the Bug or Issue

-

### Expected behavior

-

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

https://github.com/potahtml/pota

A playground, testing all our libs at the same time is in 
https://pota.quack.uy/Reactivity/mutable-tests
Ambiguous terms: possible, around, seems like, probably, more than it should, problems with, something is wrong with, infinite, reacting to, supports, should avoid, possible related to, supports
Questions:
1. What specific criteria determine whether an implementation detail is considered "by design" and therefore not counted as a failing test?
2. Can you clarify what is meant by "problems with getters defined in classes"?
Clarified requirement: Describe the bug by listing specific failing tests for the solid implementation, excluding those related to "by design" implementation details. Additionally, provide details on the issues encountered with getters defined in classes.


Clarify this requirement: ### Describe the bug

Top level effects (`createEffect` that isn't wrapped in a `createRoot`)  behave inconsistently when compared with effects under a root, because top level effects aren't batched. 

This isn't an issue with solid per se, as its `render` function already wraps in a `root`. 

The issue is when solid is used for reactivity exclusively(besides rendering dom nodes), such when creating long-lived effects that will never be disposed, reactivity in the server; or for demo purposes (such playground snippets and the like), this inconsistency gets in the way because doesn't match expectations, it could be hard to understand why does behave this way. 

It is possible that batching top level effects improve the performance of these effects.

### Your Example Website or App

meaw

### Steps to Reproduce the Bug or Issue

Top level effect non batched
https://playground.solidjs.com/anonymous/39d404d1-5c4a-411b-ab85-f915c82089e6

behaves differently to:

effect wrapped in a root
https://playground.solidjs.com/anonymous/d30de401-fc16-4c9a-a247-39333b970b8b
behaves the same as a top level effect that uses batch
https://playground.solidjs.com/anonymous/13b29236-c0f9-46fb-8b20-4a221fa9e4df

### Expected behavior

Please batch top level effects.

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

As discussed on discord, it may be about changing this line https://github.com/solidjs/solid/blob/main/packages/solid/src/reactive/signal.ts#L357
Ambiguous terms: inconsistently, batched, long-lived, reactivity, demo purposes, improve, performance
Questions:
1. What specific behaviors are considered inconsistent between top level effects and effects under a root?
2. Can you provide more clarity on what is meant by "batching" effects?
Clarified requirement: Describe the bug where top level effects (`createEffect` that isn't wrapped in a `createRoot`) behave differently compared to effects under a root due to the lack of batching. This issue arises when using Solid for reactivity exclusively, such as for long-lived effects or in server reactivity scenarios. The request is to batch top level effects for improved performance.


Clarify this requirement: ### Describe the bug

I started investigating this issue when I noticed that adding a [SUID](https://suid.io/) button to a page caused all [ninja-keys](https://github.com/ssleptsov/ninja-keys) hotkeys (including up/down arrows to select commands) to stop working while the ninja-keys menu is open. After stepping through the debugger, the reason is that ninja-keys is a web component and relies on keyboard events from within the menu having a target of the `ninja-keys` component instead of the actual text `input` element inside the menu. However, the SUID button uses solid `onKeyDown` and `onKeyUp`, causing these events to use solid's event delegation from the document, which overrides the event `target`.

Ryan explains in [this video](https://www.youtube.com/live/2fW6JaJHoCE?si=CJUkaUJMvHcECovU&t=6561) about "reverse shadow DOM retargetting". There's not really an explaination for _why_ solid deviates from the web standards here, but I'd assume it's so that events have the expected target when using solid _inside_ web components, such as with solid-element. When listening to events from _outside_ a web component though, I think it should not do reverse shadow DOM retargetting, especially when using an event listener that's not using solid's event delegation (whether it's an external library like ninja-keys using hotkeys-js, or with `on:` directives in solid).  

It's worth noting that the order the event listeners on document are added matters; if it was only modifying the event "once everyone else is done with it" then that would be fine, but when event listeners are added _after_ solid has already initialised it's the event delegation, then it gets the mutated event.

A simple fix could be to just keep hold of the original target and put it back after solid's event delegation is done with it. That wouldn't make event handlers that _do_ use event delegation get the "correct" target, but it would at least fix it for event handlers that aren't using event delegation.

### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-zz63ns?file=src%2FApp.tsx

### Steps to Reproduce the Bug or Issue

1. Go to the provided repro on stackblitz
2. Type in the text input
3. Observe that `keyDown target B` shows `INPUT`

### Expected behavior

All event listeners should show the same thing, `MY-INPUT-COMPONENT`, because the events originate from inside the web component and the listeners are on document, outside the web component.

### Screenshots or Videos

_No response_

### Platform

- OS:  Linux
- Browser: Tested in Chrome and Firefox
- Version: Chrome 122.0.6261.111, Firefox 123.0.1


### Additional context

_No response_
Ambiguous terms: simple, expected, correct
Questions:
1. What is the specific issue encountered when adding a SUID button to the page?
2. How does the behavior of event listeners need to be adjusted to resolve the bug?
Clarified requirement: Describe a bug where adding a SUID button to a page causes issues with ninja-keys hotkeys functionality. The bug occurs due to conflicting event delegation methods between solid and external libraries like ninja-keys. The expected resolution involves adjusting event listeners to ensure consistent event targets.


Clarify this requirement: ### Describe the bug

When you have multiple `Suspense` siblings with internal components calling `useTransition`, starting one transition shifts the pending signal to true inside all `Suspense` boundaries. Is this expected?

### Your Example Website or App

https://playground.solidjs.com/anonymous/dac2d20e-5f9e-4bbc-be95-73ff967c88d2

### Steps to Reproduce the Bug or Issue

Load https://playground.solidjs.com/anonymous/dac2d20e-5f9e-4bbc-be95-73ff967c88d2
Hit Start on one of the lines
All lines show Pending state

### Expected behavior

Only the clicked line should show a pending state as it should be isolated in the Suspense boundary.

### Screenshots or Videos

_No response_

### Platform

Solid 1.8.15


### Additional context

Let me know if I'm misunderstanding the functionality.
Ambiguous terms: multiple, internal, pending, expected, isolated, functionality
Questions:
1. What does it mean for a component to be "isolated in the Suspense boundary"?
2. Can you clarify the term "internal components" in this context?
Clarified requirement: Describe a bug where having multiple `Suspense` siblings with internal components calling `useTransition` causes starting one transition to shift the pending signal to true inside all `Suspense` boundaries, instead of isolating it to the clicked line within the `Suspense` boundary.


Clarify this requirement: The current package entry points use conditional exports which make assumptions about my desired behavior, and provide different implementations based on my environment. In my case, I want to use solid as a reactive state management library on my server, and assumed I wanted SSR with no reactivity. 

I want an entry point like `solid-js/reactive` to import the reactive core of solid-js (signals, effects, memos, etc) without any assumptions being made.
Ambiguous terms: assumptions, desired behavior, reactive state management, server, SSR, reactivity, entry point
Questions:
1. What specific assumptions are currently being made about the desired behavior when using the current package entry points?
2. Can you clarify what is meant by "reactive state management" and how it differs from SSR with no reactivity?
Clarified requirement: The current package entry points are using conditional exports that assume certain behaviors based on the environment. The requester wants an entry point like `solid-js/reactive` to import the reactive core of solid-js without any assumptions being made.


Clarify this requirement: ### Describe the bug

This is a continuation of:
https://github.com/ryansolid/dom-expressions/issues/277#issuecomment-1765059926

My goal is actually to replace all instances of DOM types (including HTMLElement etc) with my own custom type provided by a universal renderer, but this minimal repro establishes what the problem with that is.

The divide between 'solid-js' and 'solid-js/web' gives the impression that all web-related code is sectioned off into the web renderer, but that's only true at runtime, and not to typescript. The core JSX type is web-specific, and part of `solid-js`. it gets used in a few places, including the type definition of things like the `Component<>` type and the control flow primitives.

Because the runtime implementation is still doing the right thing, this can be worked around by allowing the dom types and then overriding them wherever you need to use them, but this comes at the cost of extensibility (can't make a solid-js library without depending on the web types) and maintainability.


### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-s9fb1b?file=build.log&view=editor

### Steps to Reproduce the Bug or Issue

1. Remove 'dom' from your global type definitions. (in the repo that is done by `"lib: ['ESNext']"` in the tsconfig
1. `pnpm build`
2. observe build errors. examples:
```
node_modules/.pnpm/solid-js@1.7.6/node_modules/solid-js/types/jsx.d.ts(9,19): error TS2304: Cannot find name 'Element'.
node_modules/.pnpm/solid-js@1.7.6/node_modules/solid-js/types/render/hydration.d.ts(12,28): error TS2304: Cannot find name 'Element'.
```

### Expected behavior

It should be possible to use the core reactive library without depending on the dom. likewise, it should be possible to use an entirely separate universal renderer without pulling in the dom types. 

### Screenshots or Videos

_No response_

### Platform

all


### Additional context

This is a larger task. It may require backwards-incompatible changes, and it would need input from core maintainers. I have some thoughts on how to approach this, I'll leave them in a follow-up comment
Ambiguous terms: possible, entirely, larger, some
Questions:
1. What specific issue arises when trying to replace DOM types with a custom type provided by a universal renderer?
2. How does the presence of 'dom' in global type definitions affect the build process and error messages?
Clarified requirement: Describe the issue that occurs when attempting to replace DOM types with a custom type from a universal renderer and explain how the presence of 'dom' in global type definitions impacts the build process and error messages.


Clarify this requirement: ### Describe the bug

`classList` doesn't work when used together with `class`, even when `classList` is not reactive, if the object looks like this `{ ["test"]: true }` instead of `{ test: true }`

### Your Example Website or App

https://playground.solidjs.com/anonymous/a669dae1-46b2-4366-9df0-91d6527908c6

### Steps to Reproduce the Bug or Issue

1. Go to https://playground.solidjs.com/anonymous/a669dae1-46b2-4366-9df0-91d6527908c6
2. See `class-2` being logged to the console

### Expected behavior

1. `class-1` being logged to the console

### Screenshots or Videos

_No response_

### Platform

- OS: macOS 14
- Browser: Latest FirefoxDeveloperEdition


### Additional context

_No response_
Ambiguous terms: fast, user-friendly
Questions:
1. What is the relationship between `classList` and `class` in this context?
2. Can you provide more details on how `{ ["test"]: true }` differs from `{ test: true }`?
Clarified requirement: Describe the bug where `classList` does not work properly in conjunction with `class`, even when `classList` is not reactive. This occurs when the object is structured as `{ ["test"]: true }` instead of `{ test: true }`.


Clarify this requirement: ### Describe the bug

Right now it's possible to do a mistake when destructuring, see this example: https://playground.solidjs.com/anonymous/26548b4b-87ed-4b76-bfbd-2cb6fa2b5b42

This mistake is not caught by TypeScript right now and leads to unexpected behavior - effects being re-executed when nothing happens and my value not being set.

### Your Example Website or App

https://playground.solidjs.com/anonymous/26548b4b-87ed-4b76-bfbd-2cb6fa2b5b42

### Steps to Reproduce the Bug or Issue

1. Go to playground link
2. See that a getter gets passed to a function expecting a setter without any error

### Expected behavior

I as a dev should not have to debug such a basic mistake, my computer should blurt red in my face.
Since it seems like nothing happens with stuff passed to a `readSignal` function right now it would be easy for you to just throw in dev mode, saving people that make this mistake time debugging.

### Screenshots or Videos

_No response_

### Platform

macOS (M1), latest chrome or firefox

### Additional context

_No response_
Ambiguous terms: mistake, unexpected, basic, easy, dev mode
Questions:
1. What specific mistake occurs when destructuring in the provided example?
2. Can you clarify what you mean by "dev mode" in this context?
Clarified requirement: Describe a bug in the provided example where a mistake occurs during destructuring, leading to unexpected behavior such as effects being re-executed incorrectly. The bug is not caught by TypeScript, causing issues with value setting. The expectation is for such mistakes to be highlighted clearly, possibly through a visual indication in a development environment.


Clarify this requirement: ### Describe the bug

Custom elements have numerous callbacks and these should untrack to avoid recursion. This is a bit tricky because a lot of DOM methods for manipulation could cause the callbacks to fire.

### Your Example Website or App

https://playground.solidjs.com/anonymous/b6031b3f-7ce9-4322-a06f-31823340af8d

### Steps to Reproduce the Bug or Issue

Testing code is the following

```js
import { render } from "solid-js/web";
import { createSignal } from "solid-js";

const [read, write] = createSignal(true);

function recurse(name, ...args) {
  console.log(name, ...args);
  write(!read());
}

class CustomElement extends HTMLElement {
  static observedAttributes = ["string-attribute"];

  constructor() {
    super();
    recurse("constructor");
  }
  connectedCallback() {
    recurse("Custom element added to page.");
  }

  disconnectedCallback() {
    recurse("Custom element removed from page.");
  }

  adoptedCallback() {
    recurse("Custom element moved to new page.");
  }

  attributeChangedCallback(name, oldValue, newValue) {
    recurse(`Attribute ${name} has changed.`, oldValue, newValue);
  }
  set boolean(value) {
    recurse(`boolean has changed.`, value);
  }
}

customElements.define("custom-element", CustomElement);

render(
  () => () => (
    <custom-element string-attribute="lala" boolean={true}>
      Test
    </custom-element>
  ),
  document.getElementById("app")!,
);
```
Ambiguous terms: numerous, tricky, a lot of, could
Questions:
1. What specifically do you mean by "callbacks" in this context?
2. Can you provide more detail on what you mean by "untrack" to avoid recursion?
Clarified requirement: Describe how to prevent recursion by untracking specific callbacks in custom elements that are triggered by DOM manipulation methods.


Clarify this requirement: ### Describe the bug

If, on the playgrround example, the line containing the spread gets removed, the `value` property of the input field will be assigned as follows:
```js
_$effect(() => _el$.value = get());
```
This will have the desired effect.
If the spread line doesn't get removed the `value` property will be setted like this:
```js
_$spread(_el$, _$mergeProps({
  get value() {
    return get();
  }
}, {}), false, false);
```
The `spread()` function sets properties of elements using `assignProp()`, which won't change the value of the property on the actual element if its old value is the same as the new one.
The problem is that if we type "unallowe" and then add a "d", the signal will remain with "unallowe" while the input field will contain the "d" too.
This happens because the `value` property of the actual element contained the "d" because of the user interaction, but the solid props used to create that input field still only contained "unallowe"; so when the signal was updated with the same value ("unallowe"), `assignProp()` believed that there were no changes.
I think [this](https://github.com/ryansolid/dom-expressions/blob/a9abd972d5b773ae8d4864be768bd23bf37f1dc9/packages/dom-expressions/src/client.js#L309) line should not return if `value` is different from the one contained in `node`
>Notice that there's a workaround for this problem, you just need to set the `prop:value` attribute instead of the `value` one

### Your Example Website or App

https://playground.solidjs.com/anonymous/6e6f686b-e624-49c5-b5cb-f445207883f4

### Steps to Reproduce the Bug or Issue

1. Type "unallowe" on the input field
2. Type "d", the new letter will be shown but the actual value will remain the same
3. Type another character, the actual value will start being updated again

### Expected behavior

When typing "d" (2nd step), nothing should've turned up in the first place

### Screenshots or Videos

_No response_

### Platform

(Not needed)
- OS: Windows
- Browser: Edge
- Version: 120.0.2210.77

### Additional context

_No response_
Ambiguous terms: fast, user-friendly, desired, problem, workaround, different, same, actual, new, old, contained, believed, changes, updated, start, updated
Questions:
1. What is the specific behavior that is considered the bug in this scenario?
2. Can you clarify what is meant by the terms "actual value" and "signal"?
Clarified requirement: Describe a bug where the `value` property of an input field is not updating correctly in a scenario where certain lines are removed or not removed. The bug causes the input field to display incorrect values based on user interaction, leading to confusion.


Clarify this requirement: ### Describe the bug

I have this component:

```jsx
function Div(props) {
    return (
        <div {...props}/>
    )
}
```

And I use it like this:

```jsx
<Div id="hello" ref={el => console.log('id', el.id)}>Div</Div>
```

### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-edibnb?file=src%2FApp.jsx

### Steps to Reproduce the Bug or Issue

Use the `Div` component and look at the console output. It shows:

> id _&lt;empty string&gt;_

### Expected behavior

I expected to have access to the element's attributes, e.g. `id`. Instead, I seem to get default attributes ("" instead of "hello").

### Screenshots or Videos

_No response_

### Platform

- OS: Windows
- Browser: Firefox
- Version: 120.0.1


### Additional context

Workaround: Wrap the `ref` inside `onMount()`.
Ambiguous terms: access, expected, attributes, default
Questions:
1. What specific behavior are you expecting when you mention "access to the element's attributes"?
2. Can you clarify what you mean by "default attributes" in this context?
Clarified requirement: Describe a bug where the `Div` component does not provide the expected attribute values when accessed through a `ref`, displaying an empty string instead of the desired attribute value like "hello". The bug occurs in the provided code example on the specified platform and browser.


Clarify this requirement: ### Describe the bug

This JSX code,

```js
function Example() {
	return <some-el attr:foo="123">inspect element</some-el>
}
```

outputs the attribute `foo="123"` to the DOM, as expected.

[JSX playground example](https://playground.solidjs.com/anonymous/4ea1522c-e8c7-434c-b0d5-5943325e58d2)

This `html` template,

```js
function Example() {
	return html`<some-el attr:foo="123">inspect element</some-el>`
}
```

outputs verbatim `attr:foo="123"` to the DOM.

[`html` playground example](https://playground.solidjs.com/anonymous/3f8870fa-ecb7-4222-b81c-abec2a56b6b3)

### Your Example Website or App

https://playground.solidjs.com/anonymous/3f8870fa-ecb7-4222-b81c-abec2a56b6b3

### Steps to Reproduce the Bug or Issue

see playground

### Expected behavior

Expect behavior to be consistent across JSX and `html`.

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

_No response_
Ambiguous terms: consistent
Questions:
1. What specific behavior is expected to be consistent across JSX and `html`?
2. Can you provide an example of the expected consistent behavior?
Clarified requirement: The behavior outputted to the DOM should be consistent between JSX and `html`.


Clarify this requirement: ### Describe the bug

This causes an error:

```js
import html from 'solid-js/html' 

html`
  <div>
    <template>
      <h1>Example</h1>
    </template>
  </div>
`
```

Error:

```
Uncaught TypeError: Cannot read properties of null (reading 'firstChild')
```

### Your Example Website or App

https://playground.solidjs.com/anonymous/5dd52803-e570-4f6e-a72d-0ef56944996f

### Steps to Reproduce the Bug or Issue

see console

### Expected behavior

expect to use a `<template>` element like normal HTML

### Screenshots or Videos

_No response_

### Platform

- OS: macOS
- Browser: Chrome
- Version: 1.8.5


### Additional context

_No response_
Ambiguous terms: normal, fast, user-friendly
Questions:
1. What specific behavior is expected when using a `<template>` element in this context?
2. Can you provide more details on the error message and how it relates to the use of the `<template>` element?
Clarified requirement: Describe the bug that causes an error related to using a `<template>` element in the provided JavaScript code snippet. The error message "Uncaught TypeError: Cannot read properties of null (reading 'firstChild')" is encountered. The expected behavior when using the `<template>` element needs to be clarified.


Clarify this requirement: ### Describe the bug

As the title, when using imported object for element style attribute, it is reevaluated if other attributes that use signal that is updated.

In this example a button element style uses an imported object called `style` which has background value of red.
```ts
export const style = {
  "background": "red",
}
```

After the button is mounted then it's background is changed to blue via element style property.
```jsx
import { style } from "./style"

// ...
onMount(() => {
  buttonEl.style.background = 'blue'
})

return (
  <button style={style} ... ref={buttonEl}>
    {count()}
  </button>
);
}
```

This button's aria-label attribute uses count signal which increments when clicked
```jsx
const [count, setCount] = createSignal(1);
const increment = () => setCount(count() + 1);
let buttonEl;

onMount(() => {
  buttonEl.style.background = 'blue'
})

return (
  <button type="button" onClick={increment} aria-label={count().toString()} style={style} ref={buttonEl}>
    {count()}
  </button>
```

### Your Example Website or App

https://playground.solidjs.com/anonymous/804fbf3b-2166-430f-ab99-c2b78770a1a6

### Steps to Reproduce the Bug or Issue

1. Click counter button

### Expected behavior

For button's background color to remain blue, but after clicking button it resets red which is the background property from object `style`. If button style attribute uses `style2` object, which is not imported then the button remains blue after updating count signal https://playground.solidjs.com/anonymous/efc28da8-a36c-42e5-b109-5d7b8a8c145e.

### Screenshots or Videos

_No response_

### Platform

- OS: macOS
- Browser: Chrome
- Version: 118.0.5993.117


### Additional context

_No response_
Ambiguous terms: fast, user-friendly
Questions:
1. What specific behavior is expected when the count signal is updated in relation to the button's background color?
2. How does the behavior differ when using the `style2` object compared to the `style` object?
Clarified requirement: Describe the bug that occurs when the count signal is updated in relation to the button's background color. Specifically, explain the expected behavior and the difference in behavior when using the `style2` object compared to the `style` object.


Clarify this requirement: ### Describe the bug

In my example, I've implemented a Counter component that increases the count by 1 and displays the final count every time an `onClick` event is triggered. Additionally, I've created a Web Component named CustomElement, which can accept a `mode` parameter to create a Shadow DOM and render the Counter component inside it. However, when I set the `mode` to 'closed,' the `onClick` event of the Counter component no longer gets executed. The expected behavior is for the Counter component to increase the count by 1 and display the final count upon each click.

### Your Example Website or App

https://playground.solidjs.com/anonymous/184db1e1-13a1-4d59-b685-26f1670ac9e0

### Steps to Reproduce the Bug or Issue

...

### Expected behavior

I expected that when I set the mode parameter to 'closed' for the Shadow DOM, the Counter component would still function as intended, increasing the count by 1 and displaying the final count whenever the onClick event is triggered.

### Screenshots or Videos

_No response_

### Platform

I've tested it on Linux Chrome, but I believe this issue can be reproduced on all platforms.

### Additional context

_No response_
Ambiguous terms: closed, intended
Questions:
1. What does setting the `mode` parameter to 'closed' specifically entail in terms of the Shadow DOM?
2. What is the specific functionality or behavior that is intended for the Counter component?
Clarified requirement: Describe the bug in the Counter component where setting the `mode` parameter to 'closed' for the Shadow DOM prevents the Counter component from executing the `onClick` event as expected, resulting in the count not increasing by 1 and displaying the final count.


Clarify this requirement: ### Describe the bug

When using solid-js with tagged template literals (using the html tag from solid-js/html), components that contains SVG fragments do not render when added in the context of an SVG.

This behavior is different when using JSX, which works as expected. Here are the examples:

JSX: https://playground.solidjs.com/anonymous/f5e959de-1f30-4f7e-b6b5-277dd57e711d
HTTL: https://playground.solidjs.com/anonymous/d388478e-c276-43a9-bf1b-e77d9110783b

### Your Example Website or App

https://playground.solidjs.com/anonymous/d388478e-c276-43a9-bf1b-e77d9110783b

### Steps to Reproduce the Bug or Issue

1. 

### Expected behavior

Should render SVG fragments onto page.

### Screenshots or Videos

_No response_

### Platform

OS: Linux
Browser: Firefox, Chrome

### Additional context

_No response_
Ambiguous terms: render, expected
Questions:
1. What specific issues occur when SVG fragments are added within the context of an SVG using solid-js with tagged template literals?
2. Can you provide more details on how the SVG fragments fail to render in this scenario?
Clarified requirement: Describe the bug that occurs when using solid-js with tagged template literals and adding SVG fragments within the context of an SVG. Specifically, detail the issues that arise and how the rendering differs from using JSX.


Clarify this requirement: A low-level suspense primitive would be useful for libraries to pause effects in "offscreen" branches.

Currently `Suspense` is not only a component-only primitive, but it is tied to resources, and by extend to routing, SSR, transitions, etc. It also assumes needing a fallback branch, which is not always needed.
Because of that it cannot be freely used in libraries, without affecting the rest of the app as a side effect.

For example in transition libraries like [`motionone`](https://github.com/motiondivision/motionone/tree/main/packages/solid) and [`solid-transition-group`](https://github.com/solidjs-community/solid-transition-group), when we use `<Transition>` with `mode="out-in"`, we need to wait for the previous element finish his exit animation, before the newly rendered element can be added to the DOM. But solid doesn't know that the new element is only kept in memory, and not yet appeared on the page, so the updates queue will proceed normally, calling all `onMount` callbacks, where we expect to deal with elements connected to the DOM.
An issue with more details: https://github.com/solidjs-community/solid-transition-group/issues/34

Also if we wish to keep some roots in memory—e.g. to [avoid recreating the same elements when filtering a large array](https://playground.solidjs.com/anonymous/10c6b36e-cd25-4da1-84d7-eeb5de82382a), or [displaying search highlights](https://github.com/solidjs-community/solid-primitives/tree/main/packages/marker#solid-primitivesmarker), or implementing a [root pool primitive](https://github.com/solidjs-community/solid-primitives/blob/main/packages/rootless/README.md#createRootPool)—there is no way to simply prevent then from running some side effects.

If we tried to use `<Suspense>` to suspend those branches, any resource read under it will also trigger it, possibly breaking the intended behavior of the app—by not showing a fallback in an expected place, or causing a transition (transaction) to be exited sooner (`<Transition>` is commonly used for wrapping rendered routes).

<details>
<summary> Code

example `createSuspense` using `Suspense`:
https://playground.solidjs.com/anonymous/21cef751-8f37-4354-8a63-0aa475d54e64
</summary>

```ts
function createSuspense<T>(when: Accessor<boolean>, fn: () => T): T {
  let value: T,
    resolve = noop;

  const [resource] = createResource(
    () => when() || resolve(),
    () => new Promise<void>((r) => (resolve = r)),
  );

  Suspense({
    // @ts-expect-error children don't have to return anything
    get children() {
      createMemo(resource);
      value = fn();
    },
  });

  return value!;
}
```
</details>

In @fabiospampinato's [`oby`](https://github.com/vobyjs/oby) this is solved by having a low-level [`suspense` primitive](https://github.com/vobyjs/oby#suspense) that simply takes a function to suspend and a boolean signal to inform if the branch should be suspended or not, and returns the value directly, similar to `createRoot`.
When the condition signal is `true`, all effects will be suspended, while resources ignore it and keep the lookup for Suspense they can trigger.

<details>
<summary> Code

Something like this could *maybe* be implemented currently as this: (although I'm not sure if resources won't trigger it anyway)
</summary>

```ts
function suspense<T>(when: Accessor<boolean>, fn: () => T): T {
  const SuspenseContext = getSuspenseContext(),
    store = {
      effects: [] as Computation<unknown>[],
      resolved: false,
      inFallback: when
    };

  let result!: T;

  SuspenseContext.Provider({
    value: store,
    get children() {
      result = fn();

      createMemo(() => {
        if (!when()) {
          store.resolved = true;
          resumeEffects(store.effects);
        }

        return result;
      });

      return undefined;
    }
  }) as any;

  return result;
}
```
</details>
Ambiguous terms: low-level, useful, branch, component-only, tied, freely, always, needed, wait, finish, exit, newly, appear, queue, proceed, connected, avoid, simply, prevent, tried, possibly, expected, commonly, wrapped, rendered, solved, similar, currently, maybe, sure, trigger
Questions:
1. What specific characteristics define a "low-level suspense primitive"?
2. How does the current implementation of `Suspense` affect the behavior of libraries in the app?
Clarified requirement: A low-level suspense primitive is needed for libraries to pause effects in "offscreen" branches without causing side effects in the rest of the app. Currently, the `Suspense` component is not only a primitive tied to resources, routing, SSR, and transitions, but also assumes the need for a fallback branch, which may not always be necessary. This limitation prevents its free use in libraries without unwanted side effects.


Clarify this requirement: ### Describe the bug

I'm using the `Portal` component for a toast element where I noticed that the wrapper `div` element is messing up the styles of the elements.

I know that this `div` is required, but is it possible to at least add the ability to add the `class` attribute for this element for these edge cases?

### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-cshflq?file=src%2FApp.tsx

### Steps to Reproduce the Bug or Issue

1. Go to the [StackBlitz](https://stackblitz.com/edit/solidjs-templates-cshflq?file=src%2FApp.tsx) demo
2. Click the button to show the toast
3. You will see that the styles are messed up
4. If you inspect the elements and manually remove the wrapping `div` the layout will be fixed

### Expected behavior

I expected to at least be able to add the `class` attribute to the `Portal`'s wrapper `div`.
I would also be great if we can pass any attributes down to the `div` element.

### Screenshots or Videos

_No response_

### Platform

- OS: Linux
- Browser: Chrome
- Version: 116


### Additional context

Sorry if this issue is too specific, feel free to close it if it's out of scope.
Ambiguous terms: possible, at least, edge cases, great
Questions:
1. What specific styles are being affected by the wrapper `div` element in the `Portal` component?
2. Can you provide an example of how you would like to use the `class` attribute on the `Portal`'s wrapper `div` element?
Clarified requirement: Describe the issue where the wrapper `div` element in the `Portal` component is causing style disruptions. Requesting the ability to add the `class` attribute to the `Portal`'s wrapper `div` element and pass attributes to it.


Clarify this requirement: ### Describe the bug

https://playground.solidjs.com/anonymous/ef7f22ce-7141-4690-8fe3-a5f5497a0ac0

When a store gets updated, it updates the original data as well. In the example above, let's say that `dataFromExternalLibrary` should not mutate. The solution would be to deep clone the original data. But:

https://playground.solidjs.com/anonymous/987aa07c-26d2-42e0-af9f-b03336ba260f

In the case where we use a store as the underlying storage of `createResource`, whenever data needs to be reconciled, the user would need to deep clone, if the user wants to avoid mutating the original object.

If an option allows Solid to clone, it would allow for less cloning. In the lack of such option, we need to deep clone the whole data received from e.g. a library (which may be large) every time:

```typescript
function createDeepSignal<T>(value: T): Signal<T> {
  const [store, setStore] = createStore({ value });

  return [
    () => store.value,
    (v: T) =>
      untrack(() => {
        const unwrapped = unwrap(store.value);
        typeof v === 'function' && (v = v(unwrapped));
        
        // <=== deep clone `v`
        
        setStore('value', reconcile(v));
        return store.value;
      })
  ] as Signal<T>;
}
```

(My real-world case involves receiving GraphQL cached data, i.e. JS objects held by the GraphQL client library. Those caches should not mutate, hence I need to deep clone).

### Platform

- OS: Windows
- Browser: Chrome
- Version: 116

### Additional context

https://discord.com/channels/722131463138705510/1126684602480734368/1145982497281282139 (last messages)
Ambiguous terms: deep clone, less cloning, mutating, reconciled, large, real-world case
Questions:
1. What is meant by "reconciled" in this context?
2. Can you provide more clarity on what is considered a "real-world case"?
Clarified requirement: Describe the issue where updating a store mutates the original data, leading to the need for deep cloning to prevent mutation. The goal is to explore options for reducing the need for deep cloning, especially in scenarios like receiving GraphQL cached data where objects should not mutate.


Clarify this requirement: ### Describe the bug

`mutate` returned from `createResource` is `setValue` ([line 723 here](https://github.com/solidjs/solid/blob/f79ba4d9087d74ef7e55fd0dc336c98ce2ec8526/packages/solid/src/reactive/signal.ts#L723)) and is oblivious to the loading-state of the resource.

This is an issue, when we use custom state handlers reacting on state while mutating signals in resources.



### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-uwtyzi?file=src%2FApp.tsx

### Steps to Reproduce the Bug or Issue

```
  const [resource, { mutate }] = createResource(
    () => undefined,
    async () => {
      return 'test'
    }
  )
  mutate('updated')
  resource.latest // 'updated'
  resource.state // 'unresolved'

  const [resource2, { mutate: mutate2 }] = createResource(async () => {
    throw new Error('Boom')
  })
  mutate2('updated')
  console.log(resource2.latest) // 'updated'
  console.log(resource2.state) // 'errored'
```

### Expected behavior

As a user I expect a way to set the state after mutation, e.g. to `ready` after I have mutated the data.

### Screenshots or Videos

_No response_

### Platform

- OS: [ macOS]
- Browser: [ Chrome]
- Version: [116]


### Additional context

_No response_
Ambiguous terms: oblivious, issue, reacting, custom, state handlers, loading-state
Questions:
1. What does it mean for `mutate` to be oblivious to the loading-state of the resource?
2. How does the custom state handler react on state while mutating signals in resources?
Clarified requirement: Describe the bug where the `mutate` function returned from `createResource` in SolidJS is not aware of the loading-state of the resource, causing issues when using custom state handlers to react on state changes during signal mutations.


Clarify this requirement: ### Describe the bug

I'm creating a resource that is triggered on user input and is quite fallible (requesting camera access). I want to refetch the resource when the user clicks.

My first inclination was to use the `refetch` method. However I don't want the resource to be fetched immediately. I figured that a fasly source would let me choose when to fetch, however this doesn't work. I think it's counter-intuitive that `refetch` is conditional instead of an override.

### Your Example Website or App

https://playground.solidjs.com/anonymous/06e79e93-84e3-4977-9126-d4c0a1f0ec03

### Steps to Reproduce the Bug or Issue

1. `const [value, { refetch }] = createResource(false, fetch)`
2. `refetch()`

### Expected behavior

I was expecting the `fetch` method to be called.

### Screenshots or Videos

_No response_

### Platform

N/A


### Additional context

The alternative is to create a separate `loading` signal. I've been doing that but it's very brittle and get out of state with `resource.loading` especially when exceptions are thrown into the mix.

In fact I tried to create an example of it in action but I failed a few times. Using a boolean loading signal doesn't work correctly because you need to set it back to false, which apparently sets the resource state back to unresolved?? 

Anyway here's what I settled on, but I think it would be much better if I could just call refetch: https://playground.solidjs.com/anonymous/0e878b05-ff06-4d4a-aaae-39e62274456e
Ambiguous terms: fast, quite, immediately, counter-intuitive, conditional, brittle, especially
Questions:
1. What does the term "fasly source" refer to in this context?
2. Can you clarify what you mean by "overrides" in relation to the `refetch` method?
Clarified requirement: Describe a bug where the `refetch` method is not behaving as expected when trying to fetch a resource on user input without immediately fetching it.


Clarify this requirement: ### Describe the bug

Works with DOM API:
https://playground.solidjs.com/anonymous/05d9ad70-852d-40ca-8134-544ed1a6c21a

Doesn't work with Solid:
https://playground.solidjs.com/anonymous/4f293905-4892-478a-b6ba-ad4dd5912df7

Click Make Indeterminate a few times, should be able to toggle on and off, doesnt work on Solid


### Your Example Website or App

Above

### Steps to Reproduce the Bug or Issue

Click button

### Expected behavior

Works like DOM API

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]
Latest

### Additional context

_No response_
Ambiguous terms: few times, toggle on and off, Works like DOM API
Questions:
1. What specific button should be clicked to reproduce the issue?
2. Can you clarify what "Make Indeterminate" means in this context?
Clarified requirement: Describe the bug where clicking a specific button on the Solid playground does not function as expected compared to the DOM API playground. The issue involves toggling the button on and off, but it does not work properly on Solid.


Clarify this requirement: ### Describe the bug

I would like to have the ability to use declarative shadow DOM (without custom elements) within Solid components just to get style scoping. It doesn't work and I get the error Uncaught TypeError: Cannot read properties of null (reading 'nextSibling')


### Your Example Website or App

https://codesandbox.io/p/sandbox/awesome-sky-8fp8z5

### Steps to Reproduce the Bug or Issue

```tsx
export default function ShadowTest() {
  return (
    <div>
      <template shadowrootmode="open">
        <p>This is in the shadow DOM</p>
        <slot>
          <p>This is in the light DOM</p>
          <button>Light button</button>
        </slot>
        <button>Shadow button</button>
      </template>
    </div>
  );
}
```


### Expected behavior

It should render a shadow tree. 

### Screenshots or Videos

_No response_

### Platform

- OS: all
- Browser: Chrome + Safari (Firefox hasn't shipped support for it yet)


### Additional context

_No response_
Ambiguous terms: declarative, style scoping
Questions:
1. What is meant by "declarative shadow DOM"?
2. Can you clarify what is meant by "style scoping" in this context?
Clarified requirement: Describe the bug that occurs when attempting to use declarative shadow DOM (without custom elements) within Solid components just for style scoping. The error "Uncaught TypeError: Cannot read properties of null (reading 'nextSibling')" is encountered. The provided example code demonstrates the issue.


Clarify this requirement: ### Describe the bug

Here's an example:






### Your Example Website or App

https://playground.solidjs.com/anonymous/64e29718-38db-4df4-afeb-4445b799d170

### Steps to Reproduce the Bug or Issue

Press Increment

### Expected behavior

When pressing the button I'd expect that both counters update, however the one using on() isn't working.

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

_No response_
Ambiguous terms: describe, expected, working
Questions:
1. What does "both counters update" refer to in this context?
2. How is the counter using on() different from the other counter?
Clarified requirement: Describe a bug where pressing the Increment button on the provided website does not update one of the counters as expected. The issue specifically involves the counter that uses on().


Clarify this requirement: ### Describe the bug

I used `event.stopPropagation` in the event in the application, but the event can still be executed outside the application.


### Your Example Website or App

https://codesandbox.io/p/sandbox/cool-thunder-mw586z?welcome=true

### Steps to Reproduce the Bug or Issue

## Solidjs component
```
export defualt App() {
  return (
    <button
          style="margin-left: 20px"
          onclick={(event) => {
            console.log("solidjs click");
            event.stopPropagation();
          }}
        >
          click
        </button>
  )
}
```

## index.html
```
<body>
    <div id="root"></div>
    <script src="/src/index.jsx" type="module"></script>
  </body>
  <script>
    document.body.addEventListener('click', () => {
      console.log('click')
    })
  </script>
```

click button of solidjs app, the click event of `document.body` will execute

### Expected behavior

`event.stopPropagation` works fine.

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

_No response_
Ambiguous terms: fine
Questions:
1. What does it mean for `event.stopPropagation` to work fine?
2. Can you clarify what you mean by "the event can still be executed outside the application"?
Clarified requirement: Describe a bug where the `event.stopPropagation` method is used in a Solidjs component, but the event can still trigger the `document.body` click event outside the application. The expected behavior is for `event.stopPropagation` to prevent this from happening.


Clarify this requirement: ### Describe the bug

When using spread on a select element the value will be set before the children are created and this will cause the value to be set to an empty string (this is a browser behavior because no option match).

### Your Example Website or App

https://playground.solidjs.com/anonymous/d2bf2e03-5e3b-4a9c-a5c0-37a62bbc8f9c

### Steps to Reproduce the Bug or Issue

1. Open the example
2. Look at the result

### Expected behavior

The second and third select boxes should have the same option selected.

### Screenshots or Videos

_No response_

### Platform

- OS: Windows
- Browser: Edge
- Version: 113


### Additional context

_No response_
Ambiguous terms: empty string, same option selected
Questions:
1. What does "same option selected" refer to in this context?
2. Can you provide more details on how the value is set before the children are created?
Clarified requirement: Describe a bug where using spread on a select element sets the value before the children are created, resulting in the value being set to an empty string due to no option match. The expected behavior is for the second and third select boxes to have the same option selected.


Clarify this requirement: ### Describe the bug

https://playground.solidjs.com/anonymous/551fc377-eef8-4688-a32e-d136eb295d83

Weather updating onchange is a good idea, or even supported, in my case a bug where by untrack wasn't used at the callsite, it is still strange to see LogComponent which is an unrelated sibling, mount and unmount each time the tickTocktick signal is updated.


### Your Example Website or App

https://playground.solidjs.com/anonymous/551fc377-eef8-4688-a32e-d136eb295d83

### Steps to Reproduce the Bug or Issue

Run playground see unrelated component mount and unmount on each signal (although its not dependent on that signal)

### Expected behavior

Not sure, but not this

### Screenshots or Videos

_No response_

### Platform

Latest

### Additional context

_No response_
Ambiguous terms: strange, good, unrelated, each time, Not sure
Questions:
1. What specific behavior is considered "strange" in this context?
2. Can you clarify what you mean by "unrelated sibling"?
Clarified requirement: Describe the bug in which the LogComponent, an unrelated sibling, mounts and unmounts each time the tickTocktick signal is updated, even when untrack wasn't used at the callsite. The behavior is considered strange and not expected.


Clarify this requirement: ### Describe the bug

When a (focusable) element is flanked by a Show component on either side, a signal triggering both Show components to true will cause the focusable element to lose focus.

Proximally this is caused by the reconcileArray logic using `replaceChild` rather than an insertion method (replacing the focusable element with one of the newly visible Shows, before putting the focusable element back in the DOM). This results in a `blur` event being fired at the focusable element (and no subsequent `.focus` event for it to regain focus).

### Your Example Website or App

https://playground.solidjs.com/anonymous/6a550f0d-b8bd-41cd-840f-491c94b2ec36

### Steps to Reproduce the Bug or Issue

1. Go to the playground link
2. Open the in-playground console
3. Click the Do Show button
4. observe the focusable div gets focused and then immediately blurred

### Expected behavior

I expect that causing (seemingly) unrelated divs to Show will not result in a blur event being fired on the element that has focus. If that is not possible, I expect the element to at least regain focus after the reconciliation is complete

### Screenshots or Videos

_No response_

### Platform

Reproduces on multiple browsers, but mine is`macOS, Chrome Version 113.0.5672.92 (Official Build) (x86_64)`, using latest Solid


### Additional context

_No response_
Ambiguous terms: blur, focus, reconciliation
Questions:
1. What is meant by "reconciliation" in this context?
2. Can you clarify what is expected after the reconciliation process is complete?
Clarified requirement: Describe the bug: When a focusable element is flanked by a Show component on either side, triggering both Show components to true causes the focusable element to lose focus. This is due to the reconcileArray logic using `replaceChild` instead of an insertion method, resulting in a `blur` event being fired at the focusable element without subsequent focus event for it to regain focus.


Clarify this requirement: ### Describe the bug

Normally The resources start at `"rending"` state before they become `"ready"`. When the initial value is passed the resources start at `"refreshing"`, as it's considered a subsequent request of sorts.
But passing `undefined` as the initial value — e.g. when creating a custom primitive with `createResource` and passing the user's parameter strength through as the initial value, which by default will be `undefined` — results in the `"refreshing"` initial state. Which seems a bit odd as `undefined` kinda reads as "user did not defined an initial value" 🙃
So I'm wondering if this is intended as we got an [issue on solid-primitives](https://github.com/solidjs-community/solid-primitives/pull/434) because of this behavior.
Interestingly, the solution to fix this on our side is to check `initialValue !== undefined` and not pass the property at all if it's not defined, which is funny because this is exactly what I would expect resources to do instead of pushing this problem downstream.

### Your Example Website or App

https://playground.solidjs.com/anonymous/dcf0dc7e-6f56-4b30-be43-ed0a850190a4

### Steps to Reproduce the Bug or Issue

Look at the console

### Expected behavior

Both resources should have the same initial state
Ambiguous terms: odd, kinda, exactly, funny
Questions:
1. What are the two initial states of the resources mentioned?
2. What is the expected behavior for the initial state of the resources?
Clarified requirement: Describe the bug where the initial states of the resources are different based on the initial value passed, including when the value is `undefined`. The expected behavior is for both resources to have the same initial state.


Clarify this requirement: ### Describe the bug

Conceptually the signals provided by `mapArray` (index) and `indexArray` (value) are derived directly from the input source array. So accessing them during batch should have a similar effect as accessing memos — force them to be updated immediately.
The fact that they are implemented using roots, signals not memos, etc. are internal details, but it causes them to stay in the past until the `batch` is over, or until they are updated by reading the function returned by `mapArray`.
I'm sure this is a known bug, but it's probably worth having an open issue for it.

### Your Example Website or App

https://playground.solidjs.com/anonymous/31b6b52f-85a6-4fc7-87cc-b46c21430e54

### Steps to Reproduce the Bug or Issue

Clicking the buttons will cause the rendered list to update, changing the indexes of individual items.
But the value of the `index` signal is different depending on if it was read under batch or after it.

### Expected behavior

The derived index signal should always be in sync with the input source.
Ambiguous terms: conceptually, similar, immediately, internal details, past, over, probably, worth, known
Questions:
1. What is the specific issue with the derived index signal when accessed during batch versus after it?
2. How does the current behavior deviate from the expected behavior?
Clarified requirement: Describe the bug related to the derived index signal being out of sync when accessed during batch compared to after it on the provided example website or app. The expected behavior is for the derived index signal to always be in sync with the input source.


Clarify this requirement: ### Describe the bug

Some internal metadata nodes are never cleared up, so they keep consuming memory indefinitely, even if nobody needs them anymore.

### Your Example Website or App

https://playground.solidjs.com/anonymous/b8626377-1d8a-4535-9aed-3bdb438b4e34

### Steps to Reproduce the Bug or Issue

1. Uncomment only the Solid code.
2. Take a heap snapshot
3. Uncomment only the equivalent Oby code.
4. Take a heap snapshot
5. Notice how the Solid code is consuming way more memory, even though the user is basically doing the same thing in both.

To magnify the effect the counter can be increased.

### Expected behavior

Solid's stores should clean up after themselves, and shouldn't consume significantly more memory than Oby's stores.

### Screenshots or Videos

_No response_

### Platform

- OS: macOS
- Browser: Chrome@latest
- Version: 1.6 (I think? The one in the playground)

### Additional context

_No response_
Ambiguous terms: significantly
Questions:
1. What is considered a significant difference in memory consumption between Solid's stores and Oby's stores?
2. How is the counter increased to magnify the effect?
Clarified requirement: Describe the bug where some internal metadata nodes in Solid's stores are not cleared up, leading to indefinite memory consumption, even if not needed. To reproduce, uncomment Solid code, take a heap snapshot, then uncomment Oby code, take another heap snapshot, and observe Solid code consuming more memory. The expected behavior is for Solid's stores to clean up after themselves and not consume significantly more memory than Oby's stores.


Clarify this requirement: ### Describe the bug

When you try to create a new property on an object during store update, and you set it to value `undefined` - a property descriptor is not added to the object, the `in` operator does not see it. The contradicts expected JS behavior: 

```typescript
import { createStore, produce } from "solid-js/store";

let normalObj = {} as any;
normalObj.foo = undefined;

// returns true
console.log("foo" in normalObj);
console.log(Object.getOwnPropertyDescriptors(normalObj));

let [val, setVal] = createStore({} as any);

setVal(
  produce((x: any) => {
    x.foo = undefined;
    // returns false
    console.log("foo" in x);
    console.log(Object.getOwnPropertyDescriptors(x));
  })
);
```

Playground with above code: https://playground.solidjs.com/anonymous/d71e1157-190b-4eca-94d1-cfab4e70c3c1

### Your Example Website or App

https://playground.solidjs.com/anonymous/d71e1157-190b-4eca-94d1-cfab4e70c3c1

### Steps to Reproduce the Bug or Issue

1. Go to playground: https://playground.solidjs.com/anonymous/d71e1157-190b-4eca-94d1-cfab4e70c3c1
2. Observe the console.

### Expected behavior

A property descriptor should be created when a new property is assigned, even if assigned value is `undefined`.

### Screenshots or Videos

_No response_

### Platform

- OS: Windows 11
- Browser: Microsoft Edge
- Version: 108.0.1462.54 (Official build) (64-bit)


### Additional context

_No response_
Ambiguous terms: undefined
Questions:
1. What is meant by "store update" in this context?
2. Can you clarify the expected behavior when a property descriptor is created?
Clarified requirement: Describe a bug where when trying to create a new property on an object during a store update and setting it to the value `undefined`, a property descriptor is not added to the object, causing the `in` operator to not see it. This behavior contradicts the expected JavaScript behavior. The expected behavior is that a property descriptor should be created when a new property is assigned, even if the assigned value is `undefined`.


Clarify this requirement: ### Describe the bug

Setting a getter-function on a key that has already been initialized in a store with `setStore` will not create a reactive getter, unlike when you set the getter-function while initializing a key.

This can be solved (as @thetarnav suggested) by doing a shallow merge.

```
setStore({
  alreadyDefinedKey: {
    get get() {
      return store.value;
    },
  },
});
```

but this feels like it should be supported without having to shallow merge objects (i personally try to avoid shallow merging as much as possible, because of the fact you can accidentally create multiple paths leading to the same reactive value and that can have unexpected results)

### Your Example Website or App

https://playground.solidjs.com/anonymous/972b3aec-d7df-4ec0-9a68-c8b8b60785e3

### Steps to Reproduce the Bug or Issue

```
const [store, setStore] = createStore({ value: 0, alreadyDefinedKey: {}});

setStore('alreadyDefinedKey', {
 get get() {
   return store.value
 }
})

setStore('newKey', {
 get get() {
   return store.value
 }
})

setStore('value', 1)
```

### Expected behavior

I expect in the above example store.alreadyDefinedKey.get to be 1, just as store.newKey.get, but instead it is the old value 0.

### Screenshots or Videos

_No response_

### Platform

- OS: iOS
- Browser: firefox
- Version: 12.1.1


### Additional context

_No response_
Ambiguous terms: fast, user-friendly, shallow merge, reactive, unexpected, supported
Questions:
1. What is meant by "reactive getter" in this context?
2. Can you clarify what is meant by "shallow merge" and why it is necessary in this scenario?
Clarified requirement: Describe an issue where setting a getter-function on a key that has already been initialized in a store with `setStore` does not create a reactive getter, unlike setting the getter-function during initialization. The problem can be resolved by performing a shallow merge, as suggested by @thetarnav. The issue is illustrated with an example code snippet and the expected behavior is explained.


Clarify this requirement: ### Describe the bug

Within a `batch` call, when setting a signal's value to a new value, and then back to the original value, effects are still run for the "changed" value.

This could be desired behavior, but I think an argument could be made for the behavior I'm expecting here.

The playground I've linked is a contrived example. I encountered this when trying to batch a couple store actions together, that involved this scenario of a value being changed, and then changed back to the original value at the start of the `batch` operation.

### Your Example Website or App

https://playground.solidjs.com/anonymous/157e35f6-d812-4798-8222-082d559eec5f

### Steps to Reproduce the Bug or Issue

1. Go to the [playground link](https://playground.solidjs.com/anonymous/157e35f6-d812-4798-8222-082d559eec5f)
2. Switch to the Console output in dev tools
3. Click the 'Click' button
4. Despite the final value of `num()` being unchanged at the end of `batch(...)`, the effect is run, and the "new" value of `num()` is logged to the console. `memoNum()` naturally does not have the same issue.

### Expected behavior

I expect changes to signal values within `batch` to be "batched", with only the end result being considered in determining what changed and what effects to run. Note that when calling `setNum(0)` when `num()` is already `0`, effects are not rerun.

Sorry I know this is probably an inaccurate expectation of what `batch` should do. The docs description doesn't make a lot of sense to me:
> \# batch
Holds executing downstream computations within the block until the end to prevent unnecessary recalculation. [Solid Store](https://www.solidjs.com/docs/latest/api#createstore)'s set method, [Mutable Store](https://www.solidjs.com/docs/latest/api#createmutable)'s array methods, and Effects automatically wrap their code in a batch.

### Screenshots or Videos

_No response_

### Platform

N/A

### Additional context

_No response_
Ambiguous terms: described, could be desired, think, could be made, expecting, probably, inaccurate
Questions:
1. What specific behavior is being observed when the signal's value is set to a new value, then back to the original value within a `batch` call?
2. Can you clarify what you mean by effects being "run for the 'changed' value"?
Clarified requirement: Describe the behavior observed when setting a signal's value to a new value, then back to the original value within a `batch` call, and explain the impact of effects being run for the "changed" value.


Clarify this requirement: In my opinion people expect deeply proxied objects that can intercept reads and writes to work identically to JS objects, with basically the only difference being that the proxy is aware of every read and write that goes through the proxied object.

Stores created with `createMutable` break that assumption in some ways that I think can cause bugs, and in ways that are not documented, in case the present behavior is intentional, so I think the following issues should be addressed:

- [ ] Setting a property to `undefined` deletes the property. That's just not what plain objects do. Repro: https://playground.solidjs.com/anonymous/b3976972-e6bb-42ef-8481-dc07bb203009
- [ ] A bunch of extra properties are attached to proxied objects. I don't think any detectable edits to the object that the user didn't explicitly perform should be performed, in particular in this case we can use WeakMaps instead. Repro: https://playground.solidjs.com/anonymous/577681f3-d496-4354-97f2-51bff69025f9
- [ ] Some interceptable writes are not intercepted, kinda creating a hole in the "observer membrane". Ideally this should get fixed to make `createMutable` work more predictably and reliably. In particular the `defineProperty` proxy trap is not implemented, so `Object.defineProperty` is not intercepted. Repro: https://playground.solidjs.com/anonymous/aea88d65-fea3-4cb8-a53a-56402667d0af
Ambiguous terms: identically, basically, deeply, user didn't explicitly perform, predictably, reliably
Questions:
1. What specific behaviors are expected from deeply proxied objects when intercepting reads and writes?
2. Can you clarify what you mean by "detectable edits to the object that the user didn't explicitly perform"?
Clarified requirement: - Some interceptable writes are not being intercepted, creating a gap in the "observer membrane." It is crucial to fix this to enhance the predictability and reliability of `createMutable`. Specifically, the `defineProperty` proxy trap is not implemented, leading to `Object.defineProperty` not being intercepted.


Clarify this requirement: ### Describe the bug

click not disabled when wrapping button in fieldset

This is the same issue as [#7711 in react](https://github.com/facebook/react/issues/7711)

```tsx
<fieldset disabled>
  <button onClick={() => alert('clicked')}>
    click me here and <span style={{color: 'red'}}>here</span>
  </button>
</fieldset>
```


### Your Example Website or App

https://stackblitz.com/edit/solidjs-templates-jeskz7?file=src/App.tsx

### Steps to Reproduce the Bug or Issue

Go to the stackblitz
Try to click the button both on the gray and red text
That'll show that clicking directly on the button doesn't trigger the onClick, while clicking on the child element will.

### Expected behavior

Clicking on anything within the button should not trigger the onClick handler on the button if the fieldset is set to disabled.

### Screenshots or Videos

_No response_

### Platform

- OS: [e.g. macOS, Windows, Linux]
- Browser: [e.g. Chrome, Safari, Firefox]
- Version: [e.g. 91.1]


### Additional context

https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#concept-fe-disabled
Ambiguous terms: disabled, click, trigger, within, handler
Questions:
1. What is meant by "click not disabled" in this context?
2. Can you clarify the expected behavior when mentioning "clicking on anything within the button"?
Clarified requirement: Describe a bug where the `onClick` event is not disabled when a button is wrapped in a disabled `fieldset`. The expected behavior is that clicking on anything within the button should not trigger the `onClick` handler if the `fieldset` is disabled.


Clarify this requirement: ### Describe the bug

I've just implemented a custom renderer to [GTK4](https://gtk.org/), using solid-js/universal. It works pretty well, even though it requires some little workarounds.

Gtk.Box, which is one of the most used GTK widgets, has a method insert_child_after(child, previous_sibling), while solid's universal insertNode only provides the sibling _after_:
From the solid [universal renderer example](https://github.com/solidjs/solid/tree/main/packages/solid/universal#example):
```js
insertNode(parent, node, anchor) {
    parent.insertBefore(node, anchor);
},
```

what GTK requires me to do:
```js
insertNode(parent, node, anchor) {
    parent.insert_child_after(node, ???????);
},
```

### Steps to Reproduce the Bug or Issue

Implement a custom native renderer using gtk

### Expected behavior

I think solid may already have the information about the previous_sibling internally. If that's the case, it would be nice exposing that sibling in insertNode so that people can write
```js
insertNode(parent, node, next_sibling, prev_sibling) {
    parent.insert_child_after(node, prev_sibling);
}
```

I think I'm able to workaround this issue for many GTK widgets, but having the prev_sibling directly available would be nicer
Ambiguous terms: nice, many, some, pretty well
Questions:
1. What specific information about the previous sibling is needed in the insertNode function?
2. How does the current implementation in GTK differ from what is available in solid's universal insertNode function?
Clarified requirement: Describe the bug related to implementing a custom renderer using GTK4 and solid-js/universal, where the insertNode function in solid's universal renderer lacks direct access to the previous sibling, which is necessary for GTK's insert_child_after method. The request is to modify insertNode to include access to the previous sibling for better compatibility with GTK widgets.


Clarify this requirement: ### Describe the bug

This is a sequel to #955, where the same issue occurred with `class`/`className`.

```jsx
<input value={undefined}/>
```

compiles to

```js
const _el$ = _tmpl$.cloneNode(true);
_el$.value = undefined;
return _el$;
```

Because of the infinite wisdom of the DOM `.value` interface, this causes the value to be set to the *string* `"undefined"`. 🙁 

[Reported on Discord](https://discord.com/channels/722131463138705510/722349143024205824/983056839170199612)

### Your Example Website or App

https://playground.solidjs.com/?hash=-335339517&version=1.4.1

### Steps to Reproduce the Bug or Issue

1. Go to [Playground link](https://playground.solidjs.com/?hash=-335339517&version=1.4.1)
2. Observe input value.

### Expected behavior

I'm not sure there's a clear expectation here, but I probably expected a blank input, with the intuition that `attr={undefined}` is equivalent to omitting `attr` altogether. Instead I'm seeing the string "undefined" in the input.

### Screenshots or Videos

![image](https://user-images.githubusercontent.com/2218736/172077056-eccce941-792d-4b18-96d2-a385ed78072a.png)


### Platform

- OS: Windows
- Browser: Chrome
- Version: 102


### Additional context

FWIW, [here's a CodeSandbox](https://codesandbox.io/s/react-input-value-undefined-0my4b3?file=/index.js) showing that `value={undefined}` renders blank in React.

Is it worth reviewing for other DOM interfaces like these?
Ambiguous terms: clear expectation, intuition, probably, worth, other
Questions:
1. What specific issue occurred with `class`/`className` in the previous situation?
2. What exactly is the bug being described in this context?
Clarified requirement: Describe the bug that occurred with `class`/`className` in a previous situation and explain the issue related to using `value={undefined}` in the current context.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

![Image](https://github.com/user-attachments/assets/23e52aa6-99ec-49d7-be41-47dd4a61724c)

Having to go and change JSON for each new data seems cumbersome and creating new copy of the same request and change body also seems like clutter. 

### Describe the solution you'd like

Would it be easier if we could select request body variation like we select form-data, raw or binary, etc. If we could have variation of json request body that would make testing easier. 

### Describe alternatives you've considered

_No response_

### Additional context

While testing of API I use repeated data a lot and use few default data or pattern. And changing the json data manually and trying the api again is such a hastle. Creating copy of request is the way for now to get around this. Imagine making copy of most of routes.
Ambiguous terms: cumbersome, easier, clutter, default
Questions:
1. What specific feature is being requested in relation to selecting request body variation?
2. Can you clarify what is meant by "default data or pattern" in the context of testing API?
Clarified requirement: Is there a request for a feature that allows users to select different variations of request body, such as form-data, raw, or binary, for easier testing of APIs? Additionally, the feature should address the need for managing repeated data and patterns efficiently during API testing.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When entering a variable inside the value input of another variable (e.g. a variable named `API_URL` received the value `{{ API_URL_STAGING }}` - The value appears as a simple text, and doesn't provide typeahead/auto-completion

To be clear - the functionality of nesting variable does work, and there is no problem with that (in the previous example - the value of `API_URL_STAGING` is being used for `API_URL` as expected)

![Image](https://github.com/user-attachments/assets/86dd214a-94b7-4893-a507-6dfc0c18e2b1)

### Describe the solution you'd like

1. While typing the value of a variable, and entering `{{` - the autocomplete UI used for variables in other parts of the app should appear.
2. When a variable has another variable in it's value (`{{ XYZ }}`) it should be visually presented as a variable, with the hover tooltip that shows the value, the text color representing validitiy, etc...
3. The auto-complete UI component that helps select a variable from the list, should show the calculated value that will be used, rather than the raw text (currently it shows the name of the nested variable - screenshot 1)
4. The tooltip that shows the value of the variable should also show the calculated value, rather than the raw text (Screenshot 2).


#### Screenshot 1
![Image](https://github.com/user-attachments/assets/b1aba254-2f96-49cf-b515-584b3827132d)

#### Screenshot 2
![Image](https://github.com/user-attachments/assets/62b42f5d-7455-43b0-8ee7-f89a034d55ec)

### Describe alternatives you've considered

_No response_

### Additional context

Nested/canonical variables seems like a hidden feature, that might even not be planned, but still works - and has a great value when you need to store multiple.

P.S I know that the environments feature exists and better be used for the examples I've shown. please focus on the essence and not the example 😄
Ambiguous terms: simple, clear, visually presented, tooltip, calculated value, raw text, essence
Questions:
1. What does "validity" refer to in the context of representing variables visually?
2. Can you provide an example of what you mean by "calculated value" versus "raw text" in the context of nested variables?
Clarified requirement: Is there an existing request for a feature that enhances the visual representation and functionality of nested variables in the autocomplete UI component within the app?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

The Postman-generated OpenAPI specification of my collection shows no details about 90% of my POST requests

### Describe the solution you'd like

To allow types to be added for multipart/form-data body requests, since this is easier to read within the Postman application and is used a lot.

### Describe alternatives you've considered

Manually updating the generated OpenAPI spec to provide these details, but the API is far too big for this to write it for every single entry

### Additional context

It would just be wonderful if this exact menu would be added for multipart/form-data body parameters, and it doesn't sound unreachable.

![Image](https://github.com/user-attachments/assets/2d611d80-9a7e-439b-be4b-e8f177b9c83f)
Ambiguous terms: easier, a lot, big, wonderful, unreachable
Questions:
1. What specific types are you referring to when mentioning "types to be added for multipart/form-data body requests"?
2. Can you clarify what you mean by "this exact menu" that you wish to be added for multipart/form-data body parameters?
Clarified requirement: Is there an existing request for adding specific types to multipart/form-data body requests in the Postman application, and have duplicates been addressed accordingly? Additionally, can a detailed description be provided for the exact menu that should be included for multipart/form-data body parameters?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Disable function to exclude some requests for certain purposes.

Hello, i'd like to suggest you a new feature, that i need to use and think that, it might be useful for other users, too.
We may shortly call it as "disable request" function. In the collection, at any part of it, (at request level), when i right click, there should be an option, that a request might be disabled. It sohuld be there but in a grey color (it means, it is deactivated).Goal is, i don't want it to be triggered during folder run or collection run. Ok, there is an option to exclude them on the runner level but i have many regression tests and i do not want to exclude some of them from running.... If there is a disable function, i can set those tests already to inactive status and they'll never be called during folder or collection runs and i'll not be in need of manuel exclusion of them...
Thanks in advance for your taking it into consideration.
best regards,
zafer

### Describe the solution you'd like

disabling any request by clicking right-mouse and choosing "disable request" in order to deactivate it to be run during collection or folder running.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: disable, deactivate, inactive
Questions:
1. What is the difference between disabling, deactivating, and making a request inactive?
2. Can a disabled request be re-enabled later?
Clarified requirement: Implement a "disable request" function that allows users to deactivate specific requests within a collection, preventing them from being triggered during folder or collection runs. The disabled requests should be visually indicated in grey color and should be able to be re-enabled if needed.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

### Problem Statement
The current horizontal tab bar in Postman presents significant usability challenges for developers:
- Limited visibility when multiple tabs are open
- Cumbersome horizontal scrolling
- Difficulty in quickly identifying and switching between tabs

### Describe the solution you'd like

### Proposed Solution
Implement a vertical tab layout inspired by Visual Studio Code, offering:
- Vertical tab arrangement along the application window's side
- Enhanced readability and navigation
- Improved developer productivity

### Describe alternatives you've considered

### Detailed Feature Specifications
- [ ] Replace horizontal tab bar with a vertical tab layout
- [ ] Maintain existing tab functionality (open, close, drag-and-drop)
- [ ] Add icons for quick visual tab identification
- [ ] Provide toggle option in settings to switch between horizontal and vertical layouts

### Additional context

### Key Benefits
- ✅ Improved tab visibility
- ✅ Reduced horizontal scrolling
- ✅ Faster tab switching
- ✅ More compact UI

### User Experience Improvements
- Tabs listed vertically with clear hierarchy
- Active tab prominently highlighted
- Easy-to-read tab names and icons
- Minimal screen space consumption

### Technical Considerations
- Ensure compatibility with existing Postman UI
- Provide smooth transition between tab layouts
- Maintain current tab management functionality

### Example Visual Reference
Imagine a side panel similar to VS Code:
- Vertical tab list
- Clean, intuitive design
- Quick tab identification and switching

---

🚀 Help us make Postman more developer-friendly by revolutionizing tab management!
Ambiguous terms: revolutionizing, user-friendly, improved, enhanced, quick, clear, easy-to-read, intuitive
Questions:
1. Is there a specific timeframe for implementing this vertical tab layout?
2. Are there any constraints or limitations that need to be considered when developing this feature?
Clarified requirement: Is there a specific timeframe and any constraints or limitations for implementing a vertical tab layout in Postman to replace the current horizontal tab bar?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I like to keeo my home directory clean on Linux Desktop. Every folder I put there is intentional, while the unintentional folder is stored as dotfiles, etc. So I won't see any unrelated directory other than the standard of xdg-user-dirs.

I notice that upon using Postman, it will always create that default working directory until you change the default working directory.

I have no idea why you guys choose that directory on $HOME directly, it doesn't have the same level of importance as xdg-user-dirs or something. This makes me uncomfortable because I have a lot of computers that I set a certain way. So, I have to open postman on every single computers to change that default working directory.

### Describe the solution you'd like

Can you guys change the default working directory to be at either of these:

- `$HOME/Documents/Postman`
- `$HOME/.local/share/Postman`

It's better than way. Take a look at Telegram, they respect the xdg-user-dirs

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: clean, intentional, unintentional, standard, important, uncomfortable, certain, better, respect
Questions:
1. What is meant by "xdg-user-dirs"?
2. Can you clarify what you mean by "respect the xdg-user-dirs"?
Clarified requirement: Is there an existing request for changing the default working directory in Postman to either `$HOME/Documents/Postman` or `$HOME/.local/share/Postman` in order to align with the xdg-user-dirs standard?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When multiple people are contributing to Postman API Automation Tests, and when conflict arises on pulling changes from the source, there is an option to either keep source or destination but not both in the conflict resolution process.

![Image](https://github.com/user-attachments/assets/042e6455-a7bc-49eb-aece-b73aaf34ce5a)

### Describe the solution you'd like

I would like to see an option that allows me to have both source and destination changes. 

### Describe alternatives you've considered

As an alternative, we end up creating a new fork from the source and manually copy paste our changes which may not be ideal.

### Additional context

This issue is experienced when changes to collection variables are made. We are unable to retain variables in both source and destination.
Ambiguous terms: ideal
Questions:
1. What specifically is meant by "ideal" in this context?
2. Can you clarify what is meant by "retain variables in both source and destination"?
Clarified requirement: Is there an existing request for a feature that allows retaining variables in both the source and destination when conflicts arise during pulling changes in Postman API Automation Tests?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

No

### Describe the solution you'd like

It would be great if Postman allowed users to import and apply custom themes. While the existing themes are useful, many users would benefit from the ability to fully customize the UI to fit their preferences and ergonomic needs.

Why is this important?
• Improved Visual Comfort: Custom themes could help reduce eye strain by allowing users to adjust colors, contrast, and brightness.
• Personalization & Branding: Teams could create a cohesive look across tools, making Postman feel more integrated into their workflow.
• Community Engagement: A custom theme feature would encourage the community to share and develop themes, similar to what’s seen in other development platforms.

Suggested Implementation:
1. Enable theme customization via configuration files (e.g., JSON, CSS).
2. Provide an option to import/export themes.
3. Consider a community-driven theme repository where users can share their designs.

Are there any plans to support this?

This feature could significantly enhance the Postman experience for developers and teams alike. Looking forward to feedback from the team and the community!

### Describe alternatives you've considered

Enable theme customization via configuration files (e.g., JSON, CSS)

### Additional context

_No response_
Ambiguous terms: great, custom, fully customize, fit their preferences, ergonomic needs, improved, benefit, visual comfort, reduce, adjust, personalization, branding, cohesive look, integrated, community engagement, encourage, share, develop, suggested, consider, significantly enhance
Questions:
1. Are there any specific requirements or limitations for the custom themes that users can import and apply in Postman?
2. Is there a specific timeline or priority for implementing this feature in Postman?
Clarified requirement: Is there a specific plan to implement the feature that allows users to import and apply custom themes in Postman, considering any requirements or limitations, and with a clear timeline for implementation?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Currently a postman environment export looks like this
```
{
  "id": "xxxxxxx",
  "name": "Local Environment",
  "values": [
   {
    "key": "token",
    "value": "",
    "type": "default",
    "enabled": true
    }
  ]
}
```

We would like to be able to setup a new user on postman with a custom token for each of their environments. But we would like to set it up completely simply during environment import.

### Describe the solution you'd like

Could we allow a new field, say `"current": "__customtoken__"` that allows postman to import this file with the current value of `__customtoken__`? This token is specific for each of our environments (like qa, staging, production) and unique for each user.

### Describe alternatives you've considered

I have looked at setting up 1password with vault but that seemed a bit more work to setup than I'd like.

### Additional context

_No response_
Ambiguous terms: completely simply, unique, bit more work
Questions:
1. What does "completely simply" mean in this context?
2. Can you provide more clarity on what is meant by "unique" and "bit more work"?
Clarified requirement: Is there an existing request for the feature of allowing a new field, such as `"current": "__customtoken__"`, in a Postman environment export file to import a custom token specific to each user's environments (e.g., qa, staging, production) during environment import?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

GraphQL collection is not visible in VScode extension.

### Describe the solution you'd like

GraphQL collection is not visible in VScode extension.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: visible
Questions:
1. What does "visible" mean in the context of the GraphQL collection not being visible in the VScode extension?
2. Can you clarify what you mean by "GraphQL collection" in this requirement?
Clarified requirement: Is there an existing request for the feature related to making the GraphQL collection visible in the VScode extension? The feature request should address the problem of the GraphQL collection not being displayed in the VScode extension.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Better visualization of responses in postman

### Describe the solution you'd like

Can you add a SVG feature to postman flow's display? 
I upload a file:

```
<svg>
 <circle rx=5 ry=5 r=3 color="{{value1}}"><text>{{value2}}</text><circle>
</svg>
```

you display the file in postman's flow as a display block

### Describe alternatives you've considered

Not using postman, export to node bind to svg. I already do this

### Additional context

_No response_
Ambiguous terms: Better, visualisation, feature, add, SVG, display, upload, file, block, alternative
Questions:
1. What specifically do you mean by "Better visualization of responses in postman"?
2. When you mention adding an SVG feature to Postman flow's display, what exactly do you want the feature to do?
Clarified requirement: Is there an existing request for a feature that involves enhancing the way responses are displayed in Postman? If so, please specify the details of the request. Additionally, can you provide a detailed description of the functionality you would like the SVG feature to have when added to Postman flow's display?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Sometimes I have several dangerous requests. By dangerous I mean that if I run it by mistake or confusion, I can delete a lot of data.


### Describe the solution you'd like

I'd like the request context menu to have a lock option. This lock would disable the Send (and Send and Download) button to prevent them from being executed accidentally. Of course, if a request is already locked, the unlock option should appear in the context menu.

### Describe alternatives you've considered

The only workaround I use to avoid accidental executions is to create a variable with the domain name, and to "disable" the request I change that variable to a non-existent domain name.

### Additional context

Context menu:

![Image](https://github.com/user-attachments/assets/38491ee4-5d03-4c9a-84ca-17aa278e0f91)

Send button:

![Image](https://github.com/user-attachments/assets/7b76a497-836f-4454-a81a-386a2eb52b10)

Thanks.
Ambiguous terms: dangerous, accidentally, disable, accidental
Questions:
1. What specific actions would trigger the dangerous requests?
2. How does the current workaround with the domain name variable prevent accidental executions?
Clarified requirement: Is there an existing request for a feature that adds a lock option to the request context menu? The lock option should disable the Send and Send and Download buttons to prevent accidental executions. If a request is already locked, an unlock option should be available in the context menu.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I noticed that there is already support for switching to Japanese and would like to add support for Chinese

### Describe the solution you'd like

 switch to Chinese

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: switch, support, Chinese
Questions:
1. What specific action is meant by "switch to Chinese"?
2. Can you clarify what is meant by "support for Chinese"?
Clarified requirement: Is there an existing request for adding support to switch the language interface to Chinese? I have searched for duplicates and know they will be closed. I noticed there is support for switching to Japanese and would like to add similar support for Chinese. The solution I'd like is the ability to switch the language interface to Chinese.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

hi , please add Comments section in vs code extensions

### Describe the solution you'd like

hi , please add Comments section in vs code extensions

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: hi, Comments section, vs code extensions
Questions:
1. What specific functionality should the "Comments section" in VS Code extensions provide?
2. Can you clarify what you mean by "vs code extensions"?
Clarified requirement: "Is there an existing request for adding a Comments section to VS Code extensions? I have searched for duplicates and know they will be closed. The feature request is to include a specific functionality in the Comments section of VS Code extensions."


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have to copy and paste tokens into <https://jwt.ms> or similar every time I want to inspect the token contents. It would be nice if I could quickly see the JSON components of the token inside Postman.

### Describe the solution you'd like

I would like a small UI on the Authorization screen for OAuth to show decoded token values when a token has been generated.

### Describe alternatives you've considered

Bruno has this feature in its new OAuth rework.

### Additional context

_No response_
Ambiguous terms: quickly, nice, small, decoded
Questions:
1. What specific information should be included in the JSON components of the token?
2. Can you clarify what "decoded token values" refer to in this context?
Clarified requirement: Is there an existing request for a feature where a small UI on the Authorization screen for OAuth shows specific JSON components of a generated token, similar to the feature in Bruno's OAuth rework?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman limits the size of stored response bodies to 300kb, and anything larger is not persisted and cannot be viewed in a collection run. Our use case frequently includes responses greater than this limit, and not being able to review them makes reviewing and composing tests for these requests more difficult.

<img width="390" alt="Image" src="https://github.com/user-attachments/assets/26530097-f01f-4217-9846-9bdc22b0543d" />

There is a setting under Settings > General > Max Response size that allows the user to specify how large of a response body to download. Yet despite setting this value to 0 (no limit) or X MB, responses above 300kb are not persisted. (This may require a separate bug report)

<img width="663" alt="Image" src="https://github.com/user-attachments/assets/81e24e11-fc02-4e26-8ac7-7d24bc840720" />

### Describe the solution you'd like

I would like for either:

1. The Max Response Size setting to actually allow the user to inspect response bodies of a size they specify, or
2. The default max response size limit in Postman Collection Runner to be increased, or
3. Some combination of the two.

### Describe alternatives you've considered

The Postman console has an even lower limit, at just 10kb, making this not a viable alternative. Presently, we have to test manually via the web browser and inspect the response bodies via Dev Tools Network tab.

<img width="523" alt="Image" src="https://github.com/user-attachments/assets/86073427-f869-480e-85fb-08a549640c49" />

### Additional context

_No response_
Ambiguous terms: large, difficult, large, low, viable
Questions:
1. What specific size limit is causing issues with storing response bodies in Postman?
2. How does changing the "Max Response Size" setting currently affect the persistence of response bodies?
Clarified requirement: Is the feature request to address the issue where response bodies larger than 300kb are not persisted in Postman, despite setting the "Max Response Size" to 0 or X MB, by either allowing users to inspect response bodies of a specified size, increasing the default max response size limit in Postman Collection Runner, or a combination of both?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Can we have the ability to create API keys that are not tied to a particular user? When team members leave, our CI jobs break. Please allow API keys at the team level that we can manage. 

### Describe the solution you'd like

Please allow API keys at the team level that we can manage. API keys are currently created by individual users. So when they leave the team, automated jobs will fail.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: allow, manage, team level, individual users
Questions:
1. What specific actions do you mean by "allow" and "manage" in the context of API keys?
2. Can you clarify what you mean by "team level" and "individual users" in this scenario?
Clarified requirement: Is there an existing request for the feature of creating API keys that are not tied to a particular user? Our team needs the ability to generate API keys at a team level to avoid CI job failures when team members leave. This feature should enable managing API keys collectively for the team, rather than relying on individual users to create them.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Being a postman free edition user and enterprise version user, I often feel there must be an option to close certain collection i.e., all the requests inside the collection must be enabled only if the user open the collection again. 
Problem statement:
As a QA engineer, I duplicate collections and work on the duplicated collection because my original collection is working well and frozen. when working in this way there is a chance I may edit the original collection. This will end up in messing up the collections maintained. 


### Describe the solution you'd like

Feature request:
There should be an option to close collections i.e., all the requests (opened tabs on the collection & the requests under the collection) must be disabled. This way editing the unindented request will be solved. As of now postman is retaining the data in all the opened tabs and this must be retained as well.
The feature must be similar to close project in Eclipse IDE.

### Describe alternatives you've considered

As of now I am consciously closing all the source collections when I duplicate the collections.

### Additional context

_No response_
Ambiguous terms: option, close, disabled, similar, retaining
Questions:
1. What is meant by "close collections" in this context?
2. Can you clarify what is expected when the feature request mentions "retaining the data in all the opened tabs"?
Clarified requirement: Is there an existing request for a feature in Postman where users can close collections, disabling all requests within them until the collection is reopened? The feature should prevent accidental editing of the original collection when working on duplicates. The behavior should be similar to closing a project in Eclipse IDE, retaining data in all opened tabs.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Yes, Initially I reported this as a bug (https://github.com/postmanlabs/postman-app-support/issues/13481) because it was previously working on postman. 

However, as it was suggested here (https://community.postman.com/t/cors-issue-with-postman-app-on-macos/75978/5?u=supply-cosmonaut-254) I'm creating this as a feature request.

### Describe the solution you'd like

Given a local service returning an openapi.json file, allow it to be imported from localhost (avoiding CORS errors) using the existing import functionality in postman desktop app.  

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: fast, user-friendly, problem, solution, alternatives, additional context
Questions:
1. What is the specific feature being requested in this case?
2. Can you clarify how the existing import functionality in the postman desktop app currently works?
Clarified requirement: Is there an existing request for a feature that allows importing a local service's openapi.json file from localhost to avoid CORS errors using the import functionality in the postman desktop app?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Occasional retesting of some of our prompts is cumbersome and a really anoying experience, but with the new AI request type things are looking up. Some of our prompts use Perplexity though because of the ability to do web searches. Gemini 2.0 flash supports this too now (it's a tool called Google grounding) and more providers are adding this.


### Describe the solution you'd like

1. Add Gemini support for google grounding (searching)
2. Support for Perplexity (sonar, sonar-pro, sonar-reasoning, sonar-reasoning-pro)

### Describe alternatives you've considered

NA

### Additional context

NA
Ambiguous terms: cumbersome, annoying
Questions:
1. What is meant by "Perplexity" in the context of the prompts?
2. Can you clarify what is meant by "Gemini support for google grounding"?
Clarified requirement: Is there an existing request for adding Gemini support for google grounding (searching) and support for Perplexity (sonar, sonar-pro, sonar-reasoning, sonar-reasoning-pro) to the prompts?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Yes, currently Postman provides a JSON viewer, but it lacks some advanced functionalities that would significantly improve usability.

    Large JSON responses can be difficult to navigate.
    Searching for specific keys or values within JSON is not intuitive.
    Collapsing or expanding deeply nested objects requires manual scrolling.
    The current formatting and indentation could be improved for better readability.

These limitations make it challenging for developers to efficiently analyze and debug API responses within Postman. 🚀

### Describe the solution you'd like

I propose enhancing the Postman **JSON Viewer** with the following improvements to make API response analysis more efficient:  

- **Tree View Mode** – Introduce a structured tree view that allows users to visualize JSON data in a hierarchical format, making it easier to navigate nested objects.  
- **Collapsible/Expandable Sections** – Allow users to easily expand or collapse deeply nested JSON objects for better navigation.  
- **Search & Highlighting** – Enable a built-in search function that highlights matching keys and values within large JSON responses.  
- **Better Formatting & Indentation** – Improve JSON readability with more structured formatting and consistent indentation.  
- **Custom Themes & Color Coding** – Provide dark mode compatibility and customizable syntax highlighting for improved user experience.  
- **Side-by-Side View for Comparison** – Allow users to compare multiple JSON responses side by side within Postman.  

These improvements would make it easier for developers to analyze complex API responses without needing third-party tools.

### Describe alternatives you've considered

- Using external JSON viewers like JSONLint or VS Code for better readability and search functionality.  
- Copying JSON responses into browser-based formatters, which adds extra steps and slows down the workflow.  
- Manually expanding and collapsing nested objects in Postman, which becomes difficult for large JSON responses.  

A built-in **Tree View Mode** and improved JSON formatting in Postman would eliminate the need for these workarounds.

### Additional context

Many

![Image](https://github.com/user-attachments/assets/6ad2cf08-1ced-48ab-871f-58ceeba53acb)

 developers work with large and complex JSON responses daily, and a more advanced JSON viewer would improve efficiency when analyzing API responses.  

Other API tools provide tree view functionality and enhanced formatting, making it easier to navigate nested data structures. Adding these features to Postman would streamline debugging and reduce reliance on external tools.  

If needed, I can provide example JSON responses where the current viewer becomes difficult to use.
Ambiguous terms: advanced, efficient, improved, better, easier, streamline
Questions:
1. What specific functionalities are considered advanced and lacking in the current Postman JSON viewer?
2. How would the proposed improvements in the JSON viewer enhance the efficiency of analyzing API responses?
Clarified requirement: Is there an existing request for enhancing the Postman JSON Viewer to address specific limitations and provide advanced functionalities that would improve the efficiency of analyzing API responses?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman does not allow disabling pongs for websocket connections. It automatically responds to pings from the server. This makes it impossible to test that a websocket server properly implements timeout logic.

There is a related ticket https://github.com/postmanlabs/postman-app-support/issues/10956, but they are not the same issue.

### Describe the solution you'd like

Postman should provide a toggle to disable auto-pongs for websocket connections.

Even better would be a way to manually trigger pong frames, but that would just be a nice to have.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: fast, user-friendly, impossible, properly, timeout, better, nice to have
Questions:
1. What is the purpose of disabling auto-pongs for websocket connections in Postman?
2. How would manually triggering pong frames be beneficial in this scenario?
Clarified requirement: Is there an existing request for a feature in Postman where there should be an option to disable auto-pongs for websocket connections and potentially manually trigger pong frames?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

API endpoint is sending me a Excel file in response. I am not able to view or download the file.

### Describe the solution you'd like

Add a feature where one can view and download the file.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: view, download
Questions:
1. What specific actions do you mean by "view" and "download" in the context of the Excel file?
2. Are there any specific requirements or limitations for the feature you are requesting?
Clarified requirement: Is there an existing request for a feature that allows users to view and download an Excel file received through an API endpoint? The feature should provide clear functionality for both viewing and downloading the file.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

If you are running tests from a large collection or folder that repeats tests for different users, there is no way to able to select specific folders of tests or what tests came from where in the run results
For example if you have a similar request structure to the below
![Image](https://github.com/user-attachments/assets/2ae0ccc2-d703-49e9-be3d-e42c845cd564)
You can only singularly select/deselect requests and the results don't show what folder the request was from

![Image](https://github.com/user-attachments/assets/3d5ce17e-bb88-4bd2-91bd-0f42cd814763)

### Describe the solution you'd like

- Organise the tests in the run tab in a folder hierarchy
- Be able to (de)select requests by folder
- Show the folder of the request in the results or Organise the results in the run tab in a folder hierarchy

### Describe alternatives you've considered

Adding the information to the request name and not using folders... 🤮 

### Additional context
Ambiguous terms: able, specific, large, different, similar, singularly, show, folder, hierarchy, (de)select, organise, alternative
Questions:
1. What type of requests are being referred to in this context?
2. How would the folder hierarchy be structured in the solution?
Clarified requirement: Is there an existing request for a feature that allows organizing tests in a folder hierarchy in the run tab, enabling the (de)selection of requests by folder, and displaying the folder information in the results?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

We frequently have requests whose names do not include a key words that would identify the endpoint that is being addressed. We also have times where it would be useful to search across folders in a collection for requests using the same keyword in them. Having a way to search the collection's URLs for keywords would prove incredibly powerful and may Postman easier to use on large dynamic collections.

Example:

Request Name: "Use Case 433: Get all users with the same first name" 
URL: http://myfakeservice.com/users/lookup?term="Bob"

In this case searching  for "lookup" would not find this request. The Postman user who knows the endpoint they need to find the requests for would need to know that Postman request name uses different terms to describe the action.

### Describe the solution you'd like

An option for the search to search only request names, request names and URLs, or only URLs.

Alternatively, having 2 sets of search results, one for requests and one for URLs with each section being collapsible would also solve the issue.

### Describe alternatives you've considered

Going through every request in the collection and looking at each URL to find the keyword. This is impossible on large dynamic collections.

### Additional context

_No response_
Ambiguous terms: powerful, easier, large, dynamic, incredibly, useful, frequently, may
Questions:
1. What specific actions should the search feature be able to perform on request names and URLs?
2. How should the search results be displayed to the user?
Clarified requirement: Is there an existing request for a feature that allows users to search a collection's URLs for keywords? The feature should include options to search only request names, request names and URLs, or only URLs. Additionally, the search results should be displayed in two sets, one for requests and one for URLs, with each section being collapsible.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When making a http request for a JS file, the response body can't be set to JS for syntax highlighting; the postman app does support this feature.

### Describe the solution you'd like

Adding syntax highlighting for JS.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: fast, user-friendly
Questions:
1. What specific feature is being requested in terms of syntax highlighting for JS?
2. Is the request specifically asking for syntax highlighting support in a certain tool or environment?
Clarified requirement: Is there an existing request for adding syntax highlighting support for JavaScript in a specific tool or environment?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

In one of the latest updates to Postman, the theme color schemes were changed.

I am using the Light theme and noticed that the color of the variables has changed from red to blue.

This is extremely inconvenient, as the color blends in with the blue color of the values ​​in the JSON body.

Example:
![Image](https://github.com/user-attachments/assets/bbf6c119-94c1-4dd7-8904-091175482c19)

### Describe the solution you'd like

The best option is to return the color scheme to how it was before.

### Describe alternatives you've considered

An alternative, but more difficult to implement, is to make it possible to customize the color scheme.

### Additional context

Color scheme is a matter of habit, you can't just force it on everyone through an unexpected update
Ambiguous terms: inconvenient, best, more difficult, customize, unexpected
Questions:
1. What specific color was the variable before it changed from red to blue?
2. Can you provide more details on how the color scheme customization would work?
Clarified requirement: Is there an existing request for returning the variable color in Postman to its original red color? The feature request should include the ability to customize the color scheme in Postman to address the issue of the variable color blending in with other colors.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Every time I want to create a new request in collection I'm stuck on few seconds to find action that do it.
This is because actions sorted in weird order and I do believe does not reflect what people use mostly.

They also does not have any icons to distinguish actions between each other so my brain have to read each action before I find what I needed.

<img width="315" alt="Image" src="https://github.com/user-attachments/assets/ec0a1f23-d1a2-402d-a3d1-a39d50514e9b" />

### Describe the solution you'd like

Put `Add request` to the first action of right-click context menu on collection.


### Describe alternatives you've considered

(optional) It would be also great to add icons to each action so they could be found easily.

### Additional context

_No response_
Ambiguous terms: weird, mostly, great, easily
Questions:
1. What specific actions are currently included in the context menu for collections?
2. Can you clarify what you mean by "weird order" when referring to the sorting of actions?
Clarified requirement: Is there an existing request for the feature of adding an "Add request" option as the first action in the right-click context menu for collections? The current issue involves difficulty in finding the desired action due to the sorting order of actions in the menu and the lack of distinguishing icons.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

At the moment, the Updates Tab is not available for users within Partner Workspaces. 

As a result, teams need to communicate Postman changes outside of the workspace via another communication methods, which makes it a hassle for them and their Partners. 

### Describe the solution you'd like

Enable Updates Tab for Partner Workspaces

### Describe alternatives you've considered

N/A

### Additional context

Submitted by Postman Customer via Zendesk #232377.
Ambiguous terms: Enable, Updates Tab, Partner Workspaces, hassle
Questions:
1. What is the "Updates Tab" and how does it function within the context of Partner Workspaces?
2. Can you clarify what is meant by "Enable Updates Tab for Partner Workspaces"?
Clarified requirement: Determine if there is an existing request for enabling the Updates Tab feature within Partner Workspaces, as described by a Postman Customer via Zendesk #232377.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have a single collection of requests from which I test all the requests. I need to execute all those run parallelly so that I can save some time while building my service on jenkins.

### Describe the solution you'd like

I would like a solution where I can run multiple API request parallelly.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: multiple, parallelly
Questions:
1. What does it mean to run multiple API requests parallelly?
2. How would running multiple API requests parallelly save time in building the service on Jenkins?
Clarified requirement: Is there an existing request for a feature that allows running multiple API requests simultaneously? The requester has a single collection of requests for testing purposes and wants to execute them in parallel to save time when building the service on Jenkins.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

This request is related with tests results that output long assertions like a schema validation. 
At this time, the output is on a single line that can be difficult to follow (see image below).

![Image](https://github.com/user-attachments/assets/05c0aeda-e8c7-4688-a06e-23d0d86aa511)

### Describe the solution you'd like

Format the test result so it displays each error on a different line.
Example: 
AssertionError: expected data to satisfy schema but found following errors:
- data.timestamp_end should be >= 9466776000000
- data.distance should be >= 0
- data.distance should be <= 10000

### Describe alternatives you've considered

For now, I am pasting the line on a text editor and replacing the comma that separates the errors with a new line. 

### Additional context

_No response_
Ambiguous terms: difficult, format, displays, different, errors, replacing
Questions:
1. What specific format is currently used for displaying the test results?
2. Can you clarify what you mean by "replacing the comma that separates the errors with a new line"?
Clarified requirement: Is there an existing request for a feature that formats test results to display each error on a separate line? The current display of test results is difficult to follow, showing errors on a single line. The desired solution is to format the test results so that each error is displayed on a different line. An example format is provided where errors are listed individually. The alternative method mentioned involves manually replacing the comma that separates errors with a new line in a text editor.


Clarify this requirement: ### Describe your current workflow

I am updating yes case results in test rail to generate some html reports and some other matrix. 
Currently I am achieving this using external script and api integration with test rail tool. 

### Describe your ideal workflow

I want to update each test case and its status in test rail with respective test case. So that I don't have to work on any additional tool or script to make this is happen. 

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: ideal, respective
Questions:
1. What specific information is meant by "ideal workflow"?
2. Can you clarify what is meant by "respective test case" in this context?
Clarified requirement: Describe the current workflow of updating yes case results in Test Rail using an external script and API integration, and describe the desired workflow of updating each test case and its status in Test Rail without the need for additional tools or scripts.


Clarify this requirement: ### Describe your current workflow

I am specifically looking for a way to adjust the number of lines that are scrolled when using the mouse in Postman’s script editor. Right now, when I scroll using the mouse wheel or click the scroll bar, the movement is predefined. However, I would like to configure it so that each mouse scroll or click moves 6 to 8 lines at a time, making navigation easier in long scripts (e.g., 200+ lines).

### Describe your ideal workflow

I am specifically looking for a way to adjust the number of lines that are scrolled when using the mouse in Postman’s script editor. Right now, when I scroll using the mouse wheel or click the scroll bar, the movement is predefined. However, I would like to configure it so that each mouse scroll or click moves 6 to 8 lines at a time, making navigation easier in long scripts (e.g., 200+ lines).

### Describe alternatives you've considered

I am specifically looking for a way to adjust the number of lines that are scrolled when using the mouse in Postman’s script editor. Right now, when I scroll using the mouse wheel or click the scroll bar, the movement is predefined. However, I would like to configure it so that each mouse scroll or click moves 6 to 8 lines at a time, making navigation easier in long scripts (e.g., 200+ lines).

### Additional context

_No response_
Ambiguous terms: adjust, configure, easier, long
Questions:
1. What specifically do you mean by "adjust" and "configure" in this context?
2. Can you clarify what you mean by "easier" and "long" scripts?
Clarified requirement: Describe a method to customize the number of lines scrolled when using the mouse in Postman's script editor. Currently, scrolling with the mouse wheel or clicking the scroll bar moves a set number of lines. The goal is to set it up so that each mouse scroll or click moves between 6 to 8 lines, enhancing navigation in scripts with over 200 lines.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

can you please add a send button in the collection list in VScode
most of the time i dont want to open the request i simply want to send it. 

### Describe the solution you'd like

you can simply add it to the ... dropdown when you click the request. or simply add a send arrow on hover. 

<img width="492" alt="Image" src="https://github.com/user-attachments/assets/604c565f-4909-4c3b-80fb-073822729602" />

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: most, simply, most of the time
Questions:
1. What is the "collection list" in VScode?
2. Can you clarify what you mean by "send arrow on hover"?
Clarified requirement: Is there an existing request for the feature of adding a send button to the collection list in VScode? The feature should allow users to send requests without having to open them. The solution could involve adding the send button to a dropdown menu when clicking the request or by displaying a send arrow on hover.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I've been using [RESTer](https://github.com/frigus02/RESTer) for years but when I tried Postman I saw it lacks a feature of RESTer, which is to automatically "convert" request data between formats on the frontend.

For example, say you're sending a POST request with a bunch of ampersand-delimited POST data. Your raw request might look like this:

![Image](https://github.com/user-attachments/assets/3ad19548-e079-4555-a5c1-65d7f351223a)

When you want to edit or add to that data, it might be easier to edit the data in a form-like view (especially if the raw data is long or complex).

In RESTer, you can simply switch the request type to "Form" and it'll automatically parse the raw data into a form UI:

![Image](https://github.com/user-attachments/assets/4a825e10-2b89-446c-9e8f-989952653efe)

### Describe the solution you'd like

Auto-convert data between the various request formats (form, raw, etc.) on Postman's frontend.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: automatically, easier, long, complex, various
Questions:
1. What specific formats do you mean by "various request formats"?
2. Can you clarify what you mean by "auto-convert data" in the context of Postman's frontend?
Clarified requirement: Is there a request to add a feature in Postman that automatically converts data between different request formats, such as form and raw, on the frontend?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Hi Team,

I keep working with different apis present in different folders. So at times seeing all the opened folders looks clumsy and tough to find a new api[Need to scroll]. If we can have an option to close all opened  folders at once it would be helpful.

If it's already present please guide me

Thanks

### Describe the solution you'd like


Option to close all opened folders on Left side bar. 
Observed this function happening when we do a search. Open multiple folders and search for an API and clear the search bar. All the folders will be closed

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: clumsy, tough, helpful
Questions:
1. What specific feature is being requested regarding the opened folders?
2. Can you clarify what you mean by "clumsy and tough to find a new api"?
Clarified requirement: Is there a feature request to add an option to close all opened folders at once on the left side bar in order to make it easier to navigate through different APIs?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman's GraphQL client only supports subscriptions that are implemented via WebSockets using [GraphQL-WS](https://the-guild.dev/graphql/ws).

### Describe the solution you'd like

It should also support subscriptions implemented via Server-Sent Events using [GraphQL-SSE](https://the-guild.dev/graphql/sse).

### Describe alternatives you've considered

As a workaround, I can make an HTTP POST request (not using the GraphQL request type), set the GraphQL in the body, and manually set the `Accept: text/event-stream` request header.  That works with the example servers provided by the `graphql-sse` library.  But I can't do anything like this with Postman's GraphQL request type.

### Additional context

It is frustrating that Postman's supports WS and SSE, but Postman's GraphQL client presumes all subscriptions are implemented over WebSockets. Both WebSockets and SSE are widely implemented protocols for GraphQL subscriptions.  IMHO, both should be supported.

See:
- https://the-guild.dev/blog/graphql-over-sse
- https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets
Ambiguous terms: fast, user-friendly, widely, should, frustrating, supports, widely, IMHO
Questions:
1. Is the existing request for the feature you're referring to within the context of Postman's GraphQL client?
2. Are you specifically looking for support for GraphQL subscriptions implemented via Server-Sent Events using GraphQL-SSE in Postman's GraphQL client?
Clarified requirement: Is there an existing request within Postman's GraphQL client for adding support for GraphQL subscriptions implemented via Server-Sent Events using GraphQL-SSE?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I've Duplicated an existing collection representing a new workflow, created a new message which appears at the bottom of the Saved Messages list. Now I want to position the new message in the saved messages but I can't.


### Describe the solution you'd like

It would be nice if I could reorder saved messages within a SocketIO collection, via click-and-drag or an icon.

### Describe alternatives you've considered

_No response_

### Additional context

<img width="351" alt="Image" src="https://github.com/user-attachments/assets/71d3e724-35f4-438c-94d1-a0ec45cf4abf" />
Ambiguous terms: nice, reorder, click-and-drag, icon
Questions:
1. What does "reorder saved messages within a SocketIO collection" entail?
2. Can you clarify what you mean by "click-and-drag or an icon" in this context?
Clarified requirement: <img width="351" alt="Image" src="https://github.com/user-attachments/assets/71d3e724-35f4-438c-94d1-a0ec45cf4abf" />


Clarify this requirement: ### Describe your current workflow

PMAK-678fb5caeb748200012a5ad5-94862a28e45b6e877ab454fd5564cc7096

### Describe your ideal workflow

https://darvinmonteras-instatus.postman.co/workspace/darvinmonteras.instatus.com~7c09ca23-14dd-4e68-8a46-195c1114057d/collection/41320717-c875e29b-7b25-4661-bb07-e8ba8025e2b7?action=share&creator=41320717

### Describe alternatives you've considered

PMAK-678fb4955137bc00014be76d-47c5bf46a4bcf72eb72c1a2216a3fc3a8b

### Additional context

https://darvinmonteras.instatus.com
Ambiguous terms: Describe, ideal, alternatives, Additional context
Questions:
1. What specifically should be included in the descriptions of the workflows?
2. How detailed should the descriptions be for each section?
Clarified requirement: Provide detailed descriptions of your current workflow, ideal workflow, and any alternatives considered, including additional context.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

This feature request is purely cosmetic and doesn't relate to any problem

### Describe the solution you'd like

The ability to change the color scheme inside the postman tab, currently, the syntax highlighting and colors are from the vscode default color scheme, but the ability to change that to the currently selected color scheme or the ability to select an already installed color scheme would be nice

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: cosmetic, nice
Questions:
1. What is meant by "cosmetic" in this context?
2. Can you clarify what you mean by "nice" in relation to the feature request?
Clarified requirement: Is there an existing request for the ability to change the color scheme inside the Postman tab? The feature request should allow users to customize syntax highlighting and colors to match their selected color scheme or choose from already installed color schemes.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Creating a module with the body of a request coming in as input. Would be good that the template body can be that input with specific replacement variables. Workaround is to use an "Evaluate" block to do the same substitution.

![Image](https://github.com/user-attachments/assets/dd6e8510-447f-46b0-b71b-8e26f29b130d)

### Describe the solution you'd like

Input node on the Template Block for the body of the template

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: good, specific, like
Questions:
1. What specific variables are expected to be replaced in the template body?
2. Can you provide an example of how the input node on the Template Block would work?
Clarified requirement: Is there an existing request for a feature that allows creating a module with a customizable template body where specific variables can be replaced? The feature should include an input node on the Template Block for the body of the template, and examples of variable replacements should be provided.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Right now when someone is granted access to a workspace they are given viewer role and can see everything in the workspace. I would like a DENY / NONE role to be added so that users cannot see, export, or use certain items such as:

- collections
- environments

### Describe the solution you'd like

PREFERRED: A NONE (verbiage???) workspace role. Then the user cannot use or see ANYTHING unless explicitly granted viewer / editor on that item. Viewers can still see everything.

ALTERNATIVE: A DENY role added. When  a user is added to that role on an environment or collection they cannot physically see or use that environment or collection if they are added to the DENY role on that item.



### Describe alternatives you've considered

- environments: 
    - Removing the initial value. However this has a drawback in that every new user needs to be able to enter the current value, and they have to know **not** to enter the initial value. However, this does not block users from editing the initial value or exporting the environment.
    - Usage of a keyvault: This keeps users from seeing / exporting the values, but not using them. I also want them not to be able to use the values if denied. For example, I do not want some users to be able to use production api keys to pull back production PCI / HIPPA data.

- collections:
  - I could use personal collections and share them with specific users, but it would be preferable to keep the collections in one place so any changes do not need to be synchronized.

### Additional context

_No response_
Ambiguous terms: NONE, verbiage
Questions:
1. What does the term "NONE" mean in the context of workspace roles?
2. Can you clarify what is meant by "verbiage" in the solution description?
Clarified requirement: Is there an existing request for a new feature related to adding a DENY / NONE role in a workspace to restrict user access to certain items like collections and environments? The preferred solution is to introduce a NONE workspace role where users cannot see or use anything unless explicitly granted viewer or editor permissions. Alternatively, a DENY role can be added to prevent users from accessing specific items.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Since the latest app update (Version 11.27.3) the bodies of responses with "strange" Content-Type Headers default to "Hex" view.

e.g. Content-Type: multipart/related; type="application/xop+xml"; boundary="uuid:2d96eeb9-ca40-491d-ae52-d3f41752a05e"; start="<root.message@cxf.apache.org>"; start-info="application/soap+xml"

Before this update those responses were shown as "Raw"

I experimented with Fiddler and tried  different "Content-Type" Headers:
  “text/xml”
  “application/xml”
  “application/xop+xml”
  “application/soap+xml”
which "helped" the "Response format detection: Auto" to display it as "XML".

 

### Describe the solution you'd like

Could you please add the option "XML" to the "Response format detection"-Setting, so that the response body is "always" displayed as XML no matter what Content-Type?

The setting would look like

Response format detection     o Auto    o JSON    o XML



### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: strange, default, Hex, experimented, different, helped, always
Questions:
1. What does "strange" mean in the context of Content-Type Headers?
2. Can you clarify what "always" means in the context of displaying response bodies as XML?
Clarified requirement: Is there an existing request for adding an "XML" option to the "Response format detection" setting, so that response bodies are always displayed as XML, regardless of the Content-Type Headers?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the tracker for existing similar issues and I know that duplicates will be closed

### Describe the Issue

I can't find the login entry for the GitHub account.
![baidu1](https://github.com/user-attachments/assets/2e0a6093-bfe9-45a3-b983-eb83f5c59daf)


### Steps To Reproduce

login

### Screenshots or Videos

_No response_

### Operating System

Windows

### Postman Version

11.27.3

### Postman Platform

Postman App

### User Account Type

Signed In User

### Additional Context?

_No response_
Ambiguous terms: can't, find, login
Questions:
1. What specific actions have you taken to try to find the login entry for the GitHub account?
2. Are you looking for a specific type of login entry or information related to the GitHub account?
Clarified requirement: Determine if there is an existing issue related to the inability to find the login entry for the GitHub account.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I maintain a Postman collection with 38 environments and counting. We end up forking it to a new workspace fairly frequently. When doing so it is helpful to fork the 38 environments in one step (I appreciate this feature!) using the "Environments to Fork" drop down. However, this drop down is not sorted like the environment selection dropdown at the upper right of the Postman application and it does not have a "Select All" button.

Environments that would be grouped together and easy to find are randomly distributed throughout the list and it takes scrolling and clicking 38 checkboxes to select all environments. Using the keyboard does not work well as it does in some UI's (the spacebar checks the selected checkbox but moves the selection to the top of the list). It would also help to have a filtering feature here as other environment lists have.

Note, the environment list in the Find UI is also not sorted though it does have filtering and select all.

*I am using the Postman application for Mac

### Describe the solution you'd like

1) Add filtering, sorting and a "Select All" button to the "Environments to Fork" drop down.

2) Add sorting to the "Choose entities to find in - Environments" drop down in the Find UI.

### Describe alternatives you've considered

_No response_

### Additional context

![2025-01-09_17-56-09](https://github.com/user-attachments/assets/0e994d00-05ad-4c22-a498-1d981e463119)

![2025-01-09_17-56-58](https://github.com/user-attachments/assets/ccadbf9f-d0dc-460f-b49f-e8664250c2a9)

Postman for Mac
Version
11.27.3
UI version
11.27.3-ui-250108-2337

Desktop platform version
11.27.3

Architecture
arm64

OS platform
OS X 23.6.0
Ambiguous terms: sorting, filtering, select all, grouped together, randomly distributed
Questions:
1. What specific criteria should be used for sorting the "Environments to Fork" drop down?
2. How should the "Select All" button function in the context of selecting environments?
Clarified requirement: Ensure that the "Environments to Fork" drop down in the Postman application for Mac includes sorting based on specific criteria, filtering functionality, and a "Select All" button that functions as expected for selecting environments. Additionally, add sorting functionality to the "Choose entities to find in - Environments" drop down in the Find UI.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

There are too few language switching options.

### Describe the solution you'd like

I hope to add a language option function to this app, which is simplified Chinese.

### Describe alternatives you've considered

The language option switches a list that can be made into a list that can be turned up and down for us to choose from, instead of only two options.

### Additional context

The software is very easy to use, but it is not optimized for Chinese, which makes me feel uncomfortable. The only function that can be used is to send a request. I feel very sorry that I have not maximized the use of the software. I hope to optimize the language. Thank you.
Ambiguous terms: few, simplified, easy, optimized, uncomfortable, sorry, maximized, optimize
Questions:
1. What specific language switching options are currently available in the app?
2. Can you provide more details on how the language option function should work?
Clarified requirement: Is there an existing request for a language option function in the app? If not, the feature request is related to the limited language switching options available. The solution desired is to add a language option function that includes simplified Chinese. One alternative considered is to create a scrollable list for language selection instead of just two options. The current software lacks optimization for Chinese, limiting functionality to sending requests. The goal is to enhance the language options for better usability.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Like many others we cannot sign in due to the risk of inadvertantly syncing sensative data to the cloud.
With the desktop app you can choose to continue without signing in, using the "lightweight Postman API Client".

There does not appear to be equivalent capabiltiy in the VS Code extension.

### Describe the solution you'd like

Similar to the desktop app, please add a "continue without sign-in option" to the extension.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: many, lightweight, equivalent, similar
Questions:
1. What specific risks are associated with inadvertently syncing sensitive data to the cloud?
2. Can you clarify what capabilities are missing in the VS Code extension compared to the desktop app?
Clarified requirement: Is there an existing request for a feature that adds a "continue without sign-in option" to the VS Code extension, similar to the desktop app's functionality?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have few requests which I want to run for each subfolder. I will make them as a master and run before each sub folder

### Describe the solution you'd like

I have few requests which I want to run for each subfolder. I will make them as a master and run before each sub folder

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: few, master, each
Questions:
1. What is meant by "master" in this context?
2. Can you clarify what "run before each sub folder" entails?
Clarified requirement: Is there an existing request for the feature? I have searched for duplicates and know they will be closed. My feature request involves running a set of requests for each subfolder, treating them as a master and running them before each subfolder.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

No

### Describe the solution you'd like

I can click the ... to get an "export" option on a collection. But what if I just want to export a folder in a collection? Or just export a single request for that matter? Those options do not exist.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: No, problem, solution, export, folder, collection, single request
Questions:
1. What is the specific feature being requested in this requirement?
2. Can you clarify what is meant by "exporting a folder in a collection" and "exporting a single request"?
Clarified requirement: Is there a feature request for adding the ability to export a folder or a single request within a collection, in addition to the existing "export" option for the entire collection?


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman's WebSocket features cannot be used with WebSocket APIs built on AWS. This is likely to account for a large proportion of WebSocket APIs.

### Describe the solution you'd like

Postman has great support for signing HTTP requests with AWS Signature. This feature request is to add the exact same support for WebSocket APIs. Same configuration UI and everything. In the case of WebSockets it is used to sign the HTTP request that the client sends to initiate the connection handshake prescribed by the WebSocket protocol.

### Additional context

WebSocket APIs built with AWS [use AWS Signature for authenication](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-control-access-iam.html). The client must sign the HTTP request that initiates the connection, and signing this request works identically to signing a REST request.
Ambiguous terms: great, exact same, everything, great support, identically
Questions:
1. What specific features does Postman currently support for signing HTTP requests with AWS Signature?
2. Can you clarify what is meant by "the exact same support for WebSocket APIs"?
Clarified requirement: Is there an existing request for adding support for signing WebSocket APIs with AWS Signature in Postman, similar to the support currently available for signing HTTP requests with AWS Signature?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I'm unable to execute certain API requests because I am meeting the maximum response size. And I'm unable to find a setting in the VS code extension to increase this maximum. 

### Describe the solution you'd like


I would like to request the addition of several features to the VS Code extension for Postman to bring it on par with the desktop version. The requested features include:

1. **Save Response to File**: Add the ability to save the response directly to a file.
2. **Send and Download**: Include the "Send and Download" functionality.
3. **Copy Response to New Tab**: Introduce an option to copy the response to a new tab within VS Code.
4. **Maximum Response Size Setting**: Provide a setting that allows users to set the maximum response size, similar to the option available in the desktop version.

**Rationale**:
These features would significantly enhance the usability and functionality of the VS Code extension for Postman, aligning it more closely with the capabilities of the desktop version and improving the workflow for users who rely on these features.

**Potential Benefits**:
- **Increased Productivity**: Users can save responses directly to files and download them as needed, streamlining data management.
- **Better Organization**: Copying responses to new tabs would allow for better organization and easier comparison of responses.
- **Customization**: The ability to set the maximum response size ensures that users can work within their preferred limits and avoid performance issues.


### Describe alternatives you've considered

_No response_

### Additional context

These features are available in the Postman desktop version and would be valuable additions to the VS Code extension to provide a consistent and robust user experience.
Ambiguous terms: several, significant, enhance, significantly, improving, better, easier, preferred, valuable, consistent, robust
Questions:
1. Can you provide examples of the features that are currently available in the desktop version of Postman but missing in the VS Code extension?
2. Are there any specific limitations or challenges users are facing due to the absence of these features in the VS Code extension?
Clarified requirement: Is there an existing request for features in the VS Code extension for Postman to match the functionality of the desktop version, including the addition of features like saving responses to files, "Send and Download" functionality, copying responses to new tabs, and setting the maximum response size?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Mock Server Call Log items must be removed or cleared individually with the current trash can icon. A clear all logs will improve user workflows.


### Describe the solution you'd like

Currently, the Mock Server Call Log does not have a way to clear all items for a given Mock Server. It would be nice to be able to clear these all at once for a given mock server so I can save time when testing and keeping my log environment clean.

### Describe alternatives you've considered

The only current alternative is to delete the Mock Server, and recreate it, but this requires adjusting configurations in other applications being tested to point at the new Mock Server URL OR manually clicking the trash can icon on tens, hundreds, or thousands of logs during or after testing is completed.

### Additional context

A revious request added the trash can icon, however does not improve overall workflow and has resulted in added incremental work to clear the logs negating any time savings.
[Previous update that added the trash can icon](https://github.com/postmanlabs/postman-app-support/issues/11315)
Ambiguous terms: nice, improve, workflow, clean, alternative, considered, manually, incremental
Questions:
1. What specific action is currently required to clear individual items in the Mock Server Call Log?
2. Can you provide more details on how the trash can icon currently functions in the Mock Server Call Log?
Clarified requirement: Is there an existing request for a feature that allows clearing all items in the Mock Server Call Log at once for a given Mock Server? The current method involves clearing items individually using the trash can icon, and a more efficient way to clear all logs is desired to improve user workflows and save time during testing.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

No I don't think so but I'm not really interested in doing anything else for this project that I'm done with and was never a part of.

### Describe the solution you'd like

You get the fuck out of the way.

### Describe alternatives you've considered

There is no alternative.

### Additional context

I've been trying to work with you and I'm not good enough. Now I'm not even sure if I need any of this in my life.
Ambiguous terms: fast, user-friendly, problem, solution, alternatives, good enough, need
Questions:
1. What specific feature are you referring to in this requirement?
2. Can you clarify what you mean by "get out of the way"?
Clarified requirement: Is there an existing request for a specific feature in this project? If so, I have searched for duplicates. My feature request is to have a specific action taken regarding a certain aspect of the project.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have a table in supabase. have some data in the table. when I want to check that in postman. i copy pasted the apikey, Authorization and send getvrequest but no getting the data

### Describe the solution you'd like

i want to get the data

### Describe alternatives you've considered

i checked postman community, used chatgpt.

### Additional context

![Screenshot (4)](https://github.com/user-attachments/assets/77b30337-f855-48d8-882f-da11a79aa3c8)
![Screenshot (5)](https://github.com/user-attachments/assets/d26f9673-06b4-49ab-9bf8-be5bbd5403c5)
![Screenshot (6)](https://github.com/user-attachments/assets/c51291fa-08f3-4cfb-b6e5-9554a4355672)
Ambiguous terms: want, get
Questions:
1. What specific data are you trying to retrieve from the table in Supabase?
2. Can you clarify what you mean by "copy pasted the apikey, Authorization and send getvrequest"?
Clarified requirement: Is there an existing request for the feature related to retrieving specific data from a table in Supabase? The user has encountered an issue where they are unable to retrieve the desired data using Postman, despite copying and pasting the apikey and Authorization.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I was exporting a collection to share with a customer. I had someone else part of my company but not on my team import the collection and they mentioned that the post-scripts weren't working because they didn't have the Package Library. I was disappointed because I've been providing this to external users without knowing that Package Library wouldn't be included. Previously, I would include the script directly within the collection and the customer would not have any issues. However, this is making it harder for external users to integrate to our APIs. Package Library is only accessible to the team and not to external users. We cannot invite external users to our team because they would see all other customer workflows within our Workspace. 

### Describe the solution you'd like

We use Package Library to capture responses returned in responses. We would like to have package libraries exported along with collection so that when we provide them to external users, the end-to-end API functionality remains intact.

### Describe alternatives you've considered

I've considered switching back to just writing the script directly in the API request post-script section itself. It's a lot of copy-pasting since there's no way to export package libraries. 

### Additional context

_No response_
Ambiguous terms: harder, integrate, end-to-end, a lot
Questions:
1. What is meant by "Package Library" in this context?
2. Can you clarify what is meant by "end-to-end API functionality"?
Clarified requirement: Is there a feature request to export Package Libraries along with collections to ensure that external users can access the end-to-end API functionality without the need for Package Library access?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Feature Request Submitted by Postman Customer: 

> I'm currently setting up a Postman collection with about 10 to 20 secrets in the env. The idea is to share the collection with the team, all members on the team will have their own 1Password accounts with read access to a shared 1Password vault. 

> In the Postman vault I have all the connections made between Postman env variables and 1Password secrets. Because I have so many vars set in the Postman vault, I was wondering if there is an easier way to share this setup with the team, instead of having each person do their own setups, which is also prone to human errors and inconsistencies. 

### Describe the solution you'd like

Allow an option to export Vault secrets within Postman so that other users can import them into their instance. 

### Describe alternatives you've considered

The current solution is to manually add these secrets per user. (Opens the door to human error)

### Additional context

_No response_
Ambiguous terms: easier, share, setup, setup with the team, easier way, import, manually
Questions:
1. What specific information needs to be shared from the Postman vault with the team?
2. Can you clarify what "import" means in the context of sharing secrets from the Postman vault?
Clarified requirement: Determine a way to export Vault secrets from the Postman collection so that team members can easily import and use them in their own instances, avoiding manual setup and potential human errors.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

The change to mask sensitive data (passwords, tokens, etc) in Postman is a valuable feature, but is cumbersome in trusted environments (such as Dev environments where data is shared between developers frequently).

### Describe the solution you'd like

The ability to unmask sensitive data in trusted, internal environments would be helpful for developers sharing data within that environment. Being able to mark a workspace or scratch pad as "Trusted" so that the "Disable masking of sensitive data" is available would make Postman much more useable in these environments.

### Describe alternatives you've considered

We currently use post-request scripts to create the code we need in the console, since the console does not mask this data. However, since there is not a global scripting option, we have to set this by collection and it is cumbersome.

### Additional context

_No response_
Ambiguous terms: cumbersome, valuable, helpful
Questions:
1. What specifically makes the current process cumbersome in trusted environments?
2. How would the ability to mark a workspace or scratch pad as "Trusted" impact the masking of sensitive data?
Clarified requirement: _No response_


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I guess the problem would be the lack of capability and ease of use when it comes to scripts. Scripts are limited in functionality and still use the old commonjs/node way of doing things.  

### Describe the solution you'd like

Instead of using node, add the ability to use javascript/typescript and deno for all script-related things.

This would make the platform so much nicer using the deno ecosystem instead of node and could open the door to easily using npm and deno packages if need be.

Even without using external packages, I think it would make things simpler, especially on the typescript side.

### Describe alternatives you've considered

None

### Additional context

None
Ambiguous terms: lack of capability, ease of use, nicer, simpler
Questions:
1. What specific limitations do you encounter when using scripts in the current system?
2. Can you provide examples of how the use of JavaScript/TypeScript and Deno would improve the functionality of scripts?
Clarified requirement: Is there an existing request for adding the ability to use JavaScript/TypeScript and Deno for script-related tasks in the platform? If not, the feature request is to enhance script functionality by incorporating JavaScript/TypeScript and Deno to replace the current reliance on Node.js. This change aims to improve the capabilities and ease of use of scripts by leveraging the Deno ecosystem and potentially enabling the use of npm and Deno packages.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Currently, there is no way for a Send Request Block to change the body of a request, other than setting the entire body to a variable or adding variables to whatever we want parameterized. However, neither of these solutions makes sense in an API collection. Collection requests should be callable individually.

### Describe the solution you'd like

I would like a Body input to be added to the Send Request block. When this block has a connected input, it overrides whatever body is defined on the request. This will give us the freedom of using the Send Request block however we want, without having to alter the existing request.

![image](https://github.com/user-attachments/assets/503ab609-82b1-467f-925f-289c428f2670)


### Describe alternatives you've considered

Currently, if I want to control the body of a request from a Flow, I have to change the request's Body in the collection to use a variable. That way, I can assign said variable to another block from within the Flow.

Obviously, this is not ideal, because now, the request in my collection is pretty much useless outside of the flow. If I want to update the body and call it individually, I have to either update the variable (which is holding a JSON string - not easy to do) or update the request body (thus breaking the flow).

The way I'm using it now is essentially by duplicating the request into a separate "Flows" collection. Each request in that collection has the body set to `{{body}}`, allowing me to control it from the flow.. Again, this is not ideal, because now I have to maintain the request in two places.

### Additional context

This is useful when trying to chain multiple requests and stick certain parts of one request to the next one's body. This shouldn't require us changing the collection or creating duplicates of the request. This should be achievable directly from the Flow.
Ambiguous terms: fast, user-friendly, freedom, ideal, useful, certain
Questions:
1. What specific block are you referring to when mentioning the "Send Request block"?
2. Can you clarify what you mean by "connected input" in the context of the Send Request block?
Clarified requirement: Is there a way to add a Body input to the Send Request block so that it can override the defined body of a request, allowing for more flexibility in using the block without the need to modify the existing request?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

## Summary
I would like the ability to reposition the response panel in Postman, similar to how IDEs like Visual Studio Code allow users to customize the layout (e.g., placing the response panel on the right instead of below the request panel).

## Why This Feature is Needed
- Improved productivity for developers working with wide screen monitors or dual monitors.
- Easier side-by-side comparison of request and response for better API testing experience.

## Example Use Case
- When testing APIs, the response panel on the right allows for better visibility of both request details and response content simultaneously without scrolling or resizing panels.


### Describe the solution you'd like

- Provide an option to dock the response panel to different positions, such as:
  - Right side of the request panel.
  - As a floating, resizable panel.

### Describe alternatives you've considered

_No response_

### Additional context

- Many developers prefer customizable layouts to suit their workspace preferences.
- This feature is common in IDEs and could be a valuable addition to Postman
Ambiguous terms: similar, customize, improved, easier, better, better visibility, customizable, valuable
Questions:
1. What specific actions would the user be able to take to reposition the response panel in Postman?
2. How would the user access the feature to dock the response panel to different positions?
Clarified requirement: Is there an existing request for the feature that allows users to reposition the response panel in Postman? The feature should provide users with the ability to dock the response panel to different positions, such as the right side of the request panel or as a floating, resizable panel, and it should be easily accessible for customization.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

No

### Describe the solution you'd like

Just any way for Postman to have the ability to minimize to system tray instead of closing with the "Close" button

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: Just, any, ability, minimize, system tray, instead of, closing
Questions:
1. What do you mean by "minimize to system tray"?
2. Can you clarify what you mean by "closing with the 'Close' button"?
Clarified requirement: Is there an existing request for the feature where Postman can be minimized to the system tray instead of closing when the "Close" button is clicked?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I notice that the current version installs to %localappdata%. I understand from Support that there is no alternative to this. There is no way to force it to install to a generic location like %programfiles% (unlike the Enterprise edition)

### Describe the solution you'd like

An msi and option (command line switch) to change the default destination folder to a generic location like %programfiles% 

### Describe alternatives you've considered

The only alternative is not to package the client but for the users to do manual installations. This is do-able but not user-friendly. 

### Additional context

Like a lot of corporations we have a 'standard' to package everything, even if only used by a small number of users. We are successful in meeting this objective with 99% of software clients. The problem is that the users and desktop support teams are unfamiliar with a manual installation option (so it's not user-friendly). A lot of corporations will be in a similar position.
Ambiguous terms: generic, user-friendly
Questions:
1. What does "generic location" mean in this context?
2. Can you clarify what is meant by "user-friendly" in this scenario?
Clarified requirement: Is there an existing request for a feature that allows changing the default installation destination folder to a location like %programfiles% using an msi and a command line switch?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have multiple variables with the same prefix. When starting to type the name of the variable, I am shown the matches in a variable picker. However, the column with the variable name is too narrow to show the full name of the variable, and there is no other way for me to see which variable I am selecting, meaning I have to choose one of them, find that it is wrong, do the search again, and hopefully choose the correct one next time, which is annoying.

![postman_too_narrow_var_column](https://github.com/user-attachments/assets/a4e3e162-7fca-463b-8e05-64c2e3d5d2d2)


### Describe the solution you'd like

From the top of my head:
1. Make it possible to resize the column and make sure the app remembers the latest width
2. Show the full name of the variable when hovering over it with the mouse
3. Show the full name of the variable in the right part of the picker where you see its value

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: possible, latest, full, hovering, right part
Questions:
1. What does "resizes the column" refer to in the context of the variable picker?
2. Can you clarify what you mean by "showing the full name of the variable in the right part of the picker"?
Clarified requirement: Is there an existing request for a feature that allows users to resize the column in the variable picker and have the app remember the latest width? Additionally, users would like to see the full name of variables when hovering over them with the mouse and have the full name displayed in a specific area on the right side of the picker.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

the list of changes is not displayed when importing from a json file
![photo_2024-11-20_18-09-18](https://github.com/user-attachments/assets/8f7f021f-2fbb-4f57-a8d0-078926313bfd)


### Describe the solution you'd like

I would like to see the history of changes during automatic import of open api documentation (by url or file)
![Screenshot_6](https://github.com/user-attachments/assets/7b72bdb2-cc55-4295-9524-4a911cbfa412)


### Describe alternatives you've considered

We have a url(or file)
![photo_2024-11-20_18-09-18](https://github.com/user-attachments/assets/37869b4b-648c-47a4-b264-18ce9ab547ec)
 that provides open api documentation

I would like to see it in Postman, and also see the difference between old and new changes in the list of changes

### Additional context

_No response_
Ambiguous terms: like, history, automatic, see, difference
Questions:
1. What specific changes are considered in the history during automatic import?
2. How should the difference between old and new changes be visualized in the list?
Clarified requirement: Is there an existing request for the feature related to displaying the history of changes during the automatic import of open API documentation in Postman, including a visualization of the difference between old and new changes in the list?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Our GraphQL subscriptions require an auth token in the [connection_init](https://websockets.spec.whatwg.org/#the-websocket-interface) payload of the `graphql-transport-ws` standard to authenticate connections.

The [websocket standard](https://websockets.spec.whatwg.org/#the-websocket-interface) doesn't allow setting an authentication header when opening a socket, so the existing GraphQL Authorization options do not reflect real-world authorization options.  The `connection_init` payload is a workaround for this problem allowing an up-front authorization phase before normal traffic begins.

In practice, the payload is currently always sent as null.

### Describe the solution you'd like

I would like the ability to specify the payload for `connection_init` either explicitly through a new tab alongside parameters like header and schema, or I would like to have the headers replicated into the payload automatically which is how the graphql-playground [solved this problem](https://github.com/graphql/graphql-playground/blob/e1f715988099b74f7ea0ec19d612d97cfbf05848/packages/graphql-playground-react/src/state/sessions/fetchingSagas.ts#L66-L68).

### Describe alternatives you've considered

I have thought about trying to adopt additional code on the server to manually intercept the `connect_init` payload and inject authorization from the headers of the original websocket handshake (which would only be present when using non-browser clients like postman), but do not want to incur the overhead and complexity of forwarding the headers for every socket handshake.

I also have considered adding the ability to inject a default payload into the server as a fallback for development environments, but that would make regression testing useless against staging servers where I would never want to spoof authorization.

### Additional context

_No response_
Ambiguous terms: ability, problem, real-world, workaround, explicitly, automatically, alternatives, considered, additional, fallback, useless
Questions:
1. What specific feature is being requested in relation to the `connection_init` payload for GraphQL subscriptions?
2. Can you clarify how the existing GraphQL Authorization options differ from the real-world authorization options?
Clarified requirement: Is the feature request to be able to specify the payload for `connection_init` in GraphQL subscriptions either explicitly through a new tab or automatically replicate headers into the payload, addressing the limitations of existing GraphQL Authorization options in real-world scenarios?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

**Problem Statement**: I've a bunch of "saved" tokens which I would like to programmatically set before sending the request. Currently there is no option to do that in Postman. 

![image](https://github.com/user-attachments/assets/be00736f-ebd7-44e5-98a5-a0b803ec63d6)


### Describe the solution you'd like

**Solution**: Ability to programmatically set the "saved" tokens in Pre-Request before sending any request. Something on the lines of 
`pm.request.auth.parameters().get('accessToken');`

### Describe alternatives you've considered

**Alternative**: Manually setting the "saved" tokens each time I run the request.

### Additional context

_No response_
Ambiguous terms: bunch, programmatically, option, Ability, something on the lines of, manually
Questions:
1. What does "bunch" refer to in the context of "saved" tokens?
2. Can you provide a specific example of what you mean by "programmatically set" the "saved" tokens?
Clarified requirement: Is there an existing request for a feature that allows users to programmatically set "saved" tokens in Postman before sending a request? The feature should enable users to access the tokens in the Pre-Request phase using a specific function like `pm.request.auth.parameters().get('accessToken');`.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman is Synching Keys and Tokens to its cloud account. This is not going well with my employer (The top ranked Fortune 500 company). Entire org has been asked to delete its account, and choose alternative.



### Describe the solution you'd like

If only you can provide a way to not Sync sensitive data to cloud account. I think my employer can reconsider using Postman.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: sensitive, cloud account, alternative
Questions:
1. What specific data is considered "sensitive" in this context?
2. Can you clarify what is meant by "cloud account" and what alternatives are being considered?
Clarified requirement: Is there an existing request for a feature that allows users to prevent the synchronization of specific sensitive data to Postman's cloud account? The feature is being sought by an employer, a top-ranked Fortune 500 company, to reconsider the use of Postman due to issues with data synchronization.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Storing and linking secret data in Postman Vault from external vaults is a manual process.  For example, linking AWS Secret Manager key-value pairs requires separate individual submissions in Postman Vault, which is not feasible if you are looking to potentially link and reference hundreds of secret values from AWS Secret Manager

### Describe the solution you'd like

1.  Bulk or choose specific variables to import to Postman Vault from Environments, Collection Variables, Globals, and the Authorization tab
2. File import process to facilitate secret data entry into Postman Vault
3. For Vault Integration users, the ability to bulk link or choose specific secrets to link to Postman Vault
4. Make it easy for users to collaborate with Vault integrations - There should be a means to share the Vault integration setup across the team or multiple users


### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: bulk, specific, feasible, easy, collaborate, share
Questions:
1. What does "bulk" mean in the context of importing variables to Postman Vault?
2. Can you clarify what is meant by "specific variables" in the solution description?
Clarified requirement: Is there an existing request for the feature of enabling bulk or selective import of variables to Postman Vault from Environments, Collection Variables, Globals, and the Authorization tab to simplify the manual process of storing and linking secret data?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Users have occasionally deleted environments, which often contain sensitive information and are time-consuming to set up due to the multiple environments required per workspace. Currently, Postman does not back up environments, meaning they cannot be restored once deleted. The only recovery option is to manually re-create them. When environments are lost, it can also halt work, causing delays until they are restored.
A workaround is to have designated individuals back up these environments, create a separate workspace (Postman recommended approach) or implement an automated job that stores snapshots within our systems. However, these approaches are cumbersome and prone to issues such as expiring SCIM keys, employee turnover, role changes, additional workspace management, and accidental deletions. 

### Describe the solution you'd like

We propose implementing more explicit permissions for managing environments by setting default access to read-only, except for workspace owners/admins. Teams would need to submit a ticket to the designated Admin team for any environment modifications. In cases where no Admin is assigned (noting that PayPal currently has 2,600 workspaces with universal Admin access of which many do not have a individual admin, which presents its own challenges), users requesting edit permissions for environments would need to initiate a ticket. This approach would centralize environment management, establishing a controlled system to safeguard sensitive information and ensure secure, effective handling.

### Describe alternatives you've considered

We have reviewed various workaround solutions. In the absence of the desired solution, we may ask teams to create a separate workspace to control permissions more effectively. However, this approach may introduce confusion and additional management overhead, as it increases the risk of other artifacts, such as tests, mocks, and collections, being created in these environment workspaces.

### Additional context

An incident occurred when a user accidentally deleted multiple environments in a team workspace, mistaking it for a private workspace. This deletion blocked the team's work, led to an internal escalation, and highlighted the need for more granular controls specifically for environments, which are widely used and shared. Although some environments were eventually recovered, the process was time-consuming.
The incident underscored a general consensus that, while collections need to remain editable by contributors, environments are typically more static, stable, and referenced across all collections. The lack of dedicated controls for environments feels counterintuitive and introduces the risk of significant disruptions.
Ambiguous terms: occasionally, often, sensitive, time-consuming, manually, cumbersome, prone to issues, accidental, more explicit, various, desired, may, confusion, additional, widely, typically, counterintuitive, significant
Questions:
1. What specific challenges arise from the current lack of environment backup in Postman?
2. How would the proposed solution impact the workflow for managing environments in Postman?
Clarified requirement: Investigate the challenges caused by the absence of environment backup in Postman and propose a solution that involves implementing more explicit permissions for managing environments, requiring teams to request modifications through designated Admin teams or by initiating a ticket when no Admin is assigned. This solution aims to centralize environment management and ensure secure handling of sensitive information.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

In postman application you introduce a check box "Stop run if an error occurs" on my suggestion a while ago.
But this flag is not working as I expect; test run stops only if endpoint is not responding(rest path does not exist).
I would like to extend this and include in stop condition a fail assertion or introduce a new check box flag "Stop run on assertion fail".

In my team we have complex test scenarios, sometimes 20-30 steps per folder. We have blue green deployment and we can easily spot failing tests. Then we execute tests with local code in order to detect the issue. If failing test is at 17 out of 30 steps for example we start running the folder and untick steps that are after failing test to be able to call again failing one in order to investigate. This is a bit annoying to tick so many check boxes and stop on assertion fail condition will help a lot and will be more easy to rich failing conditions.

### Describe the solution you'd like

I would like to extend this and include in stop condition a fail assertion or introduce a new check box flag "Stop run on assertion fail".

### Describe alternatives you've considered

![image](https://github.com/user-attachments/assets/566864b6-08b9-423a-a24b-a83a9214f333)


### Additional context

_No response_
Ambiguous terms: fast, user-friendly, complex, easily, rich
Questions:
1. What specific behavior are you expecting when the "Stop run if an error occurs" flag is enabled?
2. Can you provide more details on how the current flag behaves in different scenarios?
Clarified requirement: Is there an existing request for the feature to extend the "Stop run if an error occurs" functionality in Postman to include stopping on assertion fail or introducing a new checkbox flag "Stop run on assertion fail"?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When using the Postman documentation, the code generation feature includes a long list of programming languages. For users who primarily work with only a few languages, this can make the interface feel cluttered and less efficient. Having the option to hide unused languages would streamline the workflow and improve usability.

### Describe the solution you'd like

I would like a way to customize the languages available in the code generation dropdown menu. Ideally, Postman could offer a settings option where users can select or deselect languages they commonly use, so only these appear in the dropdown.

### Describe alternatives you've considered

One alternative could be to allow users to "pin" or prioritize certain languages at the top of the dropdown, making them easier to access without removing others. Another option could be to create a frequently-used languages section based on the user’s past selections.

### Additional context

This feature would be particularly helpful in reducing unnecessary scrolling and making the interface cleaner for users with specific language preferences.
Ambiguous terms: customize, select, deselect, pin, prioritize, frequently-used, specific
Questions:
1. What does "customize" mean in the context of selecting languages for the code generation dropdown menu?
2. Can you clarify what "pin" and "prioritize" mean in relation to certain languages in the dropdown?
Clarified requirement: Is there a feature request to allow users to customize the languages available in the code generation dropdown menu in Postman? This customization would involve the ability to select or deselect specific languages, pin or prioritize certain languages at the top of the dropdown, and potentially create a frequently-used languages section based on past selections. This feature aims to streamline workflow, improve usability, and reduce unnecessary scrolling for users with specific language preferences.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I’ve got a post-response script that uses the handy Visualize feature to create a visualization of the result. I'd like to automatically highlight/activate that tab in my script.

### Describe the solution you'd like

An API to set the active tab in the response area.

### Describe alternatives you've considered

None. :) 

### Additional context

_No response_
Ambiguous terms: handy, automatically, handy, None
Questions:
1. What does "handy Visualize feature" refer to?
2. Can you clarify what you mean by "automatically highlight/activate that tab in my script"?
Clarified requirement: Is there an existing request for an API that can set the active tab in the response area? I have searched for duplicates and know they will be closed. My feature request is related to a problem with my post-response script that utilizes the Visualize feature to create a visualization, and I would like the ability to programmatically highlight or activate that tab in my script.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Dear Postman Development Team,

I am trying to test my API locally using the Postman web app, but I encounter the following error:

``` 
When testing an API locally, you need to use the Postman Desktop Agent. You currently have a different Agent selected, which can’t send requests to the Localhost.
```

I could not find a straightforward installation guide for the Postman Agent on Ubuntu. Could you please provide detailed, step-by-step instructions on how to install the Postman Agent on Ubuntu?

Alternatively, is there a way to use the Postman web app with localhost or any other solution to test my API locally on Ubuntu?

Thank you very much for your assistance.

### Describe the solution you'd like

Providing installation steps

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: straightforward, detailed, step-by-step
Questions:
1. What specifically do you mean by "straightforward" installation guide?
2. Can you clarify what you mean by "detailed, step-by-step" instructions?
Clarified requirement: "Check if there is an existing request for the feature and provide installation steps for the Postman Agent on Ubuntu. If no existing request, then provide guidance on using the Postman web app with localhost for testing APIs on Ubuntu."


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When I’m testing my backend API routes, it’s challenging to differentiate between requests that are working, not working, and completed.

### Describe the solution you'd like

To address this issue, we can add checkboxes or color symbols to each request for differentiation. For instance, a cross checkbox indicates a request is not working, an unchecked checkbox signifies the request has not been tested, and a checked checkbox means the request has been tested and is working.

### Describe alternatives you've considered

We can use color symbols for easy differentiation: red indicates a request isn't working, yellow means it hasn't been tested, and green shows the request has been tested and is working.

### Additional context

Exactly. We could design a system similar to a to-do app, where each API request has a status indicator. Green, yellow, and red colors would visually show the progress: green for tested and working, yellow for not tested yet, and red for not working. This way, you can quickly see the status of each request without any confusion. Visual clarity is everything!
Ambiguous terms: challenging, easy, quickly, confusion, visual clarity
Questions:
1. What specific challenges are faced when differentiating between requests that are working, not working, and completed?
2. How would the system visually indicate the status of each request?
Clarified requirement: Is there a need for a system to visually differentiate between working, not working, and completed requests in backend API testing, using checkboxes or color symbols to represent the status of each request?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

The problem is of the following nature. Previously, the length of the window was enough to name the token variables. Now the length of the token window is missing. Please return it.
![image](https://github.com/user-attachments/assets/016d1cfa-7020-40af-9952-050ca24d8f30)


### Describe the solution you'd like

The problem is of the following nature. Previously, the length of the window was enough to name the token variables. Now the length of the token window is missing. Please return it.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: fast, user-friendly
Questions:
1. What specific feature request is being asked for in this requirement?
2. Can you clarify what is meant by "the length of the token window"?
Clarified requirement: Is there an existing request for returning the length of the token window as a feature? The request is to bring back the ability to name token variables based on the length of the token window.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

<img width="852" alt="Screenshot 2024-10-28 at 11 52 41 AM" src="https://github.com/user-attachments/assets/b7bb3c47-f43f-4052-b73c-b052ec256d49">

Currently, there is no way to support a schema along with description to support proper documentation. This is for both request and response.

### Describe the solution you'd like

Postman should be able to parse and understand schema with each Type and support description next to each.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: proper, support, understand, should
Questions:
1. What specific types of schemas are being referred to in this context?
2. Can you clarify what is meant by "support description next to each"?
Clarified requirement: Is there a need for a feature in Postman that allows for the parsing and understanding of schemas with different types, along with the ability to include descriptions for each type in both requests and responses?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

web browsers default spell checker does not work with the Postman editor

### Describe the solution you'd like

Postman Editor should be compatible with all web browsers default spell checker.

### Describe alternatives you've considered

Web browser spell checks works when you switch from the Postman editor to the classic markdown editor option.  To workaround this issue, you can also use the Grammarly browser extension for Edge and Chrome.

### Additional context

_No response_
Ambiguous terms: compatible, all, works, classic, workaround
Questions:
1. What does "compatible" mean in this context?
2. Can you clarify what you mean by "classic markdown editor"?
Clarified requirement: Is there an existing request for making the Postman Editor compatible with all web browsers' default spell checkers? The current issue is that the web browsers' default spell checker does not work with the Postman editor, and switching to the classic markdown editor or using the Grammarly browser extension are considered as alternative solutions.


Clarify this requirement: ### Describe your current workflow

I use the Postman extension on VSCode.

### Describe your ideal workflow

I would like to use Postman extension in the Positron IDE which is based on VSCode.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: ideal, based
Questions:
1. What specific features or aspects of the Postman extension are you looking to utilize in your ideal workflow?
2. When you mention that the Positron IDE is based on VSCode, what similarities or differences between the two platforms are relevant to your workflow?
Clarified requirement: Describe how you currently use the Postman extension on VSCode, explain the specific features you want to utilize in your ideal workflow using the Postman extension in the Positron IDE, which is based on VSCode. Additionally, detail any relevant similarities or differences between the Positron IDE and VSCode that impact your workflow.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

In postman app, we can download the response to a file with `send and download` option, which is not available in VSCode Postman extension. This would be very handy when testing APIs returning files.

### Describe the solution you'd like

A button with `send and download` option to download returned response to file on local machine.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: handy, button, download, file
Questions:
1. What is meant by "handy" in this context?
2. When referring to a "file," what type of file is being downloaded?
Clarified requirement: Is there an existing request for a feature that allows users to download the response to a file on their local machine using a "send and download" button in the VSCode Postman extension? This feature would be useful for testing APIs that return specific types of files.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Currently, when setting up an endpoint, it’s possible to include multiple variables like in this example: https://{{BookingBaseUrl}}/v1/{{tc_automation}}{{location}}.

Over time, the variables may need to be changed, updated, or removed. However, to make these adjustments, I currently have to manually edit each request within my collections, which is time-consuming.

It would be more efficient to have the option to right-click on a variable and access a menu with options to replace or remove the variable throughout the entire collection. This feature would streamline the process of managing variables across collections.

**This feature could also be applied to headers, etc. I believe it would be simple to implement and would greatly improve efficiency in the workflow.

### Describe the solution you'd like



It would be more efficient to have the option to right-click on a variable and access a menu with options to replace or remove the variable throughout the entire collection. This feature would streamline the process of managing variables across collections.

**This feature could also be applied to headers, etc. I believe it would be simple to implement and would greatly improve efficiency in the workflow.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: efficient, streamline, simple, greatly improve
Questions:
1. What specific variables are being referred to in this feature request?
2. Can you provide an example of how the current manual editing process works?
Clarified requirement: There is a need for a feature that allows users to right-click on a variable in an endpoint setup and access a menu to replace or remove the variable throughout the entire collection. This feature should apply to variables like {{BookingBaseUrl}}, {{tc_automation}}, and {{location}}. The goal is to simplify the process of managing variables across collections by providing a more efficient way to make adjustments.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

In VSC I cant export collections, folders or single requests. I wanted to export something and send it directly to someone without the need to login at the postman vsc extension and inviting someone to my workspace

### Describe the solution you'd like

It would be great if a simple export and a working import for that would exist so i can share my stuff using exported files

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: simple, working, great, stuff, share, exported files
Questions:
1. What specifically do you mean by "simple export" and "working import"?
2. Can you clarify what you mean by "share my stuff using exported files"?
Clarified requirement: Is there an existing request for a feature that allows exporting collections, folders, or single requests in VSC without the need to login to the Postman VSC extension or invite someone to a workspace? The feature should include a clear process for exporting and importing files for sharing purposes.


Clarify this requirement: ### Describe your current workflow

Hello,

There are two tools I love :
-Postman
-Python

On Postman I use a lot the collections, this is the best way to organize all this stuff. And since my environments can vary, I also use environment files and my collections are variabilized.
Right now, I copy the python Postman gives and re-variabilize it on python.


### Describe your ideal workflow

I would like to have is a python package with a command like "postman_collection" that would have three arguments : 
-a postman collection file (mandatory)
-a postman environment file (optional)
-a query name (mandatory) 

and launch the said query with the variables coming from the environment.

Best regards,

Simon

### Describe alternatives you've considered

N/A

### Additional context

Additionnaly, once the package released, it can be leveraged on a lot of tools, such as the Amphi ETL.
Ambiguous terms: ideal, best, a lot of, such as
Questions:
1. What does "variabilized" mean in the context of using collections and environment files in Postman?
2. Can you clarify what you mean by "launch the said query with the variables coming from the environment"?
Clarified requirement: Describe your ideal workflow for a Python package that includes a command "postman_collection" with three arguments: a mandatory Postman collection file, an optional Postman environment file, and a mandatory query name. The command should execute the query using variables from the environment.


Clarify this requirement: ### Describe your current workflow

We use discord to communicate issues with devops and developers

### Describe your ideal workflow

We use discord to communicate issues with devops and developers

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: ideal, issues
Questions:
1. What specific types of "issues" are typically communicated with devops and developers?
2. Can you clarify what you mean by an "ideal workflow" in the context of using Discord for communication?
Clarified requirement: Describe the specific types of problems or challenges that are typically communicated with devops and developers using Discord, and explain what an optimal communication process using Discord would look like.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I have an API that requires a specific header to be set containing the size of the input file (request body) when doing a POST or PATCH of a binary file to be uploaded.  I would like to be able to calculate and populate this automatically instead of having to manually enter the value in the header for each request.

### Describe the solution you'd like

When I have a request body that references a file to be uploaded, I would like to be able to write a pre-request script to read the file size and set a header to that value.  I already have the ability to programmatically set a header.  I could also set the header to a variable and use a script to set the file size in that variable.  However, I don't have a way to calculate the size of the input file.  A solution might look something like "pm.collectionVariables.set("UPLOAD_CONTENT_LENGTH", pm.request.body.file.size);" or an equivalent comment to set a header.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: specific, automatically, manually, references, pre-request, programmatically, calculate, variable, equivalent
Questions:
1. What type of API is being used for this feature request?
2. Can you provide an example of how the header should be set based on the file size?
Clarified requirement: Is there an existing request for a feature that allows setting a specific header automatically based on the size of the input file when uploading a binary file via a POST or PATCH request in an API? If not, the feature request is to enable writing a pre-request script that calculates the file size and sets a header to that value for each request body referencing a file to be uploaded.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I need to call API's that require a client certificate to be presented
I am using Postman VSCode extension v1.3.0

### Describe the solution you'd like

In a similar manner to the Postman app, I need to be able to associate client certificates with a URL.

### Describe alternatives you've considered

There are none

### Additional context

NA
Ambiguous terms: similar, associate
Questions:
1. What does "associate client certificates with a URL" entail?
2. Can you clarify what you mean by "similar manner to the Postman app"?
Clarified requirement: Is there a previous request for adding the ability to link client certificates with specific URLs in the Postman VSCode extension v1.3.0, similar to how it is done in the Postman app?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

When running with Cloud Agent some of my tests failed (I have to adjust the timeout manually each time) but the same tests don't fail when running with Monitor or Scheduler (even if they are ran in the cloud also??) ?

### Describe the solution you'd like

It will be helpful to adjust the timeout for the tests because, I like to do the same if I run the Collections from Cloud Agent or Desktop Agent then the timeout is used. 
Is there a Postman API or a pm function to check if Cloud/Desktop Agent is used ?
Something like this **_pm.runner.name_** ? :

```
switch(pm.runner.name) {
    case 'Cloud Agent':
      timeout = 5500
      break;
    case 'Desktop Agent':
      timeout = 2500
      break;
    case 'Monitor':
      timeout = 2500
      break;
    case 'Scheduler':
      timeout = 2500
      break;
    default:
    timeout = 1500
}

// WAIT 1-5 SEC TO GET THE RESPONSE 

function pauseForStateTransition (pm, timeoutNumber) {
   const moment = require("moment");
   let startMoment = moment();
  
   setTimeout(function() {
   let diffDuration = startMoment.diff(moment());
   }, timeoutNumber);
}

pauseForStateTransition(pm, timeout);
```


### Describe alternatives you've considered

I have checked this article for reference here: https://learning.postman.com/docs/tests-and-scripts/write-scripts/postman-sandbox-api-reference/#scripting-with-response-data
but I can't find the expected solution I need.

### Additional context

_No response_
Ambiguous terms: adjust, helpful, like, check, something like, expected
Questions:
1. What specific criteria determine whether the tests are run with Cloud Agent or Desktop Agent?
2. How should the timeout values be set for the tests when not running with Cloud or Desktop Agent?
Clarified requirement: Check if the tests are run with Cloud Agent or Desktop Agent to adjust the timeout values accordingly. Set specific timeout values based on whether the tests are run with Cloud Agent, Desktop Agent, Monitor, or Scheduler. Use a Postman API or a pm function to determine the agent used and apply the appropriate timeout value settings as described in the provided code snippet.


Clarify this requirement: ### Describe your current workflow

API to AirTable to create a Vectara RAG for updating AirTable

### Describe your ideal workflow

It will allow for our app to work as intended.

### Describe alternatives you've considered

Tried Insomnia and the interface was "lacking".

### Additional context

_No response_
Ambiguous terms: ideal, intended, lacking
Questions:
1. What specific functionalities should the ideal workflow include to align with the intended use of the app?
2. In what way was the interface of Insomnia considered "lacking" in comparison to what was needed?
Clarified requirement: Describe the specific functionalities that the ideal workflow should have in order to align with the intended use of the app, and explain in what aspect the interface of Insomnia was considered "lacking" compared to the requirements.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Sometimes payloads or request resource identifiers can be extracted by using post scripts and those work great. Sometimes dynamic variables work for things that are not consequential. However, sometimes these features just don't cut it. It would be nice to have something that would prompt a user form upon clicking the send button to input variables. 

### Describe the solution you'd like

Let's suppose we have an api endpoint called **GET** v1/charts/**{{id}}**. It would be nice to have something like /charts/**{{$formTextInput}}** where post man would generate a form where the user could type the input. 

Let's also suppose there is a post call named POST v1/charts where the payload is:

```
{
  "name": "my chart",
  "teams": [
      "teamId1",
      "teamId2"
   ],
   "dashboardId": "1234"
}
```

It would be nice to have a smart variable storage as options for future dynamic form directive inputs. For instance I would like to make two request calls as a precondition for creating my new chart resource because the chart payload needs an array of team ids and one dashboard id property. 

**GET v2/teams**

```
{
   "results": ["teamid1", "teamid2"]
}
```
**post script**
```pm.environment.set("teamIds", body.results)```


**GET v2/dashboards**

```
{
   "results": ["dbID1", "dbID2"]
}
```
**post script**
```pm.environment.set("dashboardIds", body.results)```

Having these form options would allow us to have a post or put call where the payload for POST /v2/charts could be 
```
{
    "name": "{{$formTextInput}}", <- no variable specified so it takes any arbitrary val
    "teams": "{{$formMultiSelectInput:teamIds}}", <- populates multi select input with team ids collected from teamIds
    "dashboardId": "{{$formDropdownInput:dashboardIds}}" <- populates a dropdown with dashboard id options collected from dashboardIds
     "expirty": {{$formDateTimeInput}} <- creates a datepicker with an option for date format string or epoch timestamp
}
```

Personally, I would have two options as I typically generate a sequence of steps for every folder that represents a resource set in my collection. I'd probably have a folder where I'd name **charts** and another called **charts dynamic**. 

### Describe alternatives you've considered

Creating a different request for every scenario which is not fun for adhoc testing.

### Additional context

_No response_
Ambiguous terms: nice, smart, future, arbitrary, options, typically, probably, fun
Questions:
1. What specific functionality is meant by "smart variable storage as options for future dynamic form directive inputs"?
2. Can you clarify what is meant by "arbitrary val" in the payload example?
Clarified requirement: Is there an existing request for this feature? I have searched the existing issues for this feature request and I know that duplicates will be closed. If your feature request is related to a problem where sometimes payloads or request resource identifiers need to be inputted by users, a solution is needed. The solution desired is the ability for Postman to generate a form for user input upon clicking the send button. For example, when making API calls like GET v1/charts/{{id}}, it would be beneficial to have a feature where users can input variables like /charts/{{$formTextInput}} in a generated form. This form input feature should also allow for smart variable storage options for future dynamic form directive inputs, such as populating multi-select inputs or dropdowns with data from previous API calls. This functionality is aimed at streamlining the process of creating requests with dynamic inputs.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I am trying to do a pull request for a gRPC collection but this seems impossible. You can for a gRPC collection but not do pull requests or merges, which is a missing feature in my opinion. I also noticed today gRPC is missing the "Try" button when using examples.

The gRPC capability was put in a few years ago and appears as though it has been forgotten with half-working features and missing features such as Pull Requests, Changelog, Exporting, to name a few.


### Describe the solution you'd like

Fully featured collections tools such as Pull Requests, Changelogs and Exporting. But Pull Requests is a major personally.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: impossible, missing feature, half-working, missing features, fully featured, major
Questions:
1. What specific features are missing in the current gRPC collection tool?
2. Can you elaborate on why Pull Requests are a major feature that is personally important to you?
Clarified requirement: Is there an existing request for fully featured collections tools in the gRPC collection tool, specifically including Pull Requests, Changelogs, and Exporting?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

This is not related to Postman core functionality.

### Describe the solution you'd like

Postman audit logs are currently available from the team administration web console and those logs only offer 90 days of data. As an Information Security Consultant, I want to be able to stream those logs to an external tool such as Azure Monitor/Log Analytics. Shipping the audit logs would allow for longer retention, simplified querying, and reduced manual steps to access the data.

Currently the file has to be requested in from the admin console. The export is not immediately available, the link is sent by email, and the download window for the log is only 1 hour. It's easy to miss the download window which means repeating the manual steps which is inefficient. Where if the logs were shipped to a Log Analytics workspace for example the data would be alongside the other environment data and readily available to query, and even trigger alerts based on events.

### Describe alternatives you've considered

I've searched the documentation for an audit log api to retrieve the data myself but have not located a method to accomplish that.

### Additional context

In a regulated environment it's important to know who is making what changes in a platform that is used in the application development process.
Ambiguous terms: longer, simplified, easy, readily, important
Questions:
1. What specific external tool or tools are you considering for streaming the audit logs?
2. Can you provide more details on the current process of requesting the audit logs from the admin console?
Clarified requirement: Is there an existing request for the feature of streaming Postman audit logs to an external tool such as Azure Monitor/Log Analytics? The current process involves requesting the logs from the admin console, which is inefficient due to limited availability and manual steps.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I was trying to replicate the usage of rest api collection, like the sequence request and user performance testing tools. But i could not find a way to do it for grpc

### Describe the solution you'd like

Extend the grpc collection be be able to do the actions of rest api collections

### Describe alternatives you've considered

Make another section to describe how many test to launch or simulate user interaction

### Additional context

_No response_
Ambiguous terms: extend, actions, describe, how many, simulate, interaction
Questions:
1. What specific actions do you want the extended grpc collection to be able to perform?
2. Can you provide more details on what you mean by "simulate user interaction" in the alternatives considered?
Clarified requirement: Is there an existing request for this feature? I have searched the existing issues for this feature request and I know that duplicates will be closed. My feature request is related to replicating the usage of a rest api collection, specifically the sequence request and user performance testing tools, for grpc. I would like the grpc collection to be extended to perform the actions of rest api collections. As an alternative, I have considered creating another section to describe the number of tests to launch or simulate user interaction.


Clarify this requirement: ### Is there an existing request for this feature?

- [x] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

As a Postman user, I frequently run performance tests on my API. After several test runs, my dashboard becomes cluttered with old test results that are no longer relevant. However, there doesn't appear to be an option to delete specific performance test runs from the dashboard, which can make it harder to manage or view the results I actually care about.

### Describe the solution you'd like

There should be an option to delete or archive old performance test runs, so users can manage their test results more effectively.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: frequently, cluttered, old, specific, harder, effectively
Questions:
1. What defines an "old" test result in this context?
2. How should the option to delete or archive test runs be implemented in the dashboard?
Clarified requirement: Is there an existing request for a feature that allows Postman users to delete or archive specific performance test runs from the dashboard to manage their test results more effectively?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

We publish our API documentation based on our Postman collection. In addition to adding new folders and requests, we often move existing folders and requests to improve readability. Because of the difficulty of identifying changes, the most convenient method to update has been to use _Replace a collection's data_ and let Postman sort out the merge.

When the file size approaches 10 to 12 MB, Postman often returns the error: "Request body size limit exceeded," or the gateway returns 504 Gateway Timeout errors.

### Describe the solution you'd like

The documentation for _Replace a collection's data_ states:

> The maximum collection size this endpoint accepts cannot exceed 20 MB.

Postman routinely fails as the file approaches 10 MB and always fails when the file approaches 12 MB (I submitted a bug). However, even if Postman fixes the bug, our product continues to add features and the Postman collection grows. At some point, it will exceed the 20 MB limit.

Permit _Replace a collection's data_ to accept `Content-Type: application/octet-stream` for  for collections greater than 20 MB.

### Describe alternatives you've considered

I tried to remove all .body keys and then update them individually, but _Update a response_ does not update .body. I tried to remove .item[] keys and then update them individually, but _Update a folder_ does not update .item[].

In theory, I could diff the JSON, but even if I made the hundreds of calls to update the changes, example responses would remain useless because .body keys cannot be updated.

### Additional context

_No response_
Ambiguous terms: fast, user-friendly, convenient, often, approaches, routinely, continues, at some point, greater than, attempts, useless
Questions:
1. What specific issues arise when Postman returns the error "Request body size limit exceeded" or a 504 Gateway Timeout error?
2. Can you clarify what you mean by "the most convenient method to update has been to use _Replace a collection's data_ and let Postman sort out the merge"?
Clarified requirement: Is there an existing request for the feature to permit _Replace a collection's data_ to accept `Content-Type: application/octet-stream` for collections greater than 20 MB due to Postman errors like "Request body size limit exceeded" or 504 Gateway Timeout errors, and can you explain why using _Replace a collection's data_ is the preferred method for updating?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Clear All Cookies' is easily clicked by mistake
![o2gfmsup5w](https://github.com/user-attachments/assets/3109a9bf-8239-4a7f-8f30-9536c7378cf1)


### Describe the solution you'd like

Opening the Cookies Settings popup, the 'Clear All Cookies' button at the bottom is easily mistaken for a close button and clicked. Additionally, why is there no secondary confirmation dialog for such an important action?

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: easily, important
Questions:
1. What specific action triggers the 'Clear All Cookies' button to be easily clicked by mistake?
2. Can you clarify what you mean by a "secondary confirmation dialog" for the 'Clear All Cookies' action?
Clarified requirement: Is there an existing request for a feature that addresses the issue where the 'Clear All Cookies' button is easily clicked by mistake and lacks a secondary confirmation dialog for such an important action?


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Postman does not provide a way to directly monitor or control an open SSE (Server-Sent Events) connection from other requests. This makes it difficult to verify whether a specific event has been received in response to a certain API request, especially when time-sensitive actions are required. In real-world use cases, where systems rely on real-time event streams, this limitation can hinder effective API testing and validation of reactive behaviors.

My request relates to this [post](https://community.postman.com/t/pm-sendrequest-with-sse-how-to-access-streamed-events/54206)

### Describe the solution you'd like

I would like Postman to introduce functionality that allows users to observe or monitor an active SSE connection and link it to a collection, a group of requests or one request.

This feature should enable the verification that a particular event has been received in response to a request within a specified time window (e.g., within n milliseconds).

This would greatly enhance the ability to test real-time, event-driven systems and improve the reliability of API testing in reactive architectures.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: difficult, verify, specific, real-time, enhance, reliability
Questions:
1. What specific actions are considered time-sensitive in this context?
2. How would the ability to monitor an active SSE connection improve the reliability of API testing?
Clarified requirement: Is there an existing request for a feature in Postman that allows users to observe or monitor an active SSE connection and link it to a collection, group of requests, or a single request? This feature should enable users to verify that a particular event has been received in response to a request within a specified time window, enhancing the ability to test real-time, event-driven systems and improving API testing reliability.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

![postmanApi](https://github.com/user-attachments/assets/2d657c57-3f97-4524-9152-a5712e0ac07e)

I created a new api from a swagger file and a collection from it.

I added to the swagger file user endpoints and now when I update the collection the new requests are created without a folder structure.

If I generate a new collection from the New Api, then folders are created.

![newFakeApi](https://github.com/user-attachments/assets/8cc8d728-efbf-4612-8de8-f1fc6872f332)


### Describe the solution you'd like

If I update an "api collection" by an updated definition file it should create the folder structure as expected without generating a new collection.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: should, expected
Questions:
1. What is meant by "folder structure" in this context?
2. What is the expected behavior when updating an "api collection"?
Clarified requirement: Update an "api collection" with an updated definition file should organize the requests within the collection into folders based on the structure defined in the file, without the need to generate a new collection.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

no - this is a feature request

### Describe the solution you'd like

Adding a description to a folder - it is desirable to have a link which takes you somewhere that is variable configurable...

lets say you have a variable "URL" set to "https://some.instance.somewhere"
Now you have a folder like "Endpoint - xyz" with a description that would take you {{URL}}/swagger#/some-controller-documentation

When trying to edit a url - it complains to enter a valid URL because variable replacement isn't happening

### Describe alternatives you've considered

hacking the app?

### Additional context

_No response_
Ambiguous terms: desirable, variable, configurable, valid, hacking
Questions:
1. What does "variable configurable" mean in this context?
2. Can you clarify what is meant by "variable replacement isn't happening"?
Clarified requirement: Is there an existing request for the feature of adding a description to a folder with a link that is customizable? The link should include a variable URL that can be configured and should lead to a specific location. Currently, when attempting to edit the URL, an error occurs due to the variable replacement not functioning correctly.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I'm using Postman for GraphQL queries for about a year and I've noticed that GraphQL Variables view in POST request is not useful for me. It'd be great if we could close it, because at this moment it's taking quite a lot of space being just empty for most of the time:

<img width="664" alt="image" src="https://github.com/user-attachments/assets/7139366a-32c2-4c72-b9d2-2ae74374b298">

While using the GraphQL requests, it can be minimized tho:

<img width="369" alt="image" src="https://github.com/user-attachments/assets/32342e6e-3153-404b-a54a-7a8e386f0071">


### Describe the solution you'd like

An option to hide/minimize the GraphQL view. It could be closed by default if variables are empty and open when some have been specified. 

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: hide/minimize, closed, open, empty, some have been specified
Questions:
1. What does "hide/minimize" mean in this context?
2. Can you clarify what you mean by "closed by default if variables are empty and open when some have been specified"?
Clarified requirement: Check if there is an existing request for a feature that allows hiding or minimizing the GraphQL view in Postman, with the view being closed by default when variables are empty and open when variables have been specified.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I couldn't find a way to send a specific type of request in-app. When sending a POST request using the form-data option, I'm unable to input an array of size one (size 2 and above is okay because postman recognizes the duplicate key names) I had to use other API tools like Hoppscotch or APIDog.

### Describe the solution you'd like

If there could be a third "array" option in addition to "text" and "file" in the form field dropdown.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: specific, array of size one, third, array option
Questions:
1. What is meant by "specific type of request" in this context?
2. Can you clarify what is meant by "third 'array' option" in the solution description?
Clarified requirement: Is there an existing request for this feature? I have searched the existing issues for this feature request and I know that duplicates will be closed. My feature request is related to a problem where I couldn't find a way to send a specific type of request in-app. When sending a POST request using the form-data option, I'm unable to input an array of size one (size 2 and above is okay because postman recognizes the duplicate key names) I had to use other API tools like Hoppscotch or APIDog. The solution I'd like is to have a third "array" option in addition to "text" and "file" in the form field dropdown.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I run into a problem of having the same `baseUrl` variable defined in both environment and collection variables. The environment variable value is something like `https://example.com` while the collection variable value is like `/api/foo`. The request URL uses `{{baseUrl}}` which is resolved to environment variable, but the actual expected value should be the combination of both environment variable and collection variable.
See more info here: https://community.postman.com/t/conflict-of-same-variable-in-collection-and-environment-scopes/67958/4

### Describe the solution you'd like

The request URL is expected to be something like `{{pm.environment.baseUrl}}{{pm.collectionVariables.baseUrl}}/...`.

### Describe alternatives you've considered

Pre-request script:
```
pm.request.url.update(`${pm.environment.get('baseUrl')}${pm.collectionVariables.get('baseUrl')}${pm.request.url.getPath()}`)
```

### Additional context

https://community.postman.com/t/conflict-of-same-variable-in-collection-and-environment-scopes/67958/4
Ambiguous terms: expected, combination, like, something, actual, expected, alternative
Questions:
1. What is the expected behavior when combining the environment and collection variables for the request URL?
2. Can you provide a specific example of how the request URL should look after combining the variables?
Clarified requirement: Determine the appropriate way to combine the environment and collection variables to form the request URL in Postman, ensuring that the URL reflects the correct values from both variables.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I can only select a run frequency with a minute, hour, or weekly timer for scheduling my collection runs.

### Describe the solution you'd like

I need a custom timer with hours and minutes for scheduling my collection run (i.e. every 3 hour + 15 minutes)

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: custom, hours, minutes
Questions:
1. What does "custom" timer mean in this context?
2. Can you clarify how the hours and minutes should be used in the scheduling?
Clarified requirement: Is there an existing request for a feature that allows users to schedule collection runs with a custom timer, specifying hours and minutes for the frequency? The feature should enable users to set specific time intervals such as every 3 hours and 15 minutes for their collection runs.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Here is the problem,
I am working on a module called Fleet.
It's requests can be found inside **Crm** folder under **Fleet Management** folder and **Settings** >> **Fleet** folder.
This module is in development and front-end team keeps trying to implement them but they keep changing.

### Describe the solution you'd like

I want to mark the **Fleet Management** folder and **Fleet** (in Settings) with _dev_ tag as shown:
![image](https://github.com/user-attachments/assets/26afb4ab-54ad-4eac-96d8-31e9a9978167)
This will prevent the front-end team from implementing these folders until we are done because endpoints, payloads and other things may change during dev.

### Describe alternatives you've considered

I've considered adding **--dev** at the end but it does not look cool

### Additional context

_No response_
Ambiguous terms: cool
Questions:
1. What does "cool" mean in the context of adding "--dev" at the end?
2. Are there any specific criteria or guidelines for determining what looks "cool" in this scenario?
Clarified requirement: _No response_


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

I want to quickly select the request from a bunch of requests. I'm using the search box in Sidebar and am content with it, but focusing it with mouse is a bit frustrating for me.

### Describe the solution you'd like

I want a keyboard shortcut to focus the search box. It would be quicker than selecting it with the mouse.

### Describe alternatives you've considered

I have tried "Search Postman" (Cmd + a), but the result included a lot of irrelevant items and was hard to find the item I was looking for.

### Additional context

_No response_
Ambiguous terms: quickly, quicker, frustrating, hard
Questions:
1. What specific actions are involved in focusing the search box with the mouse that are frustrating for the user?
2. Can you clarify what you mean by "quickly" in the context of selecting the request from a bunch of requests?
Clarified requirement: Determine if there is an existing feature request for adding a keyboard shortcut to focus the search box in the Sidebar of the application. The user finds it frustrating to manually select the search box with the mouse and seeks a quicker method to do so.


Clarify this requirement: ### Is there an existing request for this feature?

- [X] I have searched the existing issues for this feature request and I know that duplicates will be closed

### Is your feature request related to a problem?

Hope to add Chinese language UI

### Describe the solution you'd like

Hope to add Chinese language UI

### Describe alternatives you've considered

_No response_

### Additional context

_No response_
Ambiguous terms: Hope, Chinese language UI
Questions:
1. What specific elements or components are included in the "Chinese language UI"?
2. Are there any specific requirements or preferences for how the Chinese language UI should be implemented?
Clarified requirement: Is there an existing request for adding a Chinese language user interface (UI) with specific elements or components, and are there any specific requirements or preferences for its implementation?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

We use the design-first approach in our company for API development. The only reason that has stopped me from ditching postman in my teams and using hoppscotch is the fact that we cannot add examples to requests before sending one request (because we're just in the design step and there are no endpoints to send request) which stops us from documenting the API responses easily in hoppscotch.

### Why should this be worked on?

This could easily help design-first teams to use hoppscotch for documented their APIs instead of waiting for a prototype to be complete before they can document responses.
Ambiguous terms: fast, user-friendly
Questions:
1. What specific features are missing in Hoppscotch that prevent users from adding examples to requests before sending them?
2. Can you clarify how documenting API responses in Hoppscotch differs from other tools like Postman?
Clarified requirement: Is there a way to add examples to requests in Hoppscotch before sending them, as this feature is currently missing and preventing design-first teams from easily documenting API responses in the tool?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I am using desktop app. When I use multiple tabs and switch between them, Hoppscotch resets the scroll position to the top. It becomes difficult when working with long request/response bodies because I have to manually scroll back each time. I would like Hoppscotch to remember the last scroll position per tab. When switching back to a tab, it should restore to the previous scroll position automatically.

### Why should this be worked on?

I can remember where I was but Manually remembering is not convenient for large responses.
Ambiguous terms: difficult, long, remembering, convenient, large
Questions:
1. What is Hoppscotch?
2. Can you clarify what you mean by "Manually remembering is not convenient for large responses"?
Clarified requirement: Is there an existing issue in the Hoppscotch desktop app where the scroll position resets to the top when switching between multiple tabs? The request is to have Hoppscotch remember the last scroll position per tab and automatically restore it when switching back to a tab to make it more convenient for users dealing with large response bodies.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Others have mentioned this issue (Issue #3602, #4306). The desktop app currently does not support OAuth 2.0, despite having the option. You can't add the redirect url, and when you try to generate the token without it, you can't go back to the previous page.

### Why should this be worked on?

Many modern APIs utilize OAuth 2.0
Ambiguous terms: modern, utilize
Questions:
1. What specific problem is being referred to as "this issue"?
2. Is the issue related to the desktop app's lack of support for OAuth 2.0?
Clarified requirement: Is there an existing issue related to the desktop app's lack of support for OAuth 2.0, specifically regarding the inability to add the redirect URL and generate a token without being able to return to the previous page?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

桌面在切换不同的请求接口及菜单时，反应太慢

### Why should this be worked on?

如果这个响应速度无法解决，那使用起来非常不友好
Ambiguous terms: slow, user-friendly
Questions:
1. What specific actions are considered slow when switching between different request interfaces and menus on the desktop?
2. Can you provide more details on what makes the current response speed unfriendly for users?
Clarified requirement: Is there an existing issue related to the slow response when switching between different request interfaces and menus on the desktop? If the response speed issue is not resolved, the usability of the system is negatively impacted.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

One thing I'd love to see on this app is to add a response example for certain request.

### Why should this be worked on?

The example use case is, I could make a prototype for integrating with backend without actually running the backend. The shape of the response is often enough for rough integration
Ambiguous terms: love, certain, often enough, rough
Questions:
1. What specific requests are being referred to when mentioning "certain request"?
2. Can you clarify what is meant by "response example" in this context?
Clarified requirement: Is there an existing issue for this? I have searched the existing issues. One thing that should be worked on is to add a response example for specific requests on the app. The example use case is to make a prototype for integrating with the backend without actually running it, where the shape of the response is sufficient for rough integration.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

1. WS requests are saved / shared in workspaces.
2. it should be possible to set headers for the WS request just like any other REST calls.

a WS request is basically an HTTP request that was migrated to a long running protocol.


### Why should this be worked on?

1. useful for saving ws requests between workspace members + saving them for later + using variables etc.
2. lots of API's these days use sockets that require some kind of authorization token. while from a research from other issues and from
looking on some chat web apps it seems like they put the token in the url (prob due to a limitation in the default web socket implementation
by JS specs IDRC), some API's prefer to use an header. 

even if thats wrong to do that (for some reason IDK) its still a fact that lots of API's do that so would be legit if hoppscotch support it.
Ambiguous terms: possible, like, just like, useful, lots of, some kind of, some API's, some reason, legit
Questions:
1. What specific headers should be able to be set for the WS request?
2. Can you provide examples of API's that use sockets and require authorization tokens?
Clarified requirement: Is there an existing issue for setting specific headers for WS requests, which are HTTP requests migrated to a long running protocol? The feature should allow users to save and share WS requests in workspaces, similar to saving REST calls. It should also support setting headers for WS requests. The need for this feature arises from the usefulness of saving WS requests among workspace members, storing them for future use, and utilizing variables. Additionally, many APIs nowadays use sockets that require authorization tokens, with some opting to include the token in the URL while others prefer using headers. Despite potential concerns about the approach, it is common practice among many APIs, making it a valid feature for Hoppscotch to support.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

It would be great to have optional Vim keybindings in the input fields of Hoppscotch, similar to what tools like Insomnia offer.

Thanks for the amazing work on Hoppscotch.

### Why should this be worked on?

Why it's useful:

- Improves efficiency for Vim users
- Enhances accessibility for those who rely on keyboard navigation
- Adds a productivity boost when editing large or complex payloads

Suggested Scope:

- Enable Vim mode in editable text areas and input fields like request bodies, headers, tests and URL fields.
- Optional toggle in settings for users who prefer classic editing
Ambiguous terms: great, similar, useful, enhances, boost, large, complex, optional, classic
Questions:
1. What specific Vim keybindings are being referred to here?
2. Can you clarify what is meant by "classic editing"?
Clarified requirement: Is there an existing issue for implementing optional Vim keybindings in the input fields of Hoppscotch, similar to the keybindings offered by tools like Insomnia? This feature should enable Vim mode in editable text areas and input fields like request bodies, headers, tests, and URL fields, with an optional toggle in settings for users who prefer classic editing.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Hope to add support for custom headers in WebSocket and SSE, such as custom authorization headers and User-Agent customization, as some servers require specific header validation for authentication or client identification.

### Why should this be worked on?

Hope to add support for custom headers in WebSocket and SSE, such as custom authorization headers and User-Agent customization, as some servers require specific header validation for authentication or client identification.
Ambiguous terms: custom, specific
Questions:
1. What exactly is meant by "custom headers" in the context of WebSocket and SSE?
2. Can you provide examples of the specific header validations that some servers require for authentication or client identification?
Clarified requirement: Ensure support is added for custom headers in WebSocket and SSE, including custom authorization headers and User-Agent customization, to accommodate servers that require specific header validation for authentication or client identification.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

now that we have the ability to save example responses, it would be awesome to annotate response with some comments to covey meaning. 

### Why should this be worked on?

it will help to create a dummy schema of the response to understand the underlying data meaning
Ambiguous terms: awesome, dummy, underlying
Questions:
1. What type of comments should be added to annotate the response?
2. How should the meaning of the underlying data be conveyed in the comments?
Clarified requirement: Is there an existing issue for this? I have searched the existing issues. Now that we have the ability to save example responses, it would be helpful to annotate responses with specific comments to convey meaning. This will aid in creating a schema of the response to understand the underlying data meaning.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

We would like to request a feature that allows users to "star" or "favorite" specific collections so they always appear at the top of the collections list in the sidebar.

### Why should this be worked on?

As a software company, we manage more than 50 collections and work across multiple projects daily. Being able to mark active or important collections as favorites would significantly improve our workflow by making access faster and more organized.

This feature is already available in tools like Postman, and having it in Hoppscotch would be a great improvement for users with large and dynamic sets of collections.

Thank you for the great tool and your continuous efforts!
Ambiguous terms: feature, star, favorite, specific, always, top, active, important, significantly, faster, more organized, great improvement, large, dynamic
Questions:
1. What specific actions should users be able to perform on the "starred" or "favorited" collections?
2. How should the collections list in the sidebar be sorted when users "star" or "favorite" collections?
Clarified requirement: Is there an existing issue for implementing a feature that allows users to mark collections as "favorites" so they can be easily accessed and sorted at the top of the collections list in the sidebar?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

It would be useful to add the Collection folder path to the hover tooltip of request tabs. It might also be handy to add the collection path to the actual tab name, but this would need to be optional with a setting, I could see some of my request tab names getting very long, maybe only show when there are multiple requests with the same base name?

![Image](https://github.com/user-attachments/assets/8cd3484e-9cd2-4f65-8d59-63fdfb2aee0f)

### Why should this be worked on?

Would be useful when working on multiple APIs with the same request names.

At the moment I am setting up collections and then have to name the request with a name that has the collection name as a prefix.
Ambiguous terms: useful, handy, might, very long, maybe, multiple
Questions:
1. What is meant by "Collection folder path"?
2. Can you clarify what is meant by "base name"?
Clarified requirement: Ensure that the Collection folder path is included in the hover tooltip of request tabs. Additionally, consider adding the collection path to the actual tab name as an optional setting. This should be implemented to address situations where there are multiple requests with the same base name, making it easier to differentiate them.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Toggle requested to disable automatic updates. 

### Why should this be worked on?

I work for a Fortune 500 company which has VM's available for contractors to use. In order to make software available to those contractors using VMs, the applications need to be virtualized. The problem is that specific versions are approved because applications are vetted on a version-by-version basis. If automatic updates are enabled and a new version is automatically installed, even for very minor functionality, new requests would need to be submitted to have the new version vetted. To bypass this annoyance, I'd like to request to have a toggle added in the settings of the application.
Ambiguous terms: requested, disable, automatic updates, very minor functionality, annoyance, added
Questions:
1. What specific software or application is this request referring to?
2. Can you clarify what you mean by "toggle" in this context?
Clarified requirement: Is there an existing issue for adding a toggle in the settings of a specific application to disable automatic updates? This is requested to prevent new versions from being automatically installed and requiring vetting for approval.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

This feature would enable Hoppscotch users to automatically re-import their OpenAPI specification from a URL (e.g., an OpenAPI JSON or YAML file hosted on a server). This will ensure that users can work with the most up-to-date version of their API schema directly within Hoppscotch, without having to manually update the API collection each time their backend changes.

### Why should this be worked on?

When developing APIs, backend changes often occur, resulting in modifications to the OpenAPI specification. Currently, users need to manually re-import the updated OpenAPI spec into Hoppscotch, which is time-consuming, error-prone and values get lost.

This feature would streamline the development workflow by automating the re-import process, ensuring that any new or modified endpoints are instantly reflected in the Hoppscotch folder. This would be especially beneficial for teams working on rapidly changing APIs, as it ensures they always work with the latest version of the API specification.
Ambiguous terms: automatically, up-to-date, streamline, rapidly changing
Questions:
1. What does "automatically" re-importing the OpenAPI specification entail?
2. How frequently are the backend changes that are considered "rapidly changing"?
Clarified requirement: The feature aims to allow Hoppscotch users to automate the process of re-importing their OpenAPI specification from a URL, ensuring that they can easily work with the most current version of their API schema without the need for manual updates. This automation is particularly beneficial for teams dealing with frequently changing APIs.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I’d like to propose a feature that allows users to write and save custom prompts for modifying the request body using AI, and then trigger these prompts via keyboard shortcuts.

**Use Case**

One of the most common use cases for modifying a request body is using AI to randomly populate the fields with sample or test data.

In most scenarios, the prompt used for AI generation doesn’t change much. It’s often a simple instruction like:

> "Randomly populate the fields with info."

Because of this simplicity and repetitive nature, it would be very useful to treat it like a reusable macro.

**Proposed Functionality**

- Allow users to define custom prompts for AI-based request body generation.
- Enable saving these prompts under a name or shortcut label.
- Allow triggering the saved prompt via a keyboard shortcut.
- (Optional) Provide a modal preview before applying the changes, or allow silent replacement for faster workflows.


### Why should this be worked on?

**Benefits**

- Significantly improves developer productivity by removing repetitive steps.
- Makes AI-based workflows faster and more seamless.
- Encourages more usage of the AI features by making them accessible through repeatable, user-defined actions.
- Reduces the need to rewrite the same prompt multiple times—write once, reuse whenever needed.
Ambiguous terms: custom, user-defined, fast, seamless, repetitive, simple, optional
Questions:
1. What specific features should the custom prompts for AI-based request body generation include?
2. How should the keyboard shortcuts for triggering the saved prompts be set up?
Clarified requirement: Is there a need to create a feature that allows users to define custom prompts for AI-based request body generation, save them under a name or shortcut label, and trigger them via keyboard shortcuts?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Hi!

In the pre-request script there is possibility to make fetch() to another REST API. We want to have a logic to stop the main request  based on the result from the fetch.

Basically this feature request is about similar to pm.execution.skipRequest() on Postman: 
https://community.postman.com/t/the-new-skip-request-feature/54806 

Example:

![Image](https://github.com/user-attachments/assets/55539345-0cce-46dc-951f-b297920f6f27)


### Why should this be worked on?

1) Improve use cases of Pre-request script to support request
2) competitive for Hoppscotch against other tools
Ambiguous terms: possibility, logic, similar, improve, competitive
Questions:
1. What specific result from the fetch should trigger the logic to stop the main request?
2. How should the feature request be implemented in relation to the existing pre-request script?
Clarified requirement: Is there a need to implement a feature in the pre-request script that stops the main request based on a specific result obtained from a fetch to another REST API, similar to the pm.execution.skipRequest() function in Postman? This feature aims to enhance the use cases of the pre-request script to better support requests and make the tool more competitive against others like Hoppscotch.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

We should be able to add custom headers to the OAuth 2.0 Authorization Code flow (like Postman supports).

There is a tab named _Headers_ in the pop-up, but I believe these are only send in the actual collection requests.

![Image](https://github.com/user-attachments/assets/44919172-b2c4-43ee-b3d5-a8dd5ee53c2f)


### Why should this be worked on?

When working with (C)IAM services like Auth0, to successfully retrieve a correct JWT, you need to add an Audience header in the _GET /authorization_ request.

Without this, you are not able to get a (JW) token for one of the bigger CIAM services out there.

In Postman it looks like this, simple but effective:
<img width="766" alt="Image" src="https://github.com/user-attachments/assets/d689dcee-97af-4feb-a7d0-d49e7fbf7fc7" />

Thanks for looking into this.
Ambiguous terms: custom, user-friendly, correct, successful, effective
Questions:
1. What specific custom headers are needed to be added to the OAuth 2.0 Authorization Code flow?
2. Are the custom headers added in the pop-up tab expected to be included in the collection requests?
Clarified requirement: Thanks for addressing this matter.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

The package `hoppscotch-selfhost-desktop` should be updated to Tauri v2. The doc to update from Tauri v1 can be found here: https://v2.tauri.app/start/migrate/from-tauri-1/
Some work needs to be done to update the rust code, as mentioned [in this issue](https://github.com/hoppscotch/hoppscotch/issues/4235):
> TLDR is basically that, the references in hoppscotch-desktop would have to be updated to v2 of tauri (right now rc.1 is available, which is suboptimal). Also after performing the migration, more code changes in [packages/hoppscotch-selfhost-desktop/src/platform/auth.ts](https://github.com/hoppscotch/hoppscotch/blob/4fd6d6ddb4333e3d237f48d3ce01136d9f3f7f94/packages/hoppscotch-selfhost-desktop/src/platform/auth.ts) would have to be made, as `@tauri-apps/plugin-http` (from v2) is not having both `Body` and `getClientfrom` in it, unlike previously was in `@tauri-apps/api/http`. Not sure if they will be providing this in the future or Auth will need to be redesigned in the end.

After some testing, I can give some hints to start the update (I'm stuck on updating the rust code in the `src-tauri/src/`):
- Read **entirely** the documentation given above.
- A lot of imports and functions needs to be changed, both in the `src/` (typescript) and the `src-tauri/src/` (rust). For example, on the typescript side, `getWindow()` does not exist in v2. You need to import `import { getCurrentWindow } from "@tauri-apps/api/window"`.
  Another example would be in the rust side to not use `listen_global()`, but use `tauri::Listener` and replace by `listen_any()`, and not use `emit_all()` but use `tauri::Emitter` and replace by `emit()`.
- Also, I had to add the following dependencies to the `package.json` file in `packages/hoppscotch-selfhost-desktop` after the migration:
```js
  "dependencies": {
    [...]
    "@tauri-apps/api": "^2.0.2",
    "@tauri-apps/cli": "2.3.1",
    "@tauri-apps/plugin-dialog": "^2.2.0",
    "@tauri-apps/plugin-fs": "^2.2.0",
    "@tauri-apps/plugin-http": "^2.3.0",
    "@tauri-apps/plugin-os": "^2.2.0",
    "@tauri-apps/plugin-shell": "^2.0.0",
    "@tauri-apps/plugin-store": "^2.2.0",
    [...]
  },
```

I'm now stuck to update the rust code, for which I don't have enough knowledge to do so. Help needed!

### Why should this be worked on?

This should be **high priority** as it could resolve a lot of different errors faced by users, and more importantly be more up-to-date as other projects created in Hoppscotch (i.e.: hoppscotch agent).
Ambiguous terms: high priority, more up-to-date
Questions:
1. What specific errors are users facing that this update could resolve?
2. Can you clarify what "more up-to-date" means in this context?
Clarified requirement: Another example would be in the rust side to not use `listen_global()`, but use `tauri::Listener` and replace by `listen_any()`, and not use `emit_all()` but use `tauri::


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Is it possible to import a GraphQL schema from a local file into Hoppscotch and convert it into a GraphQL collection?

Currently, users need to manually create requests based on their schema. An import feature would streamline this process by automatically generating queries and mutations from a given GraphQL schema file. This would improve efficiency and ease of use for developers working with GraphQL APIs.

Expected Behavior:

- Upload a `.graphql` schema file.

- Hoppscotch parses the schema and extracts queries, mutations, and types.

- Automatically creates a GraphQL collection with predefined requests.

- Allows users to edit and customize imported requests.

### Why should this be worked on?

Retrieving the GraphQL schema dynamically is difficult due to company network settings and firewall restrictions. Allowing users to import a local schema file would provide a more convenient and efficient way to set up and test GraphQL APIs in Hoppscotch without needing external access.
Ambiguous terms: possible, streamline, automatically, improve, efficiency, ease of use, predefined, convenient, efficient
Questions:
1. What specific actions should be taken when importing a GraphQL schema from a local file into Hoppscotch?
2. How should the imported requests be presented to users for editing and customization?
Clarified requirement: Is it possible to create a feature in Hoppscotch that allows users to upload a `.graphql` schema file, which will then be parsed to extract queries, mutations, and types? The feature should automatically generate a GraphQL collection with the extracted requests for users to edit and customize. This would provide a more convenient and efficient way for developers to work with GraphQL APIs in Hoppscotch.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I see `.deb` and `AppImage` but no `.rpm` yet.
any plans to add support for it??

### Why should this be worked on?

Ubuntu _(.deb)_ is not the only distro/package format.
AppImage binaries are too large and has some setup to do too _(app image manager makes it easy)_
Ambiguous terms: plans, support, some, too, easy
Questions:
1. What specifically is meant by "support" in this context?
2. Can you clarify what is meant by "any plans to add support for it?"
Clarified requirement: Ubuntu _(using .deb)_ is not the only distro/package format available. AppImage binaries are too large and require some setup, although AppImage manager makes it easier.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I'm using Tests to generate variable values to use in a subsequent request. Currently I'm saving using `pw.env.set`. However, this saves them in the Workspace Environment, which makes them shared accross users, and this could create issues if those requests are run in parallel by different users.

### Why should this be worked on?

The use-case is generating a signed URL for S3 and then uploading a file. I'm sure there are other cases like this one. I've seen other solutions, where you can directly reference the value from a response in the request parameters, but given that might be more difficult to implement, an option to choose which environment to set when calling pw.env.set might be a good middle ground.
Ambiguous terms: shared, issues, difficult, good
Questions:
1. What specifically is meant by "shared" in this context?
2. Can you clarify what is meant by "difficult" in the context of implementing other solutions?
Clarified requirement: Is there an existing issue related to saving variable values using `pw.env.set` in the Workspace Environment, causing potential conflicts when requests are run in parallel by different users? The goal is to provide an option to choose the environment for setting variables to avoid shared conflicts, particularly for use cases like generating signed URLs for S3 and uploading files.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Header management in the OAuth 2 authorization settings.

### Why should this be worked on?

In some instances, it is necessary to specify a particular Content-Type. In my case, this would be "application/x-www-form-urlencoded". However, at present, this is not possible. As a result, the values contained in the Body are not being passed to the authorization handler.
Ambiguous terms: necessary, particular, possible, values, contained
Questions:
1. What specific authorization settings are being referred to in the requirement?
2. Can you clarify what "values contained in the Body" refers to?
Clarified requirement: Is there an existing issue for the header management in the OAuth 2 authorization settings? The issue arises from the inability to specify "application/x-www-form-urlencoded" as the Content-Type, leading to the values in the Body not being passed to the authorization handler.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

the socket.io feature is great but just bearer auth is not enough, we have to send our api keys via x-api-key header so a feature like in the normal rest queries to set custom headers would be great

### Why should this be worked on?

because it is a very often used feature
Ambiguous terms: great, enough, feature, normal, great, often
Questions:
1. What specifically is meant by "bearer auth is not enough"?
2. Can you clarify what you mean by "a feature like in the normal rest queries"?
Clarified requirement: Is there an existing issue for implementing a feature in socket.io that allows setting custom headers, specifically for sending API keys via the x-api-key header, in addition to bearer authentication? This feature is needed because it is frequently used.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Don't know if its possible for you or not, but at least inside the desktop app it would be great, If I could close the currently active tab with `CTRL/CMD + W` just like you can do inside a browser to close the current tab.

Of course this won't work inside the browser version, since you probably can't overwrite/overrule a browser native shortcude.

### Why should this be worked on?

It would behave the same as a browser 😁
Ambiguous terms: great, possible, great, won't work, same
Questions:
1. What is the specific action the user wants to perform with `CTRL/CMD + W` in the desktop app?
2. Can the user clarify what they mean by "behave the same as a browser"?
Clarified requirement: To mimic the behavior of closing tabs in a browser.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

The desktop app should remember what server instance was active last time the app was open.

### Why should this be worked on?

In the latest hoppscotch release it is possible to connect the desktop app to a self hosted instance 🥳 

What I noticed is the fact, that after closing and re-opening the app it doesn't remember, that I had my self-hosted instance active. It defaults to the SaaS version, which I have not connected (no offence, it surely works great, but I prefer my data to be self-hosted if possible 😁)

It would be nice if the app could remember, what my latest active server instance was instead of me having to re-open my self-hosted instance again after closing and re-opening the app.

Another option would be to mark a specific instance as "favorite" - and that one will get opened by default when starting the app.
Ambiguous terms: nice, active, latest, self-hosted, prefer, great, possible, would be nice, specific
Questions:
1. What does "active server instance" refer to in this context?
2. Can you clarify what is meant by "mark a specific instance as 'favorite'?"
Clarified requirement: Ensure that the desktop app remembers the last self-hosted server instance that was used, so that it can be automatically opened when the app is launched again. Additionally, provide the functionality to designate a specific server instance as a "favorite" for default opening upon app launch.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Can hoppscotch support search by request url?

<img width="360" alt="Image" src="https://github.com/user-attachments/assets/2904405e-e5bb-4c1a-984b-6c9d594d6b30" />

If I got a request on collection:

- name: my-request
- url: https://a.com/b/c

Can we search this request by just using a part of url: `b/c`?

### Why should this be worked on?

just want to find the target request quickly.
Ambiguous terms: fast, user-friendly
Questions:
1. What is the specific action that the user wants to perform when searching for a request by using a part of the URL?
2. Is the user looking to search for requests within a specific collection or across all collections?
Clarified requirement: The user wants to be able to search for a request within a collection by using a part of the URL, such as 'b/c', to quickly find the target request.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I would love for there to be a way to organize environments

the two options that would be great would be 

- being able to re-order environments
- the ability to add folders for environments



### Why should this be worked on?

we have 3 environments for every service so things can get really messy fast.
Ambiguous terms: love, great, messy
Questions:
1. What is meant by "environments" in this context?
2. Can you clarify what is meant by "re-order environments" and "add folders for environments"?
Clarified requirement: Is there an existing issue for creating a system to organize environments? I have searched the existing issues. I would like to have the ability to rearrange the order of environments and add folders to categorize environments. This is necessary because having 3 environments for every service can lead to disorganization quickly.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I would like to propose a feature that allows users to define and store reusable JavaScript functions within Hoppscotch. This feature would enable users to create a library of common functions that can be easily accessed and utilized across multiple pre-request scripts. By providing a centralized location for function storage, users can streamline their workflow, reduce redundancy, and enhance collaboration within teams.

### Why should this be worked on?

Implementing reusable JavaScript functions would significantly enhance the efficiency and productivity of Hoppscotch users. Currently, users must manually copy and paste code snippets across different requests, which can lead to errors and inconsistencies. In contrast, Postman offers features that allow for the reuse of scripts and functions across requests, making it a more attractive option for developers who need to maintain complex workflows. By incorporating similar capabilities, Hoppscotch can provide a more organized and maintainable scripting environment, saving time and promoting best practices in code reuse and collaboration. This would make Hoppscotch a more competitive and powerful tool for developers and teams working with APIs.
Ambiguous terms: streamline, reduce redundancy, enhance collaboration, efficiency, productivity, more attractive, organized, maintainable, best practices, competitive, powerful
Questions:
1. What specific actions or functionalities are expected from the feature that allows users to define and store reusable JavaScript functions within Hoppscotch?
2. How should the proposed feature integrate with the existing Hoppscotch interface and workflow?
Clarified requirement: Is there a need to develop a feature in Hoppscotch that enables users to define and store reusable JavaScript functions? This feature should allow users to create a library of common functions for easy access and utilization across multiple pre-request scripts, enhancing efficiency and collaboration within teams.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I would like to have the ability to pin the most frequently used environments. My workspace has a large list of environments, and currently, there's no way to search within the modal that opens the list.

### Why should this be worked on?

I'm not sure if this is a problem that many others face, but I believe it could help those who have the same issue.
I understand that implementing a search feature in this modal might be more complicated, but I think allowing users to pin environments could already provide a significant improvement when dealing with a large number of environments to choose from.
Ambiguous terms: frequently, user-friendly, large, search, significant
Questions:
1. What specific actions would "pinning" an environment involve?
2. Can you clarify what you mean by "search within the modal"?
Clarified requirement: Implement the ability for users to mark certain environments as favorites for easy access and add a search feature within the modal that opens the list of environments.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

It seems tests have a more general use than just testing. I almost ditched Hoppscotch as a Postman alternative because "post-request scripts" were missing. Some comparison sites (eg https://stackshare.io/stackups/hoppscotch-vs-postman) seem to think the same.

### Why should this be worked on?

Advertise features that are already implemented, so people see it as a worthy alternative.
Ambiguous terms: seems, almost, more general, just, missing, some, think
Questions:
1. What specific features are being referred to as "post-request scripts"?
2. Can you clarify what is meant by "Advertise features that are already implemented"?
Clarified requirement: Is there an existing issue for the missing "post-request scripts" feature in Hoppscotch compared to Postman? Advertise the already implemented features to highlight Hoppscotch as a worthy alternative.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

**Description:**
When entering environment keys, leading and trailing whitespaces can accidentally be included, causing unexpected behavior. Users may not immediately notice these spaces, leading to configuration errors which may be difficult to debug.

**Why is this important?**

- Improves usability by preventing unintended errors.
- Enhances user experience by ensuring environment keys are stored as expected.
- Reduces debugging time caused by invisible whitespace issues.

**Steps to Reproduce:**

1. Add an environment key with a space at the beginning or end (e.g., `"API_KEY "` instead of `"API_KEY"`).
2. Save the configuration.
3. Try to retrieve the key fails because the variable key is not recognized. 

**Expected Behavior:**

- Leading and trailing whitespaces should be automatically trimmed when saving personal, team or global environment keys.
- Users should not have to manually check for and remove spaces.
- The application should provide a smooth and error-free experience.


### Why should this be worked on?

This change aligns with best practices for form input handling and prevents common usability pitfalls.
Ambiguous terms: leading, trailing, unexpected, immediately, difficult, invisible, smooth, error-free
Questions:
1. What specific action is required to address the issue of leading and trailing whitespaces in environment keys?
2. How should the application handle environment keys with leading or trailing whitespaces?
Clarified requirement: Ensure that when saving personal, team, or global environment keys in the application, any leading and trailing whitespaces are automatically removed to prevent configuration errors and improve user experience.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

**Description:**
Currently, the environment variables dialog in Hoppscotch is limited to a maximum width of 32rem. This constraint makes it difficult to view longer variable names and values efficiently. A more adaptive or configurable width would improve the usability, especially for users working with extensive environment variables.

![Image](https://github.com/user-attachments/assets/7fb61784-543d-46a5-a29f-c853536307f2)

**Suggested Improvement:**

Allow the environment variables dialog to scale dynamically based on the screen size, rather than being fixed at 32rem.
Implement a more flexible max-width, e.g., a percentage-based limit (max-width: 65%) for larger screens.
Optionally, provide a resizable or user-configurable width for better customization.

![Image](https://github.com/user-attachments/assets/4b7d5702-58c4-4e74-9423-85e0f66c4733)

**Current Workaround (User Script):**
We have temporarily addressed this issue using a user script that overrides the CSS:
```
(function() {
    'use strict';

    // Function to inject CSS into the page
    function addCustomCSS(css) {
        const style = document.createElement('style');
        style.type = 'text/css';
        style.textContent = css;
        document.head.appendChild(style);
    }

    // Adjust max-width for larger screens
    const customCSS = `
        @media (min-width: 640px) {
            .sm\\:max-w-lg {
                max-width: 65%;
            }
        }
    `;

    // Inject the custom CSS
    addCustomCSS(customCSS);
})();
```
While this workaround helps, a native solution within Hoppscotch would be much more elegant and reliable.

**Development Contribution:**
I’d be happy to contribute a pull request for this improvement. If you could point me to the relevant part of the codebase where the modal width is defined, I can make the necessary adjustments and submit a PR.


### Why should this be worked on?

Inefficient use of screen space → On larger screens, a small fixed-width dialog feels cramped and does not take advantage of the available display area.
Ambiguous terms: adaptive, configurable, flexible, larger screens, resizable, user-configurable, better customization, larger screens, better customization, native solution
Questions:
1. What specific issues have users encountered due to the current fixed width of 32rem for the environment variables dialog?
2. Can you clarify what you mean by a "native solution" within Hoppscotch?
Clarified requirement: The current fixed width leads to inefficient use of screen space, particularly on larger screens, where the small dialog feels cramped and fails to utilize the available display area.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

**Description:**
It would be highly beneficial if Hoppscotch supported nested variables, similar to how Postman handles them. This feature allows variables to reference other variables, making environment management more dynamic and flexible.

**Expected Behavior:**
Variables should be able to reference other variables using {{variable_name}}.
When evaluating a request, Hoppscotch should resolve nested variables recursively.
Nested variables should work in all applicable fields, including environment variables, request parameters, headers, and body content.

**Use Case Example:**

A user defines an environment variable: 
`base_url = https://api.example.com`

Another variable references it: 
`users_endpoint = {{base_url}}/users`

When making a request to <<users_endpoint>>, Hoppscotch should resolve it to: 
`https://api.example.com/users`

OR

For example, a team could define a global variable:
`api_version: v1`

Then, in an environment-specific setting, this could be reused dynamically:
`api_base_url: https://api.example.com/<<api_version>>`

**Potential Implementation:**
- Enable recursive resolution of variables in requests.
- Implement safeguards to prevent infinite loops (e.g., `var_a = <<var_b>>` and `var_b = <<var_a>>`).

Would this feature be possible to add? It would greatly improve variable handling and make Hoppscotch even more powerful for API testing.

### Why should this be worked on?

**Why is this useful?**

- Reduces duplication: Users don’t need to manually update values in multiple places.
- With nested variables, global environment variables could be leveraged efficiently in different environments.
- Enables dynamic configuration: Users can define base values and build other variables based on them.
- Improves team efficiency: Teams can work with structured and reusable environment variables.
Ambiguous terms: beneficial, similar, dynamic, flexible, applicable, efficiently, structured, reusable
Questions:
1. What specific software or platform is being referred to when mentioning "Hoppscotch"?
2. Can you provide an example of how nested variables are currently handled in Hoppscotch?
Clarified requirement: The requirement is to add support for nested variables in Hoppscotch, similar to how Postman handles them. This feature would allow variables to reference other variables, making environment management more dynamic and flexible. Variables should be able to reference other variables using {{variable_name}}, and when evaluating a request, Hoppscotch should resolve nested variables recursively in all applicable fields.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

**Description:**
For teams working collaboratively, it would be highly beneficial to have global environment variables that are synchronized across all team members. Each individual should still have the ability to override these variables via the Secrets tab.

**Expected Behavior:**
- Global environment variables should be synced across all team members.
- Individual users should be able to override these global variables in their personal Secrets tab.
- If a user does not override a variable, the global value should be used.

Would this feature be feasible to implement?

### Why should this be worked on?

**Why is this useful?**
Teams often work with shared API endpoints, authentication tokens, or configurations that should be consistent for everyone globally and not specifically bound to an environment.
Ambiguous terms: highly beneficial, should, synced, able, should be used, feasible, useful, consistent, specifically
Questions:
1. What is meant by "global environment variables" in this context?
2. Can you clarify what is meant by "personal Secrets tab"?
Clarified requirement: Is there an existing issue for implementing global environment variables that are synchronized across all team members, with the ability for individual users to override these variables in their personal Secrets tab?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

**Description:**
Currently, Hoppscotch already provides a bulk editing feature for request parameters, which is very useful for quickly managing large sets of data. However, the same functionality is not available for environment variables.

![Image](https://github.com/user-attachments/assets/e2b09cad-c41d-4341-a7fa-9f6d33d63c32)

**Feature Request**
I propose adding a bulk editing option for environment **variables and secrets**, similar to the one available for request parameters. This would make it easier to:

- Quickly import/export multiple environment variables
- Modify, reorder large sets of variables at once

**Proposed Solution**
Introduce a bulk edit mode for environment **variables and secrets**, as already implemented within request parameters. 

![Image](https://github.com/user-attachments/assets/354283a6-dfda-49a0-a22c-d05b1f125dbd)

### Why should this be worked on?

This feature would be particularly useful for teams working on APIs with many environment configurations. Since the bulk editing feature already exists for parameters, implementing a similar approach for environments could align with the existing UX pattern.
Ambiguous terms: quickly, large, easier, bulk editing, multiple, large sets of variables, similar, quickly, many
Questions:
1. What specific actions are included in the bulk editing feature for request parameters?
2. How would the proposed bulk editing option for environment variables and secrets differ from the existing feature for request parameters?
Clarified requirement: Is there a need to implement a bulk editing option for environment variables and secrets, similar to the existing feature for request parameters, to facilitate managing multiple environment configurations efficiently for teams working on APIs?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

I know it has been asked before but years have passed and I was wondering if there's an ETA about implementing this.
I love how there even is websocket support for an Open Source client, but this feature is still missing.

Previous:
https://github.com/hoppscotch/hoppscotch/issues/2323
https://github.com/hoppscotch/hoppscotch/issues/801

### Why should this be worked on?

Data from messages serialized in binary formats can be retrieved much faster from clients and some protocols allow you not to de-serialize them to get access to individual pieces of information, it's a way faster approach than JSON `parse` and `stringify` on both sides of an app.
Ambiguous terms: fast, user-friendly, faster, love, missing
Questions:
1. What specific feature or improvement is being referred to in this requirement?
2. What is meant by "ETA" in this context?
Clarified requirement: Is there an existing issue in the project's repository related to the implementation of a specific feature or improvement? The requester has checked the existing issues but is inquiring about a potential timeline for implementation. The feature is related to websocket support for an Open Source client, which is currently missing.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Color Highlight on Generate Code Tab

### Why should this be worked on?

Better UX for using the Generate Code
Ambiguous terms: Better, UX
Questions:
1. What is meant by "Generate Code Tab"?
2. Can you specify what improvements are expected in terms of "Better UX"?
Clarified requirement: To improve the user experience when using the Generate Code feature.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

In Postman;

pm.globals.set("accessToken", accessToken);
pm.globals.set("refreshToken", refreshToken);

### Why should this be worked on?

In the postman application, data from the response can be saved in the global environment table, can you add it?
Ambiguous terms: saved, global environment table, add
Questions:
1. What does "saved in the global environment table" mean?
2. What specifically needs to be added in the postman application?
Clarified requirement: Determine if there is an existing issue, set access token and refresh token in Postman, and add the functionality to save data from the response in the global environment in the postman application.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Hi,

it should be very useful to have this feature in the Hopscotch UI, both desktop and web versions:

when you select several apis from the collection tree and these opens in tabs, if the user switch between opened tabs, the collection tree point to the api opened (in the tree is highlighted the api corresponding to the opened tab).

Do you think it's possible to have this? Thanks in advance

Saverio

### Why should this be worked on?

To have a meaningful UI of the app
Ambiguous terms: useful, meaningful
Questions:
1. What is the specific feature being requested for the Hopscotch UI?
2. Can you clarify how the collection tree currently functions in relation to the opened tabs?
Clarified requirement: Is there a feature that allows the collection tree in the Hopscotch UI to highlight the corresponding API when switching between opened tabs that contain selected APIs?


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

Hoppscotch currently relies on external authentication mechanisms that require internet access. To support fully offline deployments in internal networks, Hoppscotch should be enhanced to allow username/password-based authentication. This would enable users to operate Hoppscotch in environments without external connectivity, such as secure internal networks systems.

### Why should this be worked on?


1. **Offline Deployment**: Many organizations operate in secure or isolated environments where internet access is restricted. Supporting username/password login ensures Hoppscotch can be used in such scenarios without compromising security.
2. **Flexibility**: Adding this feature broadens Hoppscotch's usability, making it suitable for a wider range of deployment scenarios, including government, healthcare, and financial sectors with strict compliance requirements.
3. **User Convenience**: For teams managing internal systems, a simple username/password login is often more practical and easier to manage compared to complex authentication mechanisms.
4. **Competitive Advantage**: Many similar tools already support offline authentication. Adding this feature would make Hoppscotch more competitive and appealing to potential users in restricted environments.

This enhancement would significantly improve Hoppscotch's versatility and adoption in enterprise settings.
Ambiguous terms: secure, restricted, simple, complex, practical, competitive, significant
Questions:
1. What specific external authentication mechanisms does Hoppscotch currently rely on?
2. How does the lack of username/password-based authentication currently impact Hoppscotch's usability?
Clarified requirement: Is there an existing issue for Hoppscotch's reliance on external authentication mechanisms that require internet access to be enhanced by adding username/password-based authentication for fully offline deployments in internal networks?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Add persistence to message under realtime tab. Just like the REST tab.

Or even, add collections , environment for realtime will be useful!

### Why should this be worked on?

Hoppscotch have persistence on WS address (according to #1196 ) but the message doesn't. It will be better to have this feature.

For example, you need to connect a websocket server, and use a fix format to auth and chat:

```json
{
  "channel": "my-room"
  "data": {
    "auth": "some auth code",
    "content": "some words"
   }
}
```

If I switch tab (not only REST..., but also Socket.IO, MQTT tabs) those message will be missing! I need to key in them one by one again. The only way to avoid this is two browser tab, one for WebSocket (or and tab under realtime) one for REST or others.

![photo_2025-01-14_19-20-59](https://github.com/user-attachments/assets/db9100a2-f100-4aa2-a87c-be64ec6ba125)

Therefore, I think maybe Hoppscotch can add a persistence to message under realtime (the last input will be fine), or even the collections feature. That will be wonderful.
Ambiguous terms: persistence, realtime, feature, useful, better, fine, wonderful
Questions:
1. What specific functionality is meant by "persistence" in this context?
2. Can you clarify what is meant by "realtime tab" and how it differs from the REST tab?
Clarified requirement: Is there an existing issue for adding persistence to messages under the realtime tab, similar to the functionality in the REST tab? Additionally, consider incorporating collections and environment options for the realtime tab.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Grouping request tabs to different groups like in chrome. 

### Why should this be worked on?

Better UI and handling
Ambiguous terms: Better, UI, handling
Questions:
1. What specific criteria define a "better UI"?
2. Can you provide examples or specifics on what is meant by "handling"?
Clarified requirement: To improve the user interface and the way requests are managed.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Timed heartbeats are a standard feature in WebSocket-based communication to ensure connections remain active and to detect connection failures. Adding support for sending timed heartbeats in the Socket.IO realtime API testing tool would allow developers to simulate real-world scenarios, debug their server implementations, and optimize the reliability of their applications. This feature would include options to enable/disable heartbeats, configure intervals, and define the heartbeat payload.

### Why should this be worked on?

Timed heartbeats are essential for testing how servers handle regular keep-alive signals and maintain stable connections. This feature would help developers simulate real-world scenarios, debug server configurations, and ensure reliability. Since heartbeats are commonly used in WebSocket applications, adding this feature would make Hoppscotch more practical and valuable for realtime API testing.
Ambiguous terms: standard, real-world, essential, regular, stable, commonly, practical, valuable
Questions:
1. What specific functionality is being requested for the Socket.IO realtime API testing tool?
2. How would the timed heartbeats be utilized in the context of the tool?
Clarified requirement: Is there a request to add support for sending timed heartbeats in the Socket.IO realtime API testing tool to simulate real-world scenarios, debug server implementations, and optimize application reliability? This feature would include options to enable/disable heartbeats, configure intervals, and define the heartbeat payload.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Thanks for adding support for AWS Signature for REST requests in [v2024.8.0](https://github.com/hoppscotch/hoppscotch/releases/tag/2024.8.0). Works great! (And I think #3169 can be closed).

This feature request is to add the exact same support for WebSocket APIs. Same configuration UI and everything. In the case of WebSockets it is used to sign the HTTP request that the client sends to initiate the connection handshake prescribed by the WebSocket protocol.

### Why should this be worked on?

WebSocket APIs built with AWS [use AWS Signature for authenication](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-control-access-iam.html). It works exactly as in a REST API request. In this case it is used to sign the HTTP request that initiates the connection handshake. AWS is likely to account for a large proportion of production WebSocket APIs. Without this support, Hoppscotch cannot be used to connect to such APIs.
Ambiguous terms: support, exact, great, large, cannot
Questions:
1. What specific support is being referred to in this requirement?
2. Can you clarify what "cannot be used" means in this context?
Clarified requirement: Determine the feasibility of adding AWS Signature support for WebSocket APIs in Hoppscotch to enable connection to WebSocket APIs built with AWS, similar to the support provided for REST requests in version 2024.8.0.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

In future versions, can support for HTTP/2 requests be added?

### Why should this be worked on?

Because HTTP/2 is currently used very frequently.
Ambiguous terms: future, support, frequently
Questions:
1. What specifically is meant by "support for HTTP/2 requests"?
2. How soon is the implementation of HTTP/2 support expected in future versions?
Clarified requirement: Determine if there is an existing issue for adding support for HTTP/2 requests in future versions, as HTTP/2 is currently used very frequently.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I need a plugin in IntelliJ that can convert written code into interface definitions and pass them here

### Why should this be worked on?

It can save a lot of time without having to redefine the document, and interface changes can also be directly modified by modifying the code
like apifox helper or apipost helper
Ambiguous terms: a lot, save, a lot of time, directly, modify
Questions:
1. What specific type of code should the plugin be able to convert into interface definitions?
2. Can you provide examples of how the interface changes can be directly modified by modifying the code?
Clarified requirement: It can save time by eliminating the need to redefine documents.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Clicking request opens 'temporary' tab which gets replaced by clicking another request. Double clicking request opens permanent tab which stays open.

### Why should this be worked on?

This request builds upon issue #3520, addressing the lack of a tab-specific shortcut. Currently, clicking on a request opens it in a new tab, which can quickly lead to many open tabs when inspecting multiple requests. If the intention is merely to view requests without modifying them, manually closing each tab by clicking the close button can become cumbersome.

I propose adding (customizable) behavior similar to popular IDEs:

- Single-click on a request opens it in a temporary tab, which is replaced if another request is clicked.
- Double-click on a request opens it in a permanent tab that remains open.

This functionality would streamline workflows for users who frequently inspect requests without needing to keep multiple tabs open.
Ambiguous terms: temporary, permanent, customizable, streamline
Questions:
1. What is meant by a "temporary" tab?
2. Can you clarify what is meant by a "permanent" tab?
Clarified requirement: Determine the functionality of tabs when clicking on a request - a single click opens a temporary tab that gets replaced by another request, while a double click opens a permanent tab that remains open.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

The idea is essentially to allow users to toggle a button or something that allows users to make as many changes as they want to collections and requests in workspaces and not have those changes saved into DB.

The goal is essentially when working with a team, I often make changes to certain values of request variables or request body and do not want those changes made on my end to get saved and reflect on everyone else's workspace too.

### Why should this be worked on?

Improve workspace usability amongst teams.
Ambiguous terms: essentially, many, changes, want, certain, values, reflect
Questions:
1. What specific types of changes are users looking to make to collections and requests?
2. Can you clarify what you mean by "not have those changes saved into DB"?
Clarified requirement: Is there an existing issue for allowing users to toggle a button that prevents changes made to request variables or request body from being saved into the database, in order to improve workspace usability amongst teams?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Support importing a JSON file with collections exported from Yaak.

### Why should this be worked on?

Make it easier for users to switch from other tools to Hoppscotch.
Ambiguous terms: easier
Questions:
1. What specifically needs to be made easier for users?
2. Are there any specific challenges users face when switching from other tools to Hoppscotch?
Clarified requirement: Make the process of switching from other tools to Hoppscotch more seamless for users.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Currently, to change the name of a collection, request etc there are too many steps involved in doing so, the proposal is to implement some sort of "double click to edit input" type UI.

### Why should this be worked on?

Reduces the number of steps required to rename elements in Hoppscotch.
Ambiguous terms: too many, some sort of
Questions:
1. What specific steps are currently involved in changing the name of a collection or request?
2. Can you provide more details on what the "double click to edit input" type UI would entail?
Clarified requirement: Is there an existing issue for changing the name of a collection or request? I have searched the existing issues. Currently, there are multiple steps involved in renaming elements in Hoppscotch. The proposal is to implement a UI feature where users can double click to edit input, reducing the number of steps required for renaming.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

This feature request has been created to follow and summarize the progress of the missing features in the pre-request script.

Here's an incomplete list :
- [ ] Access request URL :
        - Get url : `pw.url.get()`
        - Set url : `pw.url.set("https://anyUrlHere.com/api/<<someVariable>>")`
- [ ] Access request method :
        - Get method : `pw.method.get()`
        - Set method : `pw.method.set("POST")` => Only available values are [GET, POST, PUT, DELETE, PATCH...]
- [ ] Access environment variables :
        ~~- Get env variables :~~ `pw.env.get("key")` **DONE**
        - Set env variables : `pw.env.set("key", (optional)secret=[true, false])` **PARTIALLY DONE**
        - Get all env variables : `pw.env.get()` => returns a map of ["key", "value"] for each of the env variables
        ~~- Unset env variable :~~ `pw.env.unset("key")` **DONE**
- [ ] Access request body :
        - Get body's element : `pw.body.get("element")` (parses either json or xml to find the value of the element)
        - Set body's element : we should use variables in order to do that.
        - Get the complete body : `pw.body.get()`
- [ ] Access request variable :
        - Get variable : `pw.var.get("key")`
        - Set variable : `pw.var.set("key")`
        - Get all variables `pw.vars.get()` => returns a map of ["key", "value"] for each of the request's variables
        - Unset variable : `pw.var.unset("key")`
- [ ] Access request parameter :
        - Get parameter : `pw.param.get("key")`
        - Set parameter : `pw.param.set("key")`
        - Get all params `pw.params.get()` => returns a map of ["key", "value"] for each of the request's parameters
        - Unset parameter : `pw.param.unset("key")`
- [ ] Access request header :
        - Get header : `pw.header.get("key")`
        - Set header : `pw.header.set("key")`
        - Get all headers `pw.headers.get()` => returns a map of ["key", "value"] for each of the request's headers
        - Unset header : `pw.header.unset("key")`
- [ ] Access request auth values :
        - Get auth type *[Inherit, None, Basic, Bearer, OAuth2, API Key]* : `pw.auth.type.get()`
        - Get auth username (Basic, OAuth2) : `pw.auth.username.get()`
        - Get auth password (Basic, OAuth2) : `pw.auth.password.get()`
        - Get auth token (Bearer, OAuth2, ) : `pw.auth.token.get()`
        - Get auth grant type (OAuth2, ) : `pw.auth.grant_type.get()`
        - Get auth code challenge (OAuth2 -> If PKCE is checked) : `pw.auth.code_challenge.get()`
        - Get auth authorization endpoint (OAuth2, ) : `pw.auth.auth_endpoint.get()`
        - Get auth token endpoint (OAuth2, ) : `pw.auth.token_endpoint.get()`
        - Get auth client ID (OAuth2, ) : `pw.auth.client_id.get()`
        - Get auth client secret (OAuth2, ) : `pw.auth.client_secret.get()`
        - Get auth scopes (OAuth2, ) : `pw.auth.scopes.get()`
        - Get auth key (API Key) : `pw.auth.api_key.get()`
        - Get auth value (API Key) : `pw.auth.api_value.get()`
        - Get auth access key (AWS) : `pw.auth.access_key.get()`
        - Get auth secret key (AWS) : `pw.auth.secret_key.get()`

> **WARNING:** Advanced configuration for AWS and Digest Auth not listed here to be implemented, though if needed I can add and implement them too!

Let me know if I should add, modify or delete something from the list! 😄 

### Why should this be worked on?

This should really be worked on because this is a highly requested feature (see #3904 , #4582 , #3726 , #4528 ).

An example use case would be to get the value of a header, set a request variable encoded in base64 from the header value, to be used in the body as <<encodedVar>>, only if the auth token equals "hoppscotch1234" (it does not make sense I know, it's just for demonstration purposes):

```javascript
******************* PRE REQUEST SCRIPT *******************

// To get the value of the request header named "Content-type"
const header = pw.header.get("Content-type");

if ( pw.auth.token.get() == "hoppscotch1234" ){
    // Set a request variable with the "header" value, encoded in base64
    pw.var.set("encodedVar", btoa(header) );
}
//
```

Feel free to share your feedback on this! 😄
Ambiguous terms: highly requested, advanced, if needed, modify, delete, should really be worked on, example use case, it does not make sense, just for demonstration purposes, feel free to share your feedback
Questions:
1. What specifically constitutes a "highly requested feature"?
2. Can you clarify what you mean by "advanced configuration"?
Clarified requirement: This feature is important due to its popularity among users (referenced by issues #3904, #4582, #3726, #4528). An example use case is provided to demonstrate how this feature could be utilized. Feedback on this request is welcome.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hello everyone, I want to retrieve all the parameters of the form request when making a request in Hoppscotch, in order to implement my own signing logic to generate a sign for the backend. However, after checking the documentation, it seems that the pw object does not have an object like pw.request. Could you please tell me how I can get the collection of request parameters? Thanks!

### Why should this be worked on?

in order to implement my own signing logic (signing for every request params)    to generate a sign for the backend
Ambiguous terms: retrieve, parameters, signing logic, generate, backend
Questions:
1. What specific parameters are being referred to in this context?
2. Can you clarify what you mean by "signing logic"?
Clarified requirement: Is there an existing issue for retrieving all the parameters of the form request when making a request in Hoppscotch, in order to implement custom signing logic for generating a sign for the backend?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I am currently self hosting hoppscotch at my company, and we need this email domain whitelisting feature so as to allow only people who are associated my our org. I saw this feature available here https://hoppscotch.com/blog/hoppscotch-v2024-3-0 but i believe it is not there in community edition of hoppscotch. I would like to contribute this feature.

### Why should this be worked on?

This feature should be worked on because it improves security for self-hosted instances by allowing access only to users with approved email domains. It’s a simple way to ensure the platform stays limited to authorized users, which is important for companies using Hoppscotch internally.
Ambiguous terms: whitelisting, associated, approved, authorized, important
Questions:
1. What does "whitelisting" mean in this context?
2. Can you clarify what you mean by "associated my our org"?
Clarified requirement: Is there an existing issue for implementing an email domain whitelisting feature in the community edition of Hoppscotch? I am self-hosting Hoppscotch at my company and would like to contribute this feature to allow access only to users with approved email domains associated with our organization. This feature is important for improving security by limiting access to authorized users.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hi there Hopscotch team!

In a past bug report (#3955), it was noted that single-line input components like the URL bar are designed without wrapping on purpose. Example:
<img width="744" alt="truncated URL on click" src="https://github.com/user-attachments/assets/a1ca8371-7cfb-4fdd-8d6f-f8eef1516f52">

**Suggested Change:**
Enable the URL input box to dynamically expand when focused or clicked.

### Why should this be worked on?

Expanding on click/focus, so users can see truncated content, is a common and intuitive behavior that aligns with user expectations. I believe this would improve the user experience while still keeping the UI clean and consistent with your design standards.

I’m new to the codebase, but I’d love to explore this issue further. From my initial look, it seems that the behavior might be controlled by the `EnvInput.vue` component or its parent container. I’d start by inspecting styles like `whitespace-nowrap` or `overflow-x-auto` and checking how the `SmartEnvInput` component is rendered in `Request.vue`
Ambiguous terms: common, intuitive, improve, clean, consistent, explore, might, start, initial, seems, checking
Questions:
1. What specific action is being requested regarding the URL input box?
2. Are there any specific design standards or guidelines that should be followed for this suggested change?
Clarified requirement: Is there an existing issue for enabling the URL input box to dynamically expand when focused or clicked? In a past bug report (#3955), it was noted that single-line input components like the URL bar are designed without wrapping on purpose. The suggested change is to allow the URL input box to expand dynamically when focused or clicked. This behavior aligns with user expectations and aims to improve the user experience while maintaining consistency with design standards.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

This field should allow users to specify domains that should bypass the proxy server when making requests.

### Why should this be worked on?

This feature mirrors existing functionality in Postman and is crucial for accessing resources that are incompatible with or blocked by the proxy.
Ambiguous terms: should, allow, specify, crucial
Questions:
1. What specific action should users be able to take with the "domains" in question?
2. Can you provide examples of resources that are incompatible with or blocked by the proxy?
Clarified requirement: Is there an existing issue for allowing users to define domains that will bypass the proxy server when making requests? This feature is important because it mirrors functionality in Postman and is necessary for accessing resources that cannot work with or are restricted by the proxy.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

this picture used hoppscotch, command execute error
![image](https://github.com/user-attachments/assets/26681a71-9de8-46c6-bb8e-ac346c803d60)

this picture used reqable.  command execute success
![image](https://github.com/user-attachments/assets/c867909a-e70f-4676-ba2b-a0465e69fa0b)



### Why should this be worked on?

generate code  execute error
Ambiguous terms: fast, user-friendly
Questions:
1. What is the specific action or decision that needs to be taken based on the existing issue search?
2. Can you clarify what is meant by "generate code execute error"?
Clarified requirement: There is an issue with code execution that needs to be addressed.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

It sounds like a useful feature to have an ability to set/unset secret variables from scripts. For example we can have two shared environments (Development and Production), each of them contains shared variables like hosts and other 'non-secret' data, and we have a some sort of a `login` API request that will return us a particular token, that we would like to set as a variable to use with other requests later. Now we have an option to call `pw.env.unset` as a Pre-request Script and then `pw.env.set` in a Tests section, but it will set this token that we received for other workspace members as well, and it's not convenient when multiple members are using the same workspace at the same time. I see an option either to add an parameter to `pw.env.unset`/`pw.env.set` like `secret = true/false` or add an additional methods to the `env` namespace. 

### Why should this be worked on?

Improve multi-member usability
Ambiguous terms: useful, non-secret, some sort of, particular, convenient, additional
Questions:
1. What specific actions are currently being taken with the shared variables and the token received from the `login` API request?
2. Can you provide more details on how the current process affects multiple workspace members?
Clarified requirement: Is there a need to enhance the functionality of setting/unsetting secret variables from scripts to improve usability for multiple members in a shared workspace environment? This enhancement could involve adding a parameter like `secret = true/false` to `pw.env.unset`/`pw.env.set` or introducing additional methods to the `env` namespace.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Access to request body in scripts, similar to Postman pm.request

### Why should this be worked on?

Hi,
in Postman I used to access to request body in scripts using pm.request
Is there the possibility to implement this feature?
Ambiguous terms: similar, possibility
Questions:
1. What does "similar to Postman pm.request" entail in terms of functionality?
2. Can you clarify what you mean by "implement this feature"?
Clarified requirement: Is there a way to access the request body in scripts, like how it is done in Postman using pm.request?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

We might want to have a unique id or label for the custom fields in the secret variables form so some integrations can properly differentiate between the variable names. 

As of now, as far as I'm aware, the id and name of the fields are `secret`. We can change this to `secret-client_id` for the `client_id` variable. If we add a variable `client_secret` we set the input field next to it `secret-client_secret` and so on so forth...

![image](https://github.com/user-attachments/assets/54168a80-478a-4364-9431-4ca0f4b20b10)


### Why should this be worked on?

By doing this, we can use Bitwarden or other password managers to autofill the variables secret key/value pairs.
Ambiguous terms: unique, label, properly, differentiate, variable names, change, set, next to, and so on
Questions:
1. What specific integrations are being referred to that need to differentiate between the variable names?
2. Can you clarify what is meant by "set the input field next to it"?
Clarified requirement: Is there an existing issue for this? We need to assign unique ids or labels to custom fields in the secret variables form so that certain integrations can distinguish between variable names. Currently, the id and name of the fields are 'secret'. To improve this, we propose changing the id to 'secret-client_id' for the 'client_id' variable. Similarly, for 'client_secret', the id would be 'secret-client_secret', and so forth. This adjustment will allow for autofill capabilities using password managers like Bitwarden.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Javascript provides a `DOMParser()` for dealing with XML, however it errors as an unknown identifier. 

<img width="414" alt="image" src="https://github.com/user-attachments/assets/71f0ec53-81d5-4b06-b526-fa054fe05189">

A better alternative would be `xml2json()`, however this is also unavailable.

<img width="433" alt="image" src="https://github.com/user-attachments/assets/2d87d40c-371d-4b6e-a956-6e81305bb770">



### Why should this be worked on?

I need to be able to test XML APIs and pass values to environment variables.
Ambiguous terms: better, unavailable
Questions:
1. What does "better" mean in the context of the alternatives?
2. How are the alternatives determined to be "unavailable"?
Clarified requirement: The task is to test XML APIs and pass values to environment variables.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

As of now the default proxy url has been hardcoded and is not configurable from env. 

https://github.com/hoppscotch/hoppscotch/blob/9da5f63e701ba072ea393e68847d7f8e395d4c4a/packages/hoppscotch-common/src/newstore/settings.ts#L100

For Self Hosted environments it should be configurable from env or Admin Settings

### Why should this be worked on?

Currently every time a new user is added he has to manually change the proxy url or install extensions. This will let the administrator to set the default for the instance
Ambiguous terms: configurable, Self Hosted, configurable, Admin Settings, default
Questions:
1. What does "configurable from env" mean in this context?
2. Can you clarify what is meant by "Self Hosted" and "Admin Settings"?
Clarified requirement: Is there an existing issue for setting the default proxy URL in the Hoppscotch application? As of now, the default proxy URL is hardcoded and cannot be changed from the environment settings. For Self Hosted environments, the default proxy URL should be adjustable either through environment configurations or Admin Settings. This change is necessary to avoid manual changes by new users or the need to install extensions every time a new user is added. It will allow the administrator to set the default proxy URL for the instance.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Team

I am the creator and maintainer of [vet](https://github.com/safedep/vet), tool to automate vetting of open source dependencies in PR using custom policies (as code). I wanted to check if you are willing to adopt `vet` to setup a policy driven security guardrail against risky OSS packages being added to `hoppscotch` as dependencies.

Example PR vetted by `vet`: 

https://github.com/safedep/vet/pull/239#issuecomment-2331412400

Example policy using which the vetting was done:

https://github.com/safedep/vet/blob/main/.github/vet/policy.yml

If there is interest, I am happy to contribute a PR to integrate `vet` as a GitHub Action to scan dependency changes during PR in `hoppscotch` as per your customised policies. Also happy to contribute subsequent PRs to upgrade packages to fix existing vulnerabilities in `npm` packages.

### Why should this be worked on?

To reduce the risk of vulnerable or malicious `npm` packages being added to `hoppscotch` as dependencies. Also to assist code reviewers to make a faster decision on PRs from the community that add new dependencies.
Ambiguous terms: risky, vulnerable, malicious, faster
Questions:
1. What is meant by "risky OSS packages"?
2. Can you clarify what is meant by "faster decision on PRs"?
Clarified requirement: Determine if there is interest in adopting the tool "vet" to set up a policy-driven security measure against potentially harmful open source packages being added as dependencies to "hoppscotch." This would involve integrating "vet" as a GitHub Action to scan dependency changes during pull requests in "hoppscotch" based on customized policies, and also upgrading packages to address existing vulnerabilities in npm packages. The goal is to mitigate the risk of adding vulnerable or malicious npm packages to "hoppscotch" and streamline the code review process for new dependencies.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

1. When I work with a local collection and I have logged in, my state is synchronized with the cloud. 
2. After logging out, I continue to work with my personal collection, my data is not synchronized with the server. 
3. After a while, I log in as a user, my current changes made in step 2 **were erased and lost**.

The problem lies in this line of the file https://github.com/hoppscotch/hoppscotch/blob/main/packages/hoppscotch-selfhost-web/src/platform/collections/collections.platform.ts#L73-L82 and https://github.com/hoppscotch/hoppscotch/blob/main/packages/hoppscotch-selfhost-desktop/src/platform/collections/collections.platform.ts#L73-L82

### Why should this be worked on?

After studying the code, it became clear that priority is given to data from the cloud. User data is simply deleted in this case. This is wrong and may alienate QA engineers due to the risk of losing their own data.

I suggest developing a more correct data synchronization strategy.
Ambiguous terms: correct, more, wrong, may, risk, more correct
Questions:
1. What specific issue is being referred to in the requirement?
2. What does the term "more correct data synchronization strategy" entail?
Clarified requirement: A more precise data synchronization strategy needs to be developed.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

The OIDC standard has defined an endpoint that is well supported by common OAuth2 providers (including but not limited to Microsoft Azure, Keycloak, Ory Hydra).

This endpoint is always found at $SERVER/.well-known/openid-configuration.

It provides information about almost all details I need to enter manually evertime I setup OAuth login in Hoppscotch: the autorization endpoint, the token endpoint, allowed flows, the allowed scopes and the "pass by" (header/body)

Instead of entering them all manually I would like to give either just the server name or the wholen url to the openid-configuration and then Hoppscotch pre-populates the fields for me.

### Why should this be worked on?

It reduces the time to configure or switch between OAuth2 configurations immensely and avoids common, hard to debug errors like selecting the wrong "pass by" method.
Ambiguous terms: common, well supported, almost all, manually, immensely, common
Questions:
1. What specific details are provided by the endpoint found at $SERVER/.well-known/openid-configuration?
2. How does pre-populating the fields in Hoppscotch help in reducing configuration time?
Clarified requirement: Is there an existing issue for this feature request to enable pre-populating OAuth2 configuration fields in Hoppscotch by providing the server name or URL to the openid-configuration endpoint, which contains details such as authorization endpoint, token endpoint, allowed flows, allowed scopes, and "pass by" method? This feature aims to reduce configuration time and prevent errors related to OAuth2 setup.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I am requesting the addition of a feature that allows users to define and use variables within collections, not just in environments. This feature would significantly enhance the flexibility, maintainability, and reusability of collections.

### Why should this be worked on?

Implementing variables in collections will provide significant benefits in terms of modularity, ease of use, maintainability, and collaboration. It aligns with modern development practices and addresses several pain points currently faced by developers. By adding this feature, it will enhance its platform's functionality and provide a more powerful and flexible setup for the collections, ultimately leading to better software outcomes.

There are siturations where you want to have some variants on a collection, but don't want to set it up in an environment.
Ambiguous terms: significant, flexibility, maintainability, reusability, modularity, ease of use, collaboration, powerful, flexible, better
Questions:
1. What specific benefits would implementing variables in collections provide in terms of modularity, ease of use, maintainability, and collaboration?
2. Can you provide examples of the pain points currently faced by developers that implementing this feature would address?
Clarified requirement: Is there an existing issue for adding a feature that allows users to define and use variables within collections, not just in environments? The addition of this feature is requested to enhance the flexibility, maintainability, and reusability of collections. Implementing variables in collections is expected to improve modularity, ease of use, maintainability, and collaboration, aligning with modern development practices and addressing pain points faced by developers. This feature aims to enhance the platform's functionality and provide a more powerful and flexible setup for collections, leading to better software outcomes.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

https://docs.hoppscotch.io/documentation/self-host/community-edition/install-and-build

This section with steps without Docker.

### Why should this be worked on?

Two reasons.
1. I'm packaging Hoppscotch Community Edition for nixpkgs (https://github.com/NixOS/nixpkgs/pull/317162), and we at nixpkgs do not prefer packaging with Docker since nixpkgs' build infrastructure/tooling already does what Docker does, there's no point adding a virtualisation layer on top of it and is wasteful.
2. The principle. No software should be married to some build tooling. Context from the conversations with the team on Hoppscotch's public Discord:
   > The backend, in particular, was designed to run with Docker, so configuring it without containerizations might be a bit of a headache.

   This shouldn't be the case. I'd argue that this issue should be a bug report and not a feature request.
Ambiguous terms: fast, user-friendly, ambiguous, vague, subjective, should, do not prefer, wasteful, might be a bit of a headache
Questions:
1. What specific issue is being referred to here?
2. What is the desired outcome or resolution for this issue?
Clarified requirement: Determine the specific existing issue related to the section on installing and building Hoppscotch Community Edition without Docker, and work on resolving it based on the reasons provided.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

It is hoped that multiple requests can be executed in batches, and the concurrency time and number of concurrency can be specified, so that you can directly test whether the whole project functions normally in one step, and then stress test whether the system is stable.

### Why should this be worked on?

When there are multiple requests, there must be a sequence, first to add data, and then to query the data, and each time you have to manually send a request to add data, to find the query interface to query the request, and maybe also need to get the result of the add request to query the data; Another one I ask to stress test a project when it shouldn't be when I manually click to implement the stress test
Ambiguous terms: hoped, multiple, specify, directly, normally, stable, sequence, manually, maybe, stress test
Questions:
1. What does "concurrency time" refer to in this context?
2. Can you clarify what is meant by "sequence" when referring to multiple requests?
Clarified requirement: Handling multiple requests currently requires manual execution in a specific sequence, involving adding data, querying data, and verifying results. Automating this process would streamline testing procedures and ensure stress testing can be performed efficiently.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Currently it is only possible to use one environment at the same time.

This brings me in challenges, when I have an Endpoint on multiple devices, but also the configuration of the device can be targetted against diffrent backends.

I am looking for the simple possibility to merge two envirnoments (of course duplicates would need to be just ignored or shown as alerts), but basiccaly it you be doable.

### Why should this be worked on?

Currently no API Interface Simulator is offering this - and basically it is a legit usecase.
Ambiguous terms: simple, merge, possible, multiple, simple, basiccaly, legit
Questions:
1. What does "merge two environments" mean in this context?
2. Can you clarify what is meant by "duplicates would need to be just ignored or shown as alerts"?
Clarified requirement: Determine if there is an existing issue for the request to enable the simultaneous use of multiple environments, allowing for the merging of environments while handling duplicates by either ignoring them or showing alerts. This feature is sought after to address the challenge of working with multiple devices and configurations targeting different backends.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Using Hoppscotch 24.8.3 on macOS, the current "dark" and "black" color schemes are almost indistinguishable, and I have to strain my eyes to see where specific UI components begin and end:
<img width="1719" alt="Screenshot 2024-09-30 at 10 07 37 AM" src="https://github.com/user-attachments/assets/097639fe-8d26-422b-8726-994d5377ff9f">
<img width="1719" alt="Screenshot 2024-09-30 at 10 07 49 AM" src="https://github.com/user-attachments/assets/67865fc3-f59d-48ae-841c-4b8a61175881">

Making the background color of "dark" mode a few shades lighter would better distinguish it from "black" mode, and perhaps making the lines separating different UI elements a bit lighter would improve visual navigation.

Here's an example of a lighter "dark" mode from Insomnia with clearer separation between the different UI elements:
<img width="1771" alt="Screenshot 2024-09-30 at 10 17 10 AM" src="https://github.com/user-attachments/assets/3da6aba4-8203-4031-8eea-1235c8634112">

Would it be possible to allow the user to tweak the theme in more detail, or at least choose a specific background color?

### Why should this be worked on?

It's important to make sure your users aren't experiencing eye strain or having difficulty distinguishing UI components. Tweaking the theme colors (or permitting the user to tweak the theme colors) seems like a good solution.
Ambiguous terms: almost, few, better, a bit, more detail, specific
Questions:
1. What specific aspects of the theme colors need to be tweaked for better visibility?
2. Is the user looking for a way to customize the background color independently in the theme settings?
Clarified requirement: The user is requesting the ability to adjust theme colors, specifically making the "dark" mode background a few shades lighter to distinguish it from "black" mode and improve visibility of UI elements. The user also seeks the option to customize the theme colors in more detail, potentially allowing for specific background color selection.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

This feature would allow users to specify which HTTP version they want to use when sending API requests. By providing the option to switch between HTTP/1.1, HTTP/2, and HTTP/3, This would help to test applications on various http versions.


### Why should this be worked on?

Many developers need to test their APIs across different HTTP versions to ensure compatibility. 
Currently, without the ability to switch HTTP versions, users may struggle to assess how their APIs perform under various conditions. 
This feature would enhance Hoppscotch's functionality, making it very useful for testing applciations.
Ambiguous terms: various, many, enhance, useful
Questions:
1. What specific conditions are developers looking to test their APIs under with different HTTP versions?
2. How exactly would this feature enhance Hoppscotch's functionality?
Clarified requirement: Developers need to test their APIs across different HTTP versions to ensure compatibility. Without the ability to switch HTTP versions, users may struggle to assess how their APIs perform under specific conditions. Implementing this feature would enhance Hoppscotch's functionality, making it a valuable tool for testing applications.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Having multiple GraphQL endpoints to query, I find myself switching often between them. But what bothers me is that I have to "Connect" everytime I switch from endpoint, having to deal with the following pop-up.

![image](https://github.com/user-attachments/assets/00f85da4-3197-4315-8224-39d3179a89d6)

I simply want to run the query without having to manually click "Connect" in this pop-up. An auto-connect setting would be nice to have (or ability to disable the pop-up).

### Why should this be worked on?

Faster switching between endpoints makes a developer more productive.
Ambiguous terms: multiple, often, bothers, nice, productive
Questions:
1. What specific actions trigger the pop-up window mentioned in the requirement?
2. Is the auto-connect setting meant to be a global setting for all endpoints or configurable per endpoint?
Clarified requirement: "Is there an existing issue for the pop-up window that appears when switching between GraphQL endpoints? I want to have an auto-connect setting to run queries without manually clicking 'Connect' on the pop-up, or the ability to disable the pop-up. This feature would allow for faster switching between endpoints and increase developer productivity."


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

We would like to use pod scaling, as far as I understand it would be necessary for all (api) pods to have the same session information, so the best solution would probably be to store the sessions in the database.

Maybe this can be easily solved: https://github.com/kleydon/prisma-session-store


### Why should this be worked on?

Makes Hoppscotch more enterprise-ready
Ambiguous terms: best, easily, enterprise-ready
Questions:
1. What specific criteria define the "best" solution in this context?
2. Can you elaborate on what "enterprise-ready" means for Hoppscotch?
Clarified requirement: Determine if using pod scaling requires all (api) pods to have the same session information and consider storing sessions in a database using the solution provided in https://github.com/kleydon/prisma-session-store to make Hoppscotch more enterprise-ready.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

as cURL requests copied from the Windows version of Chrome always include annoying characters like ^ and \ 

Like this:

`curl "https://xxxx.com/xx/xx-xx/set" ^
  -H "authority: xxxx.com" ^
  -H "accept: application/json, text/plain, */*" ^
  -H "accept-language: zh-CN,zh;q=0.9,en;q=0.8" ^
  -H "content-type: application/json;charset=UTF-8" ^
  -H "origin: http://xxxx.net:8080" ^
  -H "referer: http://xxxx.net:8080/" ^
  -H "sec-ch-ua: ^\^"Google Chrome^\^";v=^\^"119^\^", ^\^"Chromium^\^";v=^\^"119^\^", ^\^"Not?A_Brand^\^";v=^\^"24^\^"" ^
  -H "sec-ch-ua-mobile: ?0" ^
  -H "sec-ch-ua-platform: ^\^"Windows^\^"" ^
  -H "sec-fetch-dest: empty" ^
  -H "sec-fetch-mode: cors" ^
  -H "sec-fetch-site: cross-site" ^
  -H "user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36" ^
  --data-raw "^{^\^"tag^\^":^\^"backend_rewards^\^",^\^"user_id^\^":^\^"^\^",^\^"expire_at^\^":^\^"2024-09-26 16:59:59^\^",^\^"limit^\^":^\^"1^\^",^\^"desc^\^":^\^"^备^注12^\^",^\^"reward^\^":^[^{^\^"type^\^":^\^"pay_ticket^\^",^\^"quantity^\^":^\^"50^\^"^},^{^\^"type^\^":^\^"free_ticket^\^",^\^"quantity^\^":^\^"100^\^"^}^]^}" ^
  --compressed`

### Why should this be worked on?

Colleagues are collaborating directly and circulating the current cURL requests due to interface error issues. However, cURL requests copied by colleagues using Windows systems are often messy. Currently, Postman allows direct import.
Ambiguous terms: annoying, messy
Questions:
1. What specific characters are considered annoying in the cURL requests?
2. Can you provide an example of how the cURL requests copied by colleagues using Windows systems appear messy?
Clarified requirement: Determine the specific characters considered annoying in the cURL requests and provide examples of how the cURL requests copied by colleagues using Windows systems appear messy.


Clarify this requirement: ### Is there an existing issue for this?

- [ ] I have searched the existing issues

### Summary

Hoppscotch provides support for socketIO testing, however it does not support way to pass auth token parameter.

### Why should this be worked on?

As an open source project hoppscotch should support wide range of options for testing. It will be great user experience which is lacks in other alternative
![image](https://github.com/user-attachments/assets/a18a3933-5ef8-492c-bb6e-fca5126ec8ff)
Ambiguous terms: wide range, great user experience, other alternative
Questions:
1. What specific options for testing should Hoppscotch support to cater to a wide range of needs?
2. Can you clarify what is meant by "other alternative" in the context of lacking user experience?
Clarified requirement: Is there an existing issue for this? I have searched the existing issues. Hoppscotch provides support for socketIO testing, but it lacks a way to pass an auth token parameter. As an open source project, Hoppscotch should support a variety of testing options to enhance user experience, addressing the shortcomings present in other similar tools.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hoppscotch uses 5 different versions of Typescript (mostly with difference in patch version). 

### Why should this be worked on?



        Downloading typescript@5.2.2: 7,23 MB/7,23 MB, done
        Downloading @swc/core-darwin-x64@1.4.2: 14,96 MB/14,96 MB, done
        Downloading typescript@4.9.3: 11,62 MB/11,62 MB, done
        Downloading typescript@5.3.2: 5,76 MB/5,76 MB, done
        Downloading @fontsource-variable/material-symbols-rounded@5.0.16: 9,13 MB/9,13 MB, done
        Downloading typescript@5.3.3: 5,76 MB/5,76 MB, done
        Downloading typescript@4.9.5: 11,62 MB/11,62 MB, done
        Downloading @tauri-apps/cli-darwin-x64@1.5.6: 7,91 MB/7,91 MB, done
        Downloading @fontsource-variable/material-symbols-rounded@5.0.5: 9,13 MB/9,13 MB, done
        
Maybe it would be beneficial to make sure every subpackage uses the same typescript version? For the sake of fixed bugs, maybe security things, but also to just have single typescript in your pnpm thingy instead of 5 (and probably all the dependencies as well).
Ambiguous terms: beneficial, fixed, bugs, security, single, probably, all
Questions:
1. What specific action is needed regarding the different versions of Typescript used by Hoppscotch?
2. Is the goal to update all subpackages to use the same version of Typescript?
Clarified requirement: Hoppscotch uses 5 different versions of Typescript (mostly with difference in patch version). It may be beneficial to ensure that every subpackage uses the same version of Typescript for potential bug fixes, security improvements, and to streamline dependencies.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

When using Hoppscotch, it is very cumbersome to update environment variables when they are URLs. It is also not possible to see if you have a wrong value since the full value is not displayed. 

Here's an example when an URL from production was put by mistake in my fabrication environment : 

[Capture vidéo du 20-09-2024 15:29:58.webm](https://github.com/user-attachments/assets/d479bd73-80e8-4b8e-be20-7e80274a0162)

Currently the best solution I have to deal with this is to export the environment as JSON, edit it by hand in a correct editor, then import it again which is not ideal. 

Could you make the "Edit environment" screen larger, more specifically the second column which is the one that may contains long strings ? 

### Why should this be worked on?

- by allowing the user to see the value of a variable in full, we limit the risk to commit mistake (by putting a prod env url instead of a fab env url for example)
- less chance to commit a mistake by typing something when you see what you are typing
- this feature makes the app more fluid and pleasant to use
- the user will loose less time trying to debug something if he can see all the environment variables at once
Ambiguous terms: cumbersome, user-friendly, not possible, wrong, best, larger, more specifically, ideal, fluid, pleasant
Questions:
1. What specific actions are considered cumbersome when updating environment variables in Hoppscotch?
2. Can you clarify what you mean by making the "Edit environment" screen larger?
Clarified requirement: - Users will spend less time debugging if they can view all environment variables at once.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Key vault support to fetch secrets stored in Azure Key vault/AWS Secret Manager/GCP Secret Manager

### Why should this be worked on?

I have been using Postman and Insomnia for API testing. One of the primary concerns during API testing is the secure storage of API secrets. Both Postman and Insomnia support integration with Azure Key Vault, which I use to retrieve secrets and utilize them as variables within the platforms. This would help in automatically fetching API secrets instead of manually adding them for each user environment.
Ambiguous terms: secure, automatically, manually
Questions:
1. What specific platforms or tools are being used for API testing?
2. Can you clarify what is meant by "automatically fetching API secrets"?
Clarified requirement: Is there an existing issue for implementing key vault support to fetch secrets stored in Azure Key Vault, AWS Secret Manager, and GCP Secret Manager for API testing platforms like Postman and Insomnia? The goal is to enable the retrieval of secrets from these vaults and use them as variables within the testing platforms to streamline the process for users.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

There should be a button that will make it possible to sort alphabetically, both in the collection and inside it

### Why should this be worked on?

Is it possible to add sorting of API folders and collections. Now you can only manually drag and drop folders, which is extremely inconvenient when you have several dozen of them
Ambiguous terms: possible, extremely
Questions:
1. What is meant by "sort alphabetically" in this context?
2. Can you clarify what is meant by "both in the collection and inside it"?
Clarified requirement: Is there an existing issue for adding the functionality to sort API folders and collections alphabetically, both within the collection and overall? Currently, manual drag and drop is the only option, which is inconvenient when dealing with multiple folders.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I noticed that on some screens the rendering time increases linearly with the number of elements. For example, on the edit environment variables page. 

With a number of elements of about 100, the page generation time takes more than 2 seconds (macbook m1), even longer on older machines. 

With the help of the profiler, it was found out that the problem is too "heavy" SmartEnvInput. 

I ask you to optimize somehow, because this is important for us.

[test.json](https://github.com/user-attachments/files/17009709/test.json)

### Why should this be worked on?

The product is slow when used in full on large amounts of data. This prevents implementation in large companies
Ambiguous terms: slow, heavy, optimize, large
Questions:
1. What specifically does "slow" refer to in terms of page generation time?
2. Can you clarify what is meant by "heavy" in the context of SmartEnvInput?
Clarified requirement: The product's performance is significantly affected when handling large amounts of data, making it unsuitable for implementation in large companies.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Be able to switch accounts without logging out

### Why should this be worked on?

Having to log out any time I have to switch accounts and then log back in is frustrating. But it is manageable, probably worth keeping this is low priority unless others request it.
Ambiguous terms: frustrating, manageable, low priority
Questions:
1. What does "switching accounts" refer to in this context?
2. How is the priority of this task currently determined?
Clarified requirement: Determine if there is an existing issue related to the ability to switch accounts without logging out, and if not, prioritize implementing this feature to address the frustration of having to log out and log back in when switching accounts.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Current behavior

When I use attachments in the post method, they are not saved, the fields become empty.
I expect the attachment to be saved and can be used in the future

### Steps to reproduce

1. run a post with an attachment
2. save method
3. refresh page/shared method
4. attachment fields are empty
![image](https://github.com/user-attachments/assets/d18c7fe2-5df8-4edb-833c-6fe7c115b0f4)
Same on https://hoppscotch.io/

### Environment

Production

### Version

Self-hosted
Ambiguous terms: saved, empty, future
Questions:
1. What does "saved" mean in the context of attachments?
2. Can you clarify what is meant by "empty fields" for attachments?
Clarified requirement: Self-hosted


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

A test should allow setting not just a variable in the environment but a non-synced secret also.

There is a use-case here for storing tokens after a login request for use in other requests. Ideally these would be stored in secrets and non-synced.

### Why should this be worked on?

There are two types of variables, variables and secrets, and it's not clear how to set a secret (or that you can't) from the Test panel. This would speed up testing where requests need a separate login request that is not part of the builtin family of methods.
Ambiguous terms: clear, non-synced, ideally, secrets, separate
Questions:
1. What is meant by "non-synced secret" in this context?
2. Can you clarify what is meant by "secrets" and how they differ from variables?
Clarified requirement: Is there a need to allow setting non-synced secrets in tests for scenarios where tokens need to be stored after a login request for later use in other requests? This feature should enable the storage of secrets that are not synchronized, distinct from regular variables, to expedite testing processes involving separate login requests that are not part of the built-in methods.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Like how Arc, Edge & some firefox extensions do it, putting the tabs on the left instead of on top

### Why should this be worked on?

- Free up precious vertical screen heights for other contents
- Much easier in tab / history management
- The current tab bars already have enough spaces to add a `Tab` icon, so UI work should be limited (quick n easy W)
Ambiguous terms: precious, easier, enough, limited, quick, easy
Questions:
1. What specific issue is being referred to in the requirement?
2. Can you clarify what is meant by "Tab icon" in this context?
Clarified requirement: - It is noted that the current tab bars have sufficient space to accommodate a 'Tab' icon, making UI adjustments relatively quick and easy.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hi team,

<img width="309" alt="image" src="https://github.com/user-attachments/assets/1c5b874f-a9db-4a6c-bd97-2f862418d000">

When downloading files, the API client currently doesn't pre-fill the name and extension type of the file.

It would greatly improve my user experience if there would be a "send + download" button which would send the payload and download the response immediately with the name and extension of the file pre-filled.

Optionally you could have a look at how other API clients do this.

### Why should this be worked on?

Basically user experience:

The flow is currently: click send, wait for response, click download, change name, change filetype, save file. 😤

While it could be: click send + download, wait for response, and save file. 😌
Ambiguous terms: immediately, greatly, improve, Optionally, look at, how, other, could, have a look, do this, Basically, currently, click, wait, response, change, save
Questions:
1. What specific information should be pre-filled for the file name and extension type?
2. Are there any specific API clients that the team prefers to look at for inspiration?
Clarified requirement: Is there an existing issue for not pre-filling the name and extension type of the file when downloading files via the API client? The request is to add a "send + download" button that sends the payload and immediately downloads the response with the pre-filled name and extension of the file. Additionally, the team may consider looking at specific API clients for inspiration.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Offer the option to hide the request horizontal tab bar. Depends on autosave to be implemented first. 





### Why should this be worked on?

If auto save https://github.com/hoppscotch/hoppscotch/issues/3437#issue-1932666928 gets implemented, horizontal tabs would loose part of their purpose. Add the option to disable it in the UI.

In practice, opening and running several requests makes the horizontal tab bar quickly cluttered and not practical to use.
- Changing requests using the sidebar or the horizontal tab bar requires the same number of click. 
- Horizontal scrolling in a small area is less practical than sidebar vertical scrolling.
Ambiguous terms: quickly, practical, several, cluttered, not practical
Questions:
1. What is the relationship between the horizontal tab bar and the existing issue mentioned?
2. Can you clarify what is meant by "horizontal scrolling in a small area"?
Clarified requirement: In practice, when multiple requests are opened and run, the horizontal tab bar becomes cluttered and impractical to use. Changing requests using either the sidebar or the horizontal tab bar requires the same number of clicks. Additionally, horizontal scrolling within a small area is less practical than vertical scrolling in the sidebar.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Allows admins to create and manage Teams with API, and invite user to the team workspace

### Why should this be worked on?

In my company, teams and users are managed in a specific tool, 
we would like to be able to automatically create teams and associate users to them
Ambiguous terms: specific, automatically
Questions:
1. What specific tool is currently used to manage teams and users?
2. What does "automatically create teams and associate users to them" entail?
Clarified requirement: Ensure the ability for admins to create and manage Teams using the API, invite users to the team workspace, and integrate with a specific tool for managing teams and users to streamline the process of creating teams and associating users.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

A Node based system to setup workflows for API testing. should feature an intuitive collection of nodes that allows users to setup a graph with connections between API requests / responses and specify how they should behave

### Why should this be worked on?

Would allow users to setup more complicated workflows for API testing without having to explicitly program them.
Ambiguous terms: intuitive, complicated
Questions:
1. What is meant by "intuitive" in the context of setting up workflows for API testing?
2. Can you provide an example of what would be considered a "complicated workflow" for API testing?
Clarified requirement: Is there an existing issue for setting up a Node based system to create workflows for API testing that includes a collection of nodes allowing users to create a graph with connections between API requests/responses and specify their behavior? This system should enable users to set up more complex workflows for API testing without the need for explicit programming.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Though no existing issue, somewhat related is this is #3782 where it was asked to sort the variables within the environment.
It would be good to have some sort of ordering within the environment selector. I would propose alphabetical ordering.

### Why should this be worked on?

When having multiple environments to test with, it is easy to setup a request using enviroment-defined variables. Having many environments allow to a url which hit servers across different regions.

When a Viewer comes to use the request across different regions, unless the environments are added in a logical order, it is difficult to find the specific environment they want to make the request against. Having an order would make switching between environments more intuitive and remove the need for the Hoppscotch Editor/Owner to maintain their own ordering.
Ambiguous terms: some sort, good, logical, intuitive
Questions:
1. What is meant by "some sort of ordering within the environment selector"?
2. Can you clarify what is meant by "logical order" in the context of adding environments?
Clarified requirement: Is there an existing issue for implementing alphabetical ordering within the environment selector to make switching between environments more intuitive and remove the need for manual ordering by the Hoppscotch Editor/Owner?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

When I select the Light background, could the cursor color automatically change to a darker shade? Alternatively, could you provide an option to choose the cursor color? Otherwise, it is very difficult to see the cursor position when editing the body with the Light background.
![image](https://github.com/hoppscotch/hoppscotch/assets/53635077/b802026b-40e8-418f-9d53-a2bfd360ba07)


### Why should this be worked on?

To enhance the user experience for everyone
Ambiguous terms: darker, difficult
Questions:
1. What specific shade of darker should the cursor color change to when selecting the Light background?
2. Can you clarify what makes it difficult to see the cursor position when editing the body with the Light background?
Clarified requirement: Is there an existing issue for this? When selecting the Light background, the cursor color should automatically change to a specific darker shade. Alternatively, an option to choose the cursor color should be provided. It is difficult to see the cursor position when editing the body with the Light background. This change is aimed at enhancing the user experience for everyone.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Read authentication from `~/.netrc`

### Why should this be worked on?

Would be quite helpful as it allows sharing authentication between tools, i.e. `curl -n`.
Ambiguous terms: quite helpful, allows, sharing, helpful
Questions:
1. What specific tools would benefit from sharing authentication using `~/.netrc`?
2. How would the ability to share authentication between tools impact the overall workflow?
Clarified requirement: Is there an existing issue for reading authentication from `~/.netrc` to allow sharing authentication between tools like `curl -n`?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hi!
I followed the steps from https://docs.hoppscotch.io/documentation/features/authorization#oauth-2-0 to set the Collection Properties Authorization part for all requests. I'm not sure if there is any better way so I'm posting here the idea.

While changing frequently environments, the generated token is not changing accordingly. It would be nice to have it environment-aware or have some configuration that tries to regenerate the token whenever Unauthorized is returned for any request (that might be even more helpful in the case of short-lived tokens).

### Why should this be worked on?

Whenever I change the environment, I need to go to Collections Properties, hit "Generate Token" button to generate a specific one for the active environment, and save it.
Ambiguous terms: better, nice, short-lived
Questions:
1. What specific issue is the user referring to when asking if there is an existing issue for this?
2. Can the user clarify what is meant by "short-lived" tokens?
Clarified requirement: ### Is there an existing issue related to the need for environment-aware token regeneration in Hoppscotch Collections Properties Authorization? The user is experiencing issues with the generated token not updating when changing environments and suggests a feature that automatically regenerates the token when Unauthorized responses are received. The user also mentions the need for a specific token generation for the active environment.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I would like to be able to initiate an openapi collection import when we update our spec. 
I'd like to be able to fire a github action when our spec changes and update our collection. 

I'm playing with a playwright automation that can upload, but this feels very hacky.

### Why should this be worked on?

Absolutely no reason this SHOULD be worked on. Just trying to integrate hoppscotch into our automation.
Ambiguous terms: like, feel
Questions:
1. What specific actions are involved in initiating an openapi collection import and updating the collection?
2. Can you provide more details on how the current process with Playwright automation feels hacky?
Clarified requirement: There is no specific reason that necessitates this work, I am simply looking to integrate Hoppscotch into our automation process.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Can it automatically attempt to format the response data into JSON?

### Why should this be worked on?

Can it automatically attempt to format the response data into JSON?
Ambiguous terms: automatically, attempt, format, response data, JSON
Questions:
1. What is meant by "automatically attempt" in this context?
2. Can you provide more clarity on what is considered as "response data"?
Clarified requirement: Is there a way for the system to automatically convert the response data into JSON format?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

In https://github.com/hoppscotch/hoppscotch/issues/3551 the "Copy interface type" feature was added which seems to be using quicktype.io under the hood.
This feature is great!

However, I don't see any way to convert response to JSON Schema (which is a [recommended way of using quicktype](https://github.com/glideapps/quicktype?tab=readme-ov-file#generating-code-from-json-schema)).

At our company we work with ton of APIs and use JSON Schemas extensively, so it would be amazing if this option was added. At the moment we have to use additional tools to generate JSON Schemas from sample data.

I'm willing to try to make a PR for it myself if I get a green light from maintainers.

### Why should this be worked on?

That seems like a small quick win for the project.
The library used under the hood already supports JSON Schema as an output, and there's a use case for it.
That will save my team a lot of time and spare the need to use one extra tool.
Ambiguous terms: small, amazing, extensively, amazing
Questions:
1. What specific feature is the requester looking to add to the project related to JSON Schema conversion?
2. Is there a specific library or tool that the requester wants to integrate for generating JSON Schemas?
Clarified requirement: The requester is proposing to add an option for converting responses to JSON Schema within the project, as they work extensively with JSON Schemas and believe it would be a valuable addition to save time and streamline their workflow.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

 How to search for path and body

### Why should this be worked on?

 How to search for path and body
Ambiguous terms: search, path, body
Questions:
1. What exactly is meant by "search for path and body"?
2. Can you provide more context on what is meant by "existing issue"?
Clarified requirement: Is there an existing issue related to searching for the path and body? Before working on this, ensure that you have searched the existing issues thoroughly.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Feature Request: API Documentation Generation

Overview:
I would like to request the addition of an API documentation generation feature in Hoppscotch. This feature will enable users to generate comprehensive API documentation directly from their collections.

Detailed Description:

    Purpose: To enhance usability by allowing users to generate and share API documentation easily.
    Functionality:
        Users can add descriptions to their requests.
        Users can organize requests into collections.
        A new "Generate Documentation" option for collections.
        Generated documentation includes endpoint details, parameters, headers, request/response examples, and descriptions.
        Users can publish the documentation and get a sharable URL.
        Support for Markdown formatting in descriptions.

Benefits:

    Provides an easy way for users to document their APIs.
    Improves team collaboration by making API endpoints understandable.
    Enhances user experience by integrating documentation capabilities within the app.

Thank you for considering this request!

### Why should this be worked on?

Current Problem:
Hoppscotch does not have an integrated way to generate and share API documentation. Users must rely on external tools, which can be time-consuming and inconsistent.

Use Cases:

    API Development Teams: Need clear and accessible documentation for all team members to understand API endpoints, parameters, and responses.
    Clients and Partners: Require detailed and accurate documentation for effective API integration.
    Individual Developers: Benefit from a unified platform to manage API requests and documentation together.

Benefits:

    Efficiency: Saves time by generating documentation directly from Hoppscotch.
    Consistency: Ensures documentation is always up-to-date.
    Collaboration: Enhances team collaboration with a single source of truth for API documentation.
    User Experience: Improves user experience by integrating documentation capabilities into Hoppscotch.
Ambiguous terms: comprehensive, easily, clear, detailed, accurate, effective, unified, up-to-date, enhances, improves
Questions:
1. What specific format should the generated documentation be in?
2. Is there a requirement for any specific tools or platforms to publish the documentation?
Clarified requirement: Is there a specific format for the generated API documentation, and are there any specific tools or platforms required for publishing it?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Is there any feature in HOPPSCOTCH that is similar to setNextRequest in POSTMAN that would help us loop through different requests based on the requirement.


### Why should this be worked on?

We have existing requirements which uses the setNextRequest extensively for looping through multiple requests based on the  requirement
Ambiguous terms: similar, help, looping, extensively, multiple
Questions:
1. What does "setNextRequest" do in POSTMAN?
2. Can you provide an example of how "setNextRequest" is used for looping through requests?
Clarified requirement: Is there a feature in HOPPSCOTCH similar to "setNextRequest" in POSTMAN that allows for looping through different requests based on specific requirements? This is needed because there are existing requirements that heavily rely on "setNextRequest" for looping through multiple requests based on the requirement.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

An environment variable to disable the http **secure** cookies.

### Why should this be worked on?

Login feature is broken when hoppscotch installed locally and/or servers without ssl. Basically there are use cases where security isn't a major concern.
Ambiguous terms: secure
Questions:
1. What specifically is meant by "secure" in the context of http cookies?
2. Can you provide examples of how the login feature is broken when Hoppscotch is installed locally or on servers without SSL?
Clarified requirement: Is there an existing issue for this? I have searched the existing issues. An environment variable is needed to disable the secure attribute for HTTP cookies. The login feature is broken when Hoppscotch is installed locally or on servers without SSL, as there are use cases where security isn't a major concern.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

When I set the authorization type of a collection to OAuth2 for example, it will also set for each request the authorization type to OAuth2.

I believe this should instead be set to inherit for each request. This way when I send a request it will use the token defined at the scope of the collection so I don't have to connect with OAuth2 for each endpoint.

### Why should this be worked on?

This would save a lot of time to not enter manually the authorization type to inherit for each request.
Ambiguous terms: should, believe, instead, a lot
Questions:
1. What is the current behavior when setting the authorization type of a collection to OAuth2?
2. How is the authorization type currently handled for each request within the collection?
Clarified requirement: This change would save time by automatically setting the authorization type to inherit for each request, avoiding the need to manually enter it.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Currently the entire body can by imported from a file, the body might contain variables which is very good in case the body is fairly static, but some parts are variable.

Variables currently allows fairly small amount of data only. You cannot import a file into them. So it is not possible to add a larger file into a body this way.

Proposal would be to allow a file type variable, which would be a file picker, content not saved. So in order to use the request you need to provide a file first and then the body is composed as today.

### Why should this be worked on?

Requests like file upload could be added more easily.
Ambiguous terms: fairly, small, larger, easily
Questions:
1. What type of data is considered "fairly small" for the variables currently allowed?
2. Can you clarify what "easily" means in the context of adding file upload requests?
Clarified requirement: This change would simplify the addition of file upload requests."


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hello I'm using the desktop app on a Windows machine, but the c drive will be reset every time I log out, I do have persistent drives but the install is going to be done to c drive. I think it would be useful to be able to specify the user data directory.

In postman there is a argument you can pass to the exe `--user-data-dir=<some/path>` (more of a electron side effect than anything postman supports, I think). This store everything that would be stored in `%AppDataLocal%` into the passed directory. Reinstalling is something given that I would have to do but this makes it so that i can pass the same path and get the same workspace.

### Why should this be worked on?

I think this will be useful for anyone that uses a computer with a non persistent home drive. Also makes the app more portable I think.
Ambiguous terms: useful, portable
Questions:
1. What specific issue is the user experiencing with the c drive being reset?
2. How does specifying the user data directory make the app more portable?
Clarified requirement: Check if there is an existing issue related to the c drive being reset every time the user logs out. The user suggests adding the ability to specify a user data directory in the desktop app on Windows to store data persistently, similar to how it is done in Postman with the `--user-data-dir=<some/path>` argument. This feature would benefit users with non-persistent home drives and make the app more portable.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

The response to that request is also saved in the history
<img width="1386" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/49194769/f58a7682-f776-4677-bc9d-70a66e064444">
Retain the response content and the corresponding status code, time, and size
<img width="997" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/49194769/2bdb137c-d7af-4702-97e7-64344b312dc0">



### Why should this be worked on?

It is very convenient to view the content of a requested interface in the history without having to request the result again, especially when the interface is updated frequently, or when the request interface takes a little longer
Of course, Since I can tie in an account, I'm not sure if the data will be stored in the cloud,There may be privacy concerns, so you can set the switch for this feature, let the user choose whether to save the data
Ambiguous terms: convenient, frequently, little longer, privacy concerns, user choose
Questions:
1. What specific data should be retained in the history for the response to a request?
2. How should the switch for saving data be implemented for user choice?
Clarified requirement: Is there an existing issue for this? The response to a request should be saved in the history, including the response content, status code, time, and size. The user should be able to choose whether to save the data, with a switch implemented for this feature.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

A stand alone docker image should be published with just the CLI and it's depedencies so that collections can more easily be run as part of CI/CD processes.

### Why should this be worked on?

The CLI will most likely be heavily used in automated processes so a self contained solution is nice to have.
Ambiguous terms: stand alone, easily, automated, nice to have
Questions:
1. What specific dependencies should be included in the stand alone docker image?
2. Can you provide an example of the automated processes where the CLI will be heavily used?
Clarified requirement: Is there an existing issue for this? A stand alone docker image should be published with just the CLI and its specified dependencies to facilitate running collections as part of CI/CD processes. The CLI is expected to be utilized in automated processes, hence a self-contained solution is preferred.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

In the desktop version there is the option to manage cookies at the bottom left. The web app does not have this option, also as stated in the documentation (https://docs.hoppscotch.io/documentation/features/cookies). As mentioned in #1383, there is probably no reason for this if the proxy or extension is in use.

Please implement this in the web app as well.

### Why should this be worked on?

There is no pleasant way to work with cookies in the web app. This means that collaboration on APIs that work with short-lived tokens in cookies is not possible.
Ambiguous terms: pleasant, collaboration, short-lived
Questions:
1. What specific functionality related to managing cookies is missing in the web app compared to the desktop version?
2. Can you clarify what is meant by "collaboration on APIs that work with short-lived tokens in cookies"?
Clarified requirement: Implement the option to manage cookies in the web app, similar to the functionality available in the desktop version. This is necessary to enable collaboration on APIs that utilize short-lived tokens stored in cookies.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

It'd be really cool if you could use the environment variables in the collection properties.

### Why should this be worked on?

My use case is that I have a collection with a bunch of folders for my work. All of them authenticate in the same way, so instead of having to setup the authorization for all of them. I would like to only set it for the entire collection.
Ambiguous terms: cool, really, bunch, only
Questions:
1. What specific environment variables are being referred to here?
2. Can you clarify what "setting up authorization for the entire collection" entails?
Clarified requirement: Is there an existing issue for utilizing environment variables in the collection properties for setting up authorization across multiple folders within a collection?


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

I prefer thunder-client which can be integrated into vscode, because it is not open source, I am worried about security issues.

https://marketplace.visualstudio.com/items?itemName=rangav.vscode-thunder-client


It would be better if hoppscotch could be integrated into vscode and could save the Request as a file.


<img width="731" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/140048181/435d229b-a230-40da-8157-219ee0cab774">



### Why should this be worked on?

In this way, Request and RESTful api code can be put into a git repository for management.
Ambiguous terms: better, integrated, security issues, better
Questions:
1. What specific concerns about security issues are preventing the preference for thunder-client?
2. When referring to integrating hoppscotch into vscode, what does "save the Request as a file" entail?
Clarified requirement: Determine the security issues related to thunder-client that are causing concern and explore the integration of hoppscotch into vscode to enable saving Requests as files for better management of Request and RESTful api code in a git repository.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Use [jq](https://en.wikipedia.org/wiki/Jq_(programming_language)) instead of [JSONPath](https://en.wikipedia.org/wiki/JSONPath) for filtering JSON.

### Why should this be worked on?

The syntax is more intuitive :

| Action | jq | JSONPath
| -- | -- | --
| Get full data | `.` | `$.`
| Get object property | `.name` | `$.name`
| Get first array item | `.[0]` | `$.[0]`
| Get first array item property | `.[0].name` | `$.[0].name`
| Get first array item subproperty | `.[0].owner.username` | `$.[0].owner.username`
| Filter array by item property | `.[] \| select(.id == 411)` | `$[?(@.id == 411)]`
| Filter array by item subproperty | `.[] \| select(.owner.id == 1)` | `$[?(@.owner.id == 1)]`
| Filter array by item property range | `.[] \| select(.stars_count > 0)` | `$[?(@.stars_count > 0)]`
| Get property of array items filtered by property range | `.[] \| select(.stars_count > 0) \| .name` | `$[?(@.stars_count > 0)].name`
| Sort array items by property | `. \| sort_by(.id)` | Feature missing
| Filter and sort array | `map(select(.stars_count > 0)) \| sort_by(.id)` | Feature missing
| Get property of filtered and sorted array items | `map(select(.stars_count > 0)) \| sort_by(.id) \| .name` | Feature missing
| Filter array by item property via regex | `.[] \| select(.created_at \| test("^202[34]"))` | `$[?(/^202[34]/.test(@.created_at))]`

Etc...

---

Thanks
Ambiguous terms: intuitive, more
Questions:
1. What specific aspects of the syntax make jq more intuitive than JSONPath?
2. How will the transition from JSONPath to jq impact the existing codebase or processes?
Clarified requirement: Evaluate transitioning from using JSONPath to jq for filtering JSON based on the provided syntax comparison chart and reasons for improved intuitiveness.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hello!

With the 2024.3.X onwards we are able to perform OAuth authentication with client credentials. With this feature request, we would like to have an input for additional query parameters in the request URL such as **audience**.  This is an mandatory attribute in many of the authorization flows.

Please check screenshot of Postman client credential setting on how additional parameter is provided for the 

<img width="632" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/88329746/b867b407-7c49-4b27-bdc6-616e83c37266">


### Why should this be worked on?

1) Developers are not able to use Client Credentials authentication due to missing audience
2) Enables more user to Hoppscotch as audience is highly use in many authorization servers.
Ambiguous terms: mandatory, additional, many, more
Questions:
1. What specific query parameters are currently allowed in the request URL?
2. Can you provide an example of how the "audience" parameter is typically used in authorization flows?
Clarified requirement: Is there an existing issue for the lack of support for the "audience" query parameter in the Client Credentials authentication process starting from version 2024.3.X? The feature request aims to allow developers to include additional query parameters, such as "audience," in the request URL to enable successful authorization flows.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

It would be useful if we could manage users via a rest API.

### Why should this be worked on?

e.g. In order to comply with the GDPR, it is necessary to delete users who have left the company after time x. We would like to automate this.
Ambiguous terms: useful, manage, rest API, comply, necessary, automate
Questions:
1. What specific actions fall under "managing users" via a rest API?
2. Can you provide more details on how automating the deletion of users would comply with GDPR?
Clarified requirement: Is there an existing issue for managing users via a rest API? It would be beneficial to automate the deletion of users who have left the company after a specified period to comply with GDPR regulations.


Clarify this requirement: ### Is there an existing issue for this?

- [x] I have searched the existing issues

### Summary

After copying the request, focus directly on the input box for renaming, because it is tedious to modify each point by clicking the rename.

### Why should this be worked on?

Increase efficiency
Ambiguous terms: tedious, efficient
Questions:
1. What specifically needs to be renamed in the input box?
2. How would increasing efficiency benefit the task at hand?
Clarified requirement: To streamline the process and save time.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Hope to increase the ability to scale font size.

<img width="283" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/15964712/b3a465f2-bebe-469b-b488-a5dad9167ce6">

<img width="1920" alt="image" src="https://github.com/hoppscotch/hoppscotch/assets/15964712/85587b0d-de5d-4962-8e7c-16efcc85f0d7">

### Why should this be worked on?

The browser supports font scaling, so it can meet the needs of different people.
Desktop app  default font size is difficult to read on a large screen, which affects the use.
Ambiguous terms: increase, ability, scale, font size, difficult
Questions:
1. What specific aspect of the font size needs to be scaled?
2. Can you provide more details on how the default font size affects the use?
Clarified requirement: Check if there is an existing issue related to adjusting the default font size in the desktop app to improve readability on large screens. The goal is to utilize the browser's font scaling capability to cater to the needs of different users.


Clarify this requirement: ### Is there an existing issue for this?

- [X] I have searched the existing issues

### Summary

Add support for OpenAPI 3.1

### Why should this be worked on?

Starting with OpenAPI 3.1, it is allowed, although discouraged, to have a request body for GET/HEAD/DELETE requests (see https://github.com/OAI/OpenAPI-Specification/pull/2117). Maybe there are other things regarding OpenAPI 3.1 as well.

Currently it complains that the definition is invalid. This is an (valid) example for an OpenAPI 3.1.0 spec:

```
openapi: 3.1.0
info:
  title: Testapi
  version: 1.0.0
paths:
  /api/dummy:
    delete:
      description: delete with body
      responses:
        '204':
          description: Success, No content
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/mydto'
components:
  schemas:
    mydto:
      description: testobject
      required:
        - test
      type: object
      properties:
        test:
          type: string
```
Ambiguous terms: invalid, disallowed, maybe, other things, complains, valid, regarding
Questions:
1. What specific issues are currently being encountered with the OpenAPI 3.1 support?
2. Are there any specific features or functionalities that need to be added to support OpenAPI 3.1?
Clarified requirement: Is there an existing issue with the current OpenAPI 3.1 support that needs to be addressed? The goal is to add support for OpenAPI 3.1, including allowing request bodies for GET/HEAD/DELETE requests as per the OpenAPI 3.1 specifications.


Clarify this requirement: ### Summary

Right now you can create container queries easily by providing a `@` prefixed value as the key in `sx`. You can also use the `containerQueries` helper alongside theme breakpoints on the `theme` object to create an `at rule` by writing `theme.containerQueries.up('sm')`.

### Examples


It'd be convenient to use the built-in theme breakpoint values here. Something like this:

```tsx
<Box
    sx={{
        padding: {
          '@sm': 1,
          '@md': 2,
          '@': 3,
        }
    }}
/>
```
Which would be interpreted as
```tsx
<Box
    sx={{
        padding: {
          '@600': 1,
          '@900': 2,
          '@': 3,
        }
    }}
/>
```

### Motivation

This would streamline creating container query powered styles, as I typically want to use values set by our design system. Right now my approach is verbose in the form of

```tsx
const theme = useTheme();


<Box
    sx={{
        padding: {
          [`@${theme.breakpoints.values.sm}`]: 1,
          [`@${theme.breakpoints.values.md}`]: 2,
          '@': 3,
        }
    }}
/>
```

**Search keywords**: container query, sx, breakpoint
Ambiguous terms: convenient, streamline, typically, verbose
Questions:
1. What does "streamline" refer to in the context of creating container query powered styles?
2. Can you clarify what is meant by "typically want to use values set by our design system"?
Clarified requirement: **Search keywords**: container query, sx, breakpoint


Clarify this requirement: ### Summary

I'm currently using Material UI v6.4.6 with TypeScript, and I have encountered an issue when trying to add a custom color to my palette and use it across various components. While extending the palette interface to include custom keys is straightforward, I find it cumbersome to have to manually extend each component's props (e.g., ButtonPropsColorOverrides, IconButtonPropsColorOverrides, etc.) to accept the custom color for type safty.

### Examples

Create a theme with a custom palette key (e.g., accent).

Attempt to use the custom palette key in a component, such as <Button color="accent" />.

Note the TypeScript error indicating that the accent key is not allowed for the color prop.

```
import { createTheme } from "@mui/material";

declare module "@mui/material/styles" {
  interface Palette {
    accent: Palette["primary"];
  }

  interface PaletteOptions {
    accent?: PaletteOptions["primary"];
  }
}

let muiTheme = createTheme({
  palette: {
    primary: {
      main: "#E7FAFE",
    },
    secondary: {
      main: "#fff",
    },
  },
});

muiTheme = createTheme(muiTheme, {
  palette: {
    accent: muiTheme.palette.augmentColor({
      color: {
        main: "#000",
      },
      name: "accent",
    }),
  },
});

export default muiTheme;

```

[as documantation says](https://mui.com/material-ui/customization/palette/?srsltid=AfmBOorKunLoIRYjpv_2RpUVAtXPUA0EAA-cvZtmAZl5AhtYixaAVkD_#generate-tokens-using-augmentcolor-utility)

### Motivation

I understand that the current workaround involves augmenting the props interface for each individual component, as shown below for the Button component:

```
declare module '@mui/material/Button' {
  interface ButtonPropsColorOverrides {
    accent: true;
  }
}
```

However, this approach is repetitive and error-prone, especially in larger codebases where multiple components need to be extended.

I propose adding support for globally extending all component props to accept custom palette keys. This could be achieved through a single configuration or utility that ensures type safety without needing repetitive manual declarations for each component.

This enhancement would significantly reduce boilerplate code and improve the developer experience, making it easier to maintain and utilize custom palette keys across the entire component library.

Thank you for considering this request. I look forward to any feedback or suggestions from the maintainers and community.

**Search keywords**: Global-Palette,color-Palette,custome-color,type-safety,typescript-custome-color
Ambiguous terms: repetitive, error-prone, larger codebases, enhancement, boilerplate code, developer experience, custom palette keys
Questions:
1. What is the specific issue encountered when trying to add a custom color to the palette and use it across components?
2. How does extending the props interface for each individual component currently impact the development process?
Clarified requirement: The user is using Material UI v6.4.6 with TypeScript and facing difficulties when adding a custom color to the palette and using it across components. They find it cumbersome to manually extend each component's props to accept the custom color for type safety, and propose a solution to globally extend all component props to support custom palette keys efficiently.


Clarify this requirement: ### Steps to reproduce

Steps:
1. Open this link to live example: Take the [current Auto Width](https://mui.com/material-ui/react-select/?srsltid=AfmBOopEEAJ165pIelaL5GB_Km2Zx-nkiEZ89h5TCwxIFGoPzGsN1-hk#auto-width) [Code Sandbox](https://codesandbox.io/embed/hnrgtj?module=/src/Demo.tsx&fontsize=12)
2. Replace the `"Age"` value of the `InputLabel` and the Select's `label` prop with `"A Longer Title Than Usual"`
3. Notice the effects of the change on the component


### Current behavior

![Image](https://github.com/user-attachments/assets/b740de45-6a4b-4374-82de-8b01f30cd62c)
![Image](https://github.com/user-attachments/assets/20c9169a-86ef-4b04-a907-2b76863ace0a)

Notice how the input label (title) gets cropped, both when it acts as content and when it is rendered above the actual input's content.

### Expected behavior

The entire Select should be wide enough to fit the Title, even if the content is shorter.
The final width of the Select should be `max(inputWidth, titleWidth)`. Right now, it appears to only be based on `inputWidth`.

### Context

This issue is a continuation of rjsf-team/react-jsonschema-form#4484.
Finding a solution here will also fix that one.

### Your environment

_No response_

**Search keywords**: select title crop too long fit length style styling input value
Ambiguous terms: wide enough, cropped, shorter, max, based on, too long, fit, length, style, styling
Questions:
1. What does "max(inputWidth, titleWidth)" refer to in this context?
2. Can you clarify what is meant by "Finding a solution here will also fix that one"?
Clarified requirement: **Search keywords**: select title crop too long fit length style styling input value"


Clarify this requirement: ### Steps to reproduce

Steps:
1. Open this link to live example: [Link](https://stackblitz.com/edit/react-ovaj89h7?file=Demo.tsx)
2. Click select indicator icon


### Current behavior

When endAdornment is set, the menu does not appear when you click the open/close icon in select. But it does have focus.

### Expected behavior

The menu should open or close when you click the open/close icon in any case.

### Context

This is very important for the user experience. Almost all users click on that icon to open the menu.

### Your environment

<details>
  <summary><code>mui/material v6.4.3</code></summary>
</details>


**Search keywords**: select, endAdornment, indicator
Ambiguous terms: fast, user-friendly, important, almost, all
Questions:
1. What is the specific issue with the menu not appearing when clicking the open/close icon?
2. Can you clarify what you mean by "endAdornment" in this context?
Clarified requirement: **Search keywords**: select, endAdornment, indicator


Clarify this requirement: ### Summary

There are various ways to present a list of options to users, each with its own use case. Some common choices include Autocomplete, Select, Radio Group, Checkbox Group, Button Group, and Tabs. While they serve different purposes, they all ultimately allow users to make a selection from a given list.

To improve the developer experience, I’d love to see a more consistent API across these components. For now, I want to focus on two key differences, though this idea could be extended further.

#### Standardized API for Options
Currently, different components handle options inconsistently. For example, Autocomplete accepts an `options` prop along with `getOptionKey` and `getOptionLabel`, while `Select` requires its options to be passed as `MenuItem` children. Instead, all these components—Autocomplete, Select, Radio Group, Checkbox Group, Button Group, and Tabs—should support a unified API with `options`, `getOptionKey`, `getOptionValue`, and `renderOption`. This would streamline usage and improve maintainability.

#### Flexible Value Handling
Another inconsistency lies in how selected values are managed. In a Select component, the value is just the key of the selected option. However, an Autocomplete requires the entire object. In real-world forms, relationships between data often require pre-filling fields with default values, which can mean fetching additional data just to display an Autocomplete's value properly. To address this, these components should support both approaches:
- One mode where they accept and return the entire object (`onChange` provides the full option, and default values must be full objects).
- Another mode where they work solely with keys (`onChange` returns only the key, and default values can be set with just the key).

Standardizing these aspects would make working with these components far more intuitive and flexible across different use cases.

**Search keywords**: select,autocomplete,tabs,groups
Ambiguous terms: consistent, streamline, flexible, intuitive
Questions:
1. What are the specific key differences that the developer wants to focus on initially?
2. Can you provide examples of how the current API for options handling differs across the components?
Clarified requirement: There is a need for a more consistent API across components such as Autocomplete, Select, Radio Group, Checkbox Group, Button Group, and Tabs. This involves standardizing the handling of options by implementing a unified API with `options`, `getOptionKey`, `getOptionValue`, and `renderOption`. Additionally, there should be support for both returning the entire object and just the key when managing selected values in these components.


Clarify this requirement: ### Summary

Currently in order to integrate other framework `Link` components into mui (globally) we can use

``` js
export const theme = createTheme({
  components: {
    MuiLink: {
      defaultProps: {
        component: Link,
      },
    },
  }
});
```

but we can't type this correctly witht what is provided for us. Other solutions are creating a custom `Link` component and type the props ourselves.

This would be much simpler if we could do something like:

``` ts
import type NextLink from "next/link";

declare module "@mui/material/Link" {
  export interface LinkComponentOverride {
    component: typeof NextLink;
  }
}

export {};
```

### Examples

_No response_

### Motivation

_No response_

**Search keywords**: link typeoverrides
Ambiguous terms: correctly, simpler, much
Questions:
1. What specifically makes it difficult to type the provided code correctly?
2. Can you clarify what you mean by "simpler" in this context?
Clarified requirement: **Search keywords**: link typeoverrides


Clarify this requirement: ### Steps to reproduce

I have a MuiButton which has a startIcon. The generated code is

```
Button.MuiButtonBase-root
  span.MuiButton-icon
      svg.MuiSvgIcon-root
```

Now in the createTheme component options i set `MuiButton` font-size to 1rem and all sizes of `MuiSvgIcon` to their specific rem

But the button (actually the span.MuiButton-icon) adds this class:

```
.css-UNIQUE > :nth-of-type(1) {
    font-size: 18px;
}
```

While i defined the font-size on Button level and Icon on Icon level. Which is perfect and when i remove the injected extra class it all looks correct. Now i have to overrule this `:nth-of-type(1)` for each button size and then it wins from the still added font size.

I think this is a bug in the deepmerge functionality. Because how do you want me to just remove the cullprit from the component declaration instead of adding lots of selectors to win. It would be great if i can unset things, certainly when moving to a rem based setup.


### Current behavior

Button component adds specific css for the font for the icon by default.
No way to get rid of this during construction of the component with createTheme

I like MUI is having defaults, but it should be nicer to get rid of these when you implicitly want to do so (i see some implementations using `unset` for example).

### Expected behavior

I hoped just like other systems like Chakra that i can remove particular default settings.
so when i set this `'> :nth-of-type(1)': undefined|null` on theme creation it would remove it :)

### Context

We are moving to rems. Now lots of MUI is in pixels, and lots of these are not as we design them. So i endup with lots of extra classes (have to import this from every component being used in a mui component which highly couples the structure mui is using with zero guarentees for the future) to just win while the wrapper in most cases was already fine to begin with. So lots of extra code to maintain.

It would be great if i can remove defaults. So its not a variant or override.

### Your environment

its with every mui version, not particular to a single version, lets say im using latest (which i do) :)


**Search keywords**: merge, style override
Ambiguous terms: bug, nicer, get rid of, remove, unset, particular default settings
Questions:
1. What specific behavior is causing the issue with the font size in the Button component?
2. How does the deepmerge functionality relate to the problem described in the requirement?
Clarified requirement: I have a MuiButton with a startIcon. The issue arises when the Button component adds specific CSS for the font size of the icon by default, even after setting font sizes in the createTheme component options. This behavior seems to be related to the deepmerge functionality. The goal is to have the ability to remove or unset specific default settings, such as the font size added by the Button component, without the need to add additional selectors to override them.


Clarify this requirement: ### Steps to reproduce

Steps:
1. Open this link to live example: [(MUI Card Docs)](https://mui.com/material-ui/react-card/#primary-action)
2. Open developer tools
3. Make sure that tag `<div>` is placed inside a tag `<button>`, which does not comply to HTML5's specification

Problem:
http://www.w3.org/TR/2012/WD-html5-20120329/the-button-element.html#the-button-element says that a `<button>` must contain only Phrasing content. Phrasing content is defined as including `<span>` but not `<div>`.

![Image](https://github.com/user-attachments/assets/8b8ff7e6-d0af-42ee-9a7c-4b922cf71702)


### Current behavior

`<CardActionArea>` when rendered becomes a `<button>` tag. If you add anything inside of it, e.g. `<CardContent>` or `<Box>`, it will happen that after rendering, you'll end up with a `<button>` tag, that has `<div>` inside of it.

### Expected behavior

All components from MUI should follow HTML5's validation rules, including `<CardActionArea>`.

### Context

I was using MUI's `<Card>` component, which had a `<CardActionArea>` component inside of it, with child components, such as `<CardHeader>` and `<CardContent>`, then I published my website to the server and tried to check for any HTML validation errors on https://validator.w3.org, which showed me errors related to `<Card>` component from MUI.

![Image](https://github.com/user-attachments/assets/479572ba-3532-49be-93d0-77605c79f6f5)

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  System:
    OS: Windows 11 10.0.22631
  Binaries:
    Node: 20.18.0 - C:\Program Files\nodejs\node.EXE
    npm: 9.6.6 - C:\Program Files\nodejs\npm.CMD
    pnpm: Not Found
  Browsers:
    Chrome: Not Found
    Edge: Chromium (127.0.2651.74)
  npmPackages:
    @emotion/react: ^11.13.3 => 11.14.0
    @emotion/styled: ^11.13.0 => 11.14.0
    @mui/base:  5.0.0-beta.69
    @mui/core-downloads-tracker:  6.4.1
    @mui/icons-material: ^6.1.3 => 6.4.1
    @mui/lab: ^6.0.0-beta.22 => 6.0.0-beta.24
    @mui/material: ^6.1.3 => 6.4.1
    @mui/private-theming:  6.4.1
    @mui/styled-engine:  6.4.0
    @mui/system:  6.4.1
    @mui/types:  7.2.21
    @mui/utils:  6.4.1
    @types/react: ^18.3.11 => 18.3.18
    react: ^18.3.1 => 18.3.1
    react-dom: ^18.3.1 => 18.3.1
    typescript: ^5.7.3 => 5.7.3
```
</details>


**Search keywords**: W3C CardActionArea Card HTML5 SEO
Ambiguous terms: should, fast, user-friendly, make sure, comply, validation, errors, check
Questions:
1. What specific validation errors related to the `<Card>` component from MUI were shown on https://validator.w3.org?
2. Can you provide more details on how the `<CardActionArea>` component is related to the validation issues?
Clarified requirement: 3. Verify that the `<Card>` component from MUI, particularly the `<CardActionArea>` component, complies with HTML5's validation rules, ensuring that no `<div>` elements are placed inside a `<button>` element.


Clarify this requirement: ### Steps to reproduce

Steps:
1. There is no link because it is exist on mui.com documentation pages. But I will provide simple steps to reproduce.
2. PLEASE, BE CAREFUL. This behavior could negatively impact individuals who are sensitive to rapid changes in screen brightness, such as those with photosensitivity or other visual sensitivities. So don't try to reproduce it if you have high sensitivity for that.
3. At first open Dark mode documentation page https://mui.com/material-ui/customization/dark-mode/#toggling-color-mode
4. Then open these 4 tabs in the same browser. 
- https://mui.com/material-ui/customization/css-theme-variables/configuration/
- https://mui.com/material-ui/react-drawer/
- https://mui.com/material-ui/react-app-bar/#app-bar-with-responsive-menu
- https://mui.com/material-ui/customization/breakpoints/
5. On Dark mode page start quickly change light mode to dark and vise versa 
https://mui.com/material-ui/customization/dark-mode/#toggling-color-mode
6. Then stop clicking and see how modes switches by their own without any additional interaction.
7. To stop those infinite mode changing, just close all tabs and leave one of them.


### Current behavior

When more than 4 tabs opened, frequent theme mode changing starts infinite mode changing between all tabs.  

### Expected behavior

When user change theme modes, mode is changes only once user clicked.

### Context

This is crucial to take a look, because such behavior may impact on people feeling which have problems while look at frequently changing screens from dark to light.
I think this is because the tabs synchronize data about the active mode of the theme. Because after closing the tabs, the problem disappears. Apparently, the tabs react to changes from other tabs asynchronously and at the same time send these changes to other tabs. And because of this event, the changes run back and forth

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  Don't forget to mention which browser you used.
  Output from `npx @mui/envinfo` goes here.
```
</details>


**Search keywords**: theme, mode, flickering, infinite
Ambiguous terms: quickly, frequent, infinite, flickering, rapid
Questions:
1. What is meant by "quickly change light mode to dark and vise versa"?
2. Can you clarify what is meant by "infinite mode changing"?
Clarified requirement: **Search keywords**: theme, mode, flickering, infinite


Clarify this requirement: ### Summary

This should be supported out of the box:

```js
const theme = createTheme({});

const StyledButton = styled('button')`
  ${theme.applyStyles(
    'dark', `
      background: white;
    `
  )}
`;
```

But it's not because `theme.applyStyles` returns an object. The current workaround is to override `applyStyles`.

### Motivation

Taken from https://github.com/mui/material-ui/issues/44488

**Search keywords**: applyStyles template literals
Ambiguous terms: out of the box, workaround
Questions:
1. What does it mean for something to be "supported out of the box" in this context?
2. Can you provide more clarity on what is meant by "override `applyStyles`"?
Clarified requirement: **Search keywords**: applyStyles template literals"


Clarify this requirement: ### Steps to reproduce

Steps:
1. Add an `Autocomplete` component with `multiple={true}` and `disableClearable={false}`.
2. Add values
3. Press the clear button


### Current behavior

When `onChange` is called you get:
• `event = {...}`
• `value = []`
• `reason = 'clear'`
• `details = undefined`

### Expected behavior

When `onChange` is called you get:
• `event = {...}`
• `value = []`
• `reason = 'clear'`
• `details = { option: [...clearedValues] }`

### Context

When you have an `Autocomplete` with `multiple` and not `disableClearable` and you:
1. Select an option (op5) you get:
	• `event = {...}`
	• `value = [op1, op2, op5]`
	• `reason = 'selectOption'`
	• `details = { option: op5 }`
2. Remove an option (op5) you get:
	• `event = {...}`
	• `value = [op1, op2]`
	• `reason = 'removeOption'`
	• `details = { option: op5 }`

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  System:
    OS: Windows 10 10.0.19045
  Binaries:
    Node: 18.20.3 - C:\Program Files\nodejs\node.EXE
    npm: 10.9.0 - C:\Program Files\nodejs\npm.CMD   
    pnpm: 8.14.0 - C:\Program Files\nodejs\pnpm.CMD 
  Browsers:
    Chrome: Not Found
    Edge: Chromium (131.0.2903.51)
  npmPackages:
    @emotion/react: ^11.13.3 => 11.13.3
    @emotion/styled: ^11.13.0 => 11.13.0
    @mui/base:  5.0.0-beta.40
    @mui/core-downloads-tracker:  6.1.7
    @mui/icons-material: ^6.1.7 => 6.1.7
    @mui/lab:  5.0.0-alpha.173
    @mui/material: ^6.1.7 => 6.1.7
    @mui/private-theming:  5.16.6
    @mui/styled-engine:  5.16.6
    @mui/system:  5.16.7
    @mui/types:  7.2.19
    @mui/utils:  5.16.6
    @types/react:  18.3.12
    react: ^18.3.1 => 18.3.1
    react-dom: ^18.3.1 => 18.3.1
    typescript:  4.9.5
```
</details>

 I use Chrome: Version 131.0.6778.86 (Official Build) (64-bit)

**Search keywords**: multiple onChange reason clear details disableClearable
Ambiguous terms: clear, option, selectOption, removeOption
Questions:
1. What does the term "clear" refer to in the context of the Autocomplete component?
2. Can you provide more clarity on the distinction between "selectOption" and "removeOption"?
Clarified requirement: • `details = { option: op5 }`


Clarify this requirement: ### Steps to reproduce

Steps:
1. Open this link to live example: https://codesandbox.io/p/sandbox/q649qz
2. Open console to see logs
3. Click into the select box
4. Click off the select box
5. Click off the select box again


### Current behavior

On the initial focus, onFocus is called 4 times. On initial blur, onFocus is called 2 more times and onBlur is not called. On second blur, onBlur is called.

### Expected behavior

On initial focus, onFocus should be called once and not again until component is blurred and refocused. onBlur should be called when input is initially blurred.

### Context

I have a code associated to with onFocus event that is being called 4 times when I expect it to be called once.

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  Don't forget to mention which browser you used.
  Output from `npx @mui/envinfo` goes here.
```
</details>


**Search keywords**: mui select onfocus multiple times
Ambiguous terms: once, multiple times
Questions:
1. What specific behavior triggers the onFocus event to be called multiple times?
2. Can you clarify what you mean by "initial blur" and "second blur"?
Clarified requirement: **Search keywords**: mui select onFocus multiple times"


Clarify this requirement: ### Steps to reproduce

Here are 4 focused inputs:

![image](https://github.com/user-attachments/assets/faf3d8fb-2516-49b6-96d0-292ee6598568)

1. Outlined input as seen on https://mui.com/material-ui/react-text-field/

This input's styles have 
```
transform: translate(14px, -9px) scale(0.75);
```
by default.

2. Same input, but I've set
```
transform: translate(15px, -9px) scale(0.75);
```

Just comparing input 1 and input 2, to my eye, the "margin" where there is no border looks more even in the version 2 than in the version 1. But, we can check that if we see where the "margin" comes from

3. Input 1, but with `fieldset` set to `visibility: visible` and label inside to `opacity: 1`, the white text is the aria label that also serves, thanks to it's padding, to create this "magin" in the border.

4. Input 2, but with fieldset visible.

It is quite clear in inputs 3 and 4 that the label is misaligned to the `fieldset`.  The version in 4th is still not quite 100% there, but it's much less than a pixel off, so I'm not sure what can be done about it.

In order to fix the mismatch either the fieldset invisible version must be moved, or the visible version must be moved. 

If the transtion is to be changed, here it is:
(but don't forget about the non-focused versions)

https://github.com/mui/material-ui/blob/412dcbf9d54b29d85353f1ff9947a78beb6ed7c1/packages/mui-material/src/InputLabel/InputLabel.js#L169

Another option is to change the NotchedOutline here:

https://github.com/mui/material-ui/blob/412dcbf9d54b29d85353f1ff9947a78beb6ed7c1/packages/mui-material/src/OutlinedInput/NotchedOutline.js#L16

from `padding: 0 8px` to `padding: 0 7px`, because 1px of horizontal size is provided by the border anyway. I think this is actually the most correct change.

**Search keywords**: Outlined input label misaligned
Ambiguous terms: clear, quite, much less, not quite, 100%, not sure, can be done
Questions:
1. What specific elements are being referred to as "inputs" in this context?
2. Can you clarify what is meant by the term "misaligned" in relation to the label and fieldset?
Clarified requirement: The steps provide a comparison between two versions of outlined inputs with different transformations and visibility settings. The goal is to address the misalignment between the label and fieldset in both versions by adjusting the fieldset's visibility or the NotchedOutline's padding.


Clarify this requirement: ### Summary

Currently, MUI does not allow overriding the `Shadows` without augmenting the interface.
24 values are quite a lot to choose from. In our use case, we are okay with 3 values.

Since the current `Shadows` does not allow overrides unless you override the whole list of 24 values.
It would be beneficial to have a way of turning off the values that are not used.

### Examples

For example, in the `Typography` component, we override the `variants` and disable them via the `TypographyPropsVariantOverrides` interface. 

See the docs [Adding & disabling variants](https://mui.com/system/typography/#adding-amp-disabling-variants). This functionality could be extended to the `Shadows`.

### Motivation

The use case varies across different applications. However, the chances that a design system will have 24 shadow values are almost zero. In our design system, we agreed to have 2 to 3 shadow values.

Hence, being able to disable the ones that are not used is beneficial. 

My suggestion is a bit related to this: https://github.com/mui/material-ui/issues/28820, but not the same thing.

**Search keywords**: shadow overrides
Ambiguous terms: beneficial, almost zero, bit related
Questions:
1. What specific functionality is being requested to be added to the Shadows component?
2. How would the user indicate which shadow values to disable?
Clarified requirement: Currently, there is a need for the Shadows component in MUI to have the ability to disable unused shadow values. This functionality should allow users to specify which shadow values to turn off.


Clarify this requirement: ### Steps to reproduce

Link to live example: https://codesandbox.io/p/sandbox/still-snow-z385rn

Steps:
1. Add a tabs component with more tabs then the view width can hold
2.  scrollButtons="auto"
3. set the selected tab to a tab outside the view
4. refresh the view an see that the selected tab is only partly in view

Make sure to set browser width smaller then the tabs container.

<img width="699" alt="Screenshot 2024-10-25 at 11 18 35" src="https://github.com/user-attachments/assets/f5fd27b8-5969-485d-8303-8f1aeaff07a8">

You can here see a small green line and the tab is not in view.

With scrollButtons={true} it works

### Current behavior

The selected tab is not in view.

<img width="613" alt="Screenshot 2024-10-25 at 11 10 38" src="https://github.com/user-attachments/assets/70fefd9b-ad12-4eea-bc07-7979fee544ba">


### Expected behavior

The selected tab is in view.

<img width="487" alt="Screenshot 2024-10-25 at 11 11 11" src="https://github.com/user-attachments/assets/d2cc81d3-7bff-41e1-983f-5943aa62836d">


### Context

We have dynamic tabs and device sizes, and we dont want arrows all the time, but not scrolling the selected tab into view is causing out users to be confused, would be nice if the tabs component scrolled to the selected tab

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  Browser: Chrome
  System:
    OS: macOS 14.7
  Binaries:
    Node: 20.13.1 - ~/.nvm/versions/node/v20.13.1/bin/node
    npm: 10.5.2 - ~/.nvm/versions/node/v20.13.1/bin/npm
    pnpm: 9.12.2 - ~/.nvm/versions/node/v20.13.1/bin/pnpm
  Browsers:
    Chrome: 130.0.6723.70
    Edge: Not Found
    Safari: 18.0.1
  npmPackages:
    @emotion/react: 11.10.4 => 11.10.4
    @emotion/styled: 11.10.4 => 11.10.4
    @mui/icons-material: 5.16.7 => 5.16.7
    @mui/lab: 5.0.0-alpha.173 => 5.0.0-alpha.173
    @mui/material: 5.16.7 => 5.16.7
    @mui/styles: 5.16.7 => 5.16.7
    @mui/system: 5.16.7 => 5.16.7
    @mui/x-data-grid-premium: 7.20.0 => 7.20.0
    @mui/x-date-pickers: 6.20.2 => 6.20.2
    @mui/x-date-pickers-pro: 6.20.2 => 6.20.2
    @mui/x-license: 7.20.0 => 7.20.0
    @mui/x-tree-view: 7.20.0 => 7.20.0
    @types/react: 18.3.1 => 18.3.1
    react: 18.3.1 => 18.3.1
    react-dom: 18.3.0 => 18.3.0
    typescript: 4.6.4 => 4.6.4
```
</details>


**Search keywords**: tabs scroll
Ambiguous terms: confused, nice
Questions:
1. What does "refresh the view" entail in this context?
2. Can you clarify the behavior expected when the tabs component scrolls to the selected tab?
Clarified requirement: We have dynamic tabs and device sizes, and we don't want arrows all the time. However, not scrolling the selected tab into view is causing confusion among our users. It would be beneficial if the tabs component automatically scrolled to the selected tab.


Clarify this requirement: ### Steps to reproduce

Link to live example: (required)
Every (+n) avatar on https://mui.com/material-ui/react-avatar/

Steps:
1. Visit the link above.
2. Run the axe Devtools chrome extension accessibility scan on that page.
3. Every (+n) avatar on the page gets flagged as not meeting the contrast ratio (in both light and dark mode, though I have screenshotted light mode for this particular example):
<img width="1690" alt="image" src="https://github.com/user-attachments/assets/4caeb893-4df7-41a2-8cfb-209acce5ee2c">



### Current behavior

Axe devtools highlights all the (+n) avatars, with the message: Element has insufficient color contrast of 1.87 (foreground color: #ffffff, background color: #bdbdbd, font size: 15.0pt (20px), font weight: normal). Expected contrast ratio of 4.5:1

### Expected behavior

The default colors on (+n) avatars should have a high enough contrast ratio to pass the accessibility scan.

### Context

I am trying to fix accessibility issues on my site, and while I could override the avatar colors on my own, it seems worthwhile to make the default colors pass accessibility tests out of the box.

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  System:
    OS: macOS 12.7.6
  Binaries:
    Node: 20.11.0 - ~/.nvm/versions/node/v20.11.0/bin/node
    npm: 10.2.4 - ~/.nvm/versions/node/v20.11.0/bin/npm
    pnpm: Not Found
  Browsers:
    Chrome: 130.0.6723.59
```
</details>

This bug is likely system agnostic though since it is a default colors accessibility issue that can be seen on the mui website.

**Search keywords**: avatargroup default colors accessibility
Ambiguous terms: high enough, default, worthwhile, pass, out of the box
Questions:
1. What does the term "default colors" refer to in the context of the avatars?
2. Can you specify what you mean by "high enough contrast ratio" for the avatars?
Clarified requirement: Check every avatar on https://mui.com/material-ui/react-avatar/ for insufficient color contrast during an accessibility scan. The avatars should meet a contrast ratio of 4.5:1 in both light and dark modes.


Clarify this requirement: ### Steps to reproduce

The props passed through renderInput use the old API InputProps and InputLabelProps.

![image](https://github.com/user-attachments/assets/dcb78273-8ab8-4659-8930-bc8eeca9f13d)
![image](https://github.com/user-attachments/assets/a53ebb02-f39a-4fe4-ba24-24f73d454596)


### Current behavior

_No response_

### Expected behavior

_No response_

### Context

_No response_

### Your environment

<details>
  System:
    OS: Windows 11 10.0.22621
  Binaries:
    Node: 20.17.0 - C:\Program Files\nodejs\node.EXE
    npm: 9.8.1 - C:\Program Files\nodejs\npm.CMD
    pnpm: 9.9.0 - C:\Program Files\nodejs\pnpm.CMD
  Browsers:
    Chrome: Not Found
    Edge: Chromium (127.0.2651.74)
  npmPackages:
    @emotion/react: ^11.11.4 => 11.13.3
    @emotion/styled: ^11.11.5 => 11.13.0
    @mui/icons-material: ^6.1.3 => 6.1.3
    @mui/lab: 6.0.0-beta.11 => 6.0.0-beta.11
    @mui/material: ^6.1.3 => 6.1.3
    @mui/material-nextjs: ^6.1.3 => 6.1.3
    @mui/styled-engine-sc: ^6.1.3 => 6.1.3
    @mui/system: ^6.1.3 => 6.1.3
    @mui/utils: ^6.1.3 => 6.1.3
    @mui/x-data-grid-pro: ^7.20.0 => 7.20.0
    @mui/x-date-pickers: ^7.20.0 => 7.20.0
    @mui/x-date-pickers-pro: ^7.20.0 => 7.20.0
    @mui/x-license: ^7.20.0 => 7.20.0
    @types/react: ^18.2.66 => 18.3.5
    react: ^18.2.0 => 18.3.1
    react-dom: ^18.2.0 => 18.3.1
    typescript: ^5.2.2 => 5.5.4
</details>


**Search keywords**: autocomplete, api
Ambiguous terms: old, API
Questions:
1. What specifically is meant by "the old API InputProps and InputLabelProps"?
2. Are there any specific issues or errors encountered when using the props passed through renderInput?
Clarified requirement: The props passed through renderInput should utilize the previous version of the API for InputProps and InputLabelProps.


Clarify this requirement: ### Steps to reproduce

- [ ] 1. We use Google Font to load some of the font of the docs:
https://github.com/mui/material-ui/blob/a4876336bedd35d342a83eb081b0c1fc456b2339/docs/pages/_document.js#L81

However, this doesn't seem to be a best practice, see https://www.debugbear.com/blog/website-font-performance#self-host-your-web-fonts for why. The problem really boils down to having to make a CSS network request to then be able to load the font. Since 2021, all browsers have implemented [cache partitioning](https://developers.google.com/web/updates/2020/10/http-cache-partitioning), so there are no more CDN performance benefits.

- [ ] 2. We should likely warn about this problem in the docs, e.g. https://mui.com/material-ui/react-typography/#google-web-fonts is nice when you want a quick and easy way to test stuff, e.g. for bug reproductions, visual regression tests environment, but not really for production.

There is a reason why https://nextjs.org/docs/app/building-your-application/optimizing/fonts and https://docs.astro.build/en/guides/fonts/ don't mention it.

- [ ] 3. We are missing the correct font fallback. Either we should use something like https://nextjs.org/docs/app/building-your-application/optimizing/fonts or set font-display: fallback https://web.dev/articles/font-best-practices#choose_an_appropriate_font-display_strategy to be coherence.

For example, compare https://dashboard.tremor.so/overview load to https://mui.com/material-ui/getting-started/templates/dashboard/. What we do is not at the quality level, we need to set.
Ambiguous terms: best practice, likely, nice, quality level
Questions:
1. What specific issues arise from using Google Font in the current setup?
2. What criteria define the quality level that needs to be achieved in setting the correct font fallback?
Clarified requirement: - [ ] 3. Implement the correct font fallback strategy, either by following guidelines from resources like nextjs.org or setting font-display to "fallback" for coherence. The quality level should match that of https://dashboard.tremor.so/overview.


Clarify this requirement: ### Steps to reproduce

Link to live example: (required)
https://codesandbox.io/p/sandbox/quirky-layout-lm4ktv?file=%2Fsrc%2FApp.tsx%3A15%2C1-16%2C1

Steps:
1. be sure to run in a wide space, with some width to spare, as if the viewport is narrow the effect will not be evident.
2. click "show textfield"

### Current behavior

the grid automatically expands iteratively (not my code, lib's) until it reaches the limit of the dialog.

This doesn't happen if only the textfield or only the datagrid are displayed.
The behavior is triggered the moment that both are visible.

### Expected behavior

Width of the dialog should be max(width_of_textfield, width_of_datagrid)

### Context

i have dynamic forms inside dialogs.
i don't want to workaround capping the dialog's width, because the content is dynamically decided and i may have other components that need more space, so the dialog will widen legitimately.

### Your environment

can't run npx as it's codesandbox, but this is on my machine
<details>
  <summary><code>npx @mui/envinfo</code></summary>
```
  System:
    OS: macOS 14.6.1
  Binaries:
    Node: 18.17.1 - /usr/local/bin/node
    npm: 9.6.7 - /usr/local/bin/npm
    pnpm: 8.14.3 - /opt/homebrew/bin/pnpm
  Browsers:
    Chrome: Not Found
    Edge: 128.0.2739.67
    Safari: 17.6
  npmPackages:
    @emotion/react:  11.11.3 
    @emotion/styled:  11.11.0 
    @mui/base:  5.0.0-beta.40 
    @mui/core-downloads-tracker:  5.15.19 
    @mui/icons-material:  5.15.19 
    @mui/lab:  5.0.0-alpha.170 
    @mui/material:  5.15.19 
    @mui/private-theming:  5.15.14 
    @mui/styled-engine:  5.15.14 
    @mui/system:  5.15.15 
    @mui/types:  7.2.16 
    @mui/utils:  5.16.6 
    @mui/x-date-pickers:  6.20.1 
    @mui/x-tree-view:  6.17.0 
    @types/react:  18.2.48 
    react:  18.2.0 
    react-dom:  18.2.0 
    typescript:  4.9.5 

```
</details>

**Search keywords**: dialog grid datagrid
Ambiguous terms: wide, evident, automatically, moment, legitimately, more space, dynamic
Questions:
1. What defines a "wide space" in this context?
2. Can you clarify what is meant by "the moment that both are visible"?
Clarified requirement: Dynamic forms are inside dialogs, and the dialog's width should not be capped. Other components may require more space, so the dialog should widen accordingly.


Clarify this requirement: ### Summary

I'm using Material UI for all of my panel icons. I wanted to create a feature called **Export to Excel**. I did not find an icon representing Excel. or spreadsheet in general.

Please add icons for well-known apps. Or if that's not feasible, add icons for well-known app ideas at least.

1. Spreadsheet
2. Presentation
3. Document editor
4. PDF
5. ...

### Examples

_No response_

### Motivation

_No response_

**Search keywords**: excel
Ambiguous terms: well-known, feasible, ideas
Questions:
1. What is meant by "well-known" apps?
2. Can you clarify what is meant by "feasible" in this context?
Clarified requirement: I'm using Material UI for all of my panel icons. I wanted to create a feature called **Export to Excel**. I did not find an icon representing Excel or spreadsheet in general. Please add icons for commonly used applications like Spreadsheet, Presentation, Document editor, PDF, etc. If specific icons for these apps are not available, then icons representing the general ideas of these apps should be added.


Clarify this requirement: > In the future, I think that we want to automatically remove `https://mui.com/` from those links to have relative URLs.

_Originally posted by @oliviertassinari in https://github.com/mui/material-ui/pull/43472#discussion_r1733661761_
            

**Search keywords**:
Ambiguous terms: future, think, automatically, relative
Questions:
1. Can you specify a timeline for when this automatic removal of `https://mui.com/` should occur?
2. What do you mean by "relative URLs" in this context?
Clarified requirement: Remove `https://mui.com/` from the links automatically at a specific future date to convert them to relative URLs.


Clarify this requirement: ### Summary

The default `ActionsComponent` for `TablePagination` is `TablePaginationActions` which renders the page navigation buttons.  If `TablePaginationActions` can accept a custom component as a prop to render between the left navigation and right navigation, `TablePaginationActions` can be used to create a custom Action Component.




### Examples

<img width="522" alt="Screen Shot 2024-08-22 at 1 08 06 PM" src="https://github.com/user-attachments/assets/84754c9b-b07e-43ae-84d4-48ec5683be2a">


### Motivation

We have a design to add a `TextField` between the Left Navigation and Right Navigation to enter the page number.
Currently, there is no way to add this `TextField` component in `TablePaginationActions`. We have to fork the `TablePaginationActions` component and add the `TextField`. 
If MUI can provide a prop to add a component between the left navigation and right navigation in `TablePaginationActions`, we can avoid the fork.

**Search keywords**: TablePaginationActions
Ambiguous terms: custom, user-friendly, custom Action Component
Questions:
1. Can the custom component that can be passed to `TablePaginationActions` be any React component?
2. What specific functionality should the custom component added between the left navigation and right navigation in `TablePaginationActions` provide?
Clarified requirement: **Search keywords**: TablePaginationActions


Clarify this requirement: ### Steps to reproduce

_No response_

### Current behavior

_No response_

### Expected behavior

_No response_

### Context

In this [example](https://mui.com/material-ui/react-menu/#context-menu) context menu should close on mouse key down (on backdrop, not item), not waiting for it's release - this is how all typical context menus (in Windows, Chrome) behave.
Are there any ways to achieve such behavior?

### Your environment

_No response_

**Search keywords**: Menu Context Menu
Ambiguous terms: close, mouse key down, backdrop, release, typical, achieve, behavior
Questions:
1. What is meant by "close on mouse key down (on backdrop, not item)"?
2. Can you clarify what is expected in terms of the context menu behavior?
Clarified requirement: Provide steps to make the context menu close when the mouse button is pressed down on the backdrop (not on an item), similar to how typical context menus in Windows and Chrome behave.


Clarify this requirement: ### Steps to reproduce

Link to live example: https://mui.com/joy-ui/react-circular-progress/#introduction

Steps:
1. Open link on Safari.
2. Zoom in or zoom out.


### Current behavior

1. Progress bar is misaligned 
2. The progress has changed.

<img width="304" alt="스크린샷 2024-08-22 11 21 23" src="https://github.com/user-attachments/assets/18199a32-9928-4524-bc86-05a5761e2b27">


### Expected behavior

1. Progress bar should be centered.
2. The progress should not change.

### Context

I think the misalignment issue is caused by Safari miscalculating the transform and transform origin when zooming.

How about adding the animation to the top layer, like [material-ui's Progress](https://mui.com/material-ui/react-progress)?
I think it would be possible to apply the rotation transform to the parent svg element instead of the circle element, or to split the Progress and Track into two svg elements.

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  Don't forget to mention which browser you used.
  Output from `npx @mui/envinfo` goes here.
```
</details>


**Search keywords**: Circular Progress align
Ambiguous terms: misaligned, centered, change
Questions:
1. What specifically is meant by the progress bar being "misaligned"?
2. Could you clarify what is expected in terms of the progress not changing?
Clarified requirement: **Search keywords**: Circular Progress align


Clarify this requirement: ### Summary

Would like to be able to anchor the collapsed content to the bottom of to container. The effect can be achieved by adding following styles to the `Collapse` but it would be nice to have a prop that can handle this:
```tsx
sx={{
  display: "flex",
  flexDirection: "column-reverse",
}}
```
Perhaps the `direction` prop can even be expanded to account for this use-case. If not accepted, perhaps this use-case could be added to the docs?

### Examples

Here's a codesandbox that displays the desired behavior: https://codesandbox.io/p/sandbox/lucid-heyrovsky-wrjrnp?file=%2Fsrc%2FDemo.tsx%3A47%2C45


https://github.com/user-attachments/assets/9e8f89dc-5d60-4ee6-80f0-ddd286fe6a8a



### Motivation

I struggled a bit with this when building Toolpad component catalog, which feels better when it looks like the drawer is pulled from under the left edge, rather than it being already in place and revealed gradually. Now I'm running into it again with another component.


https://github.com/user-attachments/assets/0398c9c8-7fb3-42df-a94f-ecd53b223b31

vs.

https://github.com/user-attachments/assets/5aa03937-8810-4541-b021-af2caea3d114



**Search keywords**: collapse reverse
Ambiguous terms: nice, expanded, accepted, use-case, bit, better, gradually, struggled, feels, looks like
Questions:
1. What specifically is meant by "this use-case"?
2. Can you clarify what is expected in terms of the "direction" prop?
Clarified requirement: **Search keywords**: collapse reverse


Clarify this requirement: ### Steps to reproduce

Link to live example: [codesandbox](https://codesandbox.io/s/fancy-fast-3cknx2?file=/src/Demo.tsx)

Steps:
1. Assign a dark theme color in the newer syntax using the `rgb` color function, for example `rgb(106 27 154)` 
2. Render a contained button that uses this theme color as its background: `<Button variant="contained">click me</Button>`
3. Observe the text color being dark as well
4. Change the theme color to the legacy syntax with commas: `rgb(106, 27, 154)`
5. Observe the button now having a white contrast text color


### Current behavior

A dark rgb theme color in the new color syntax results in the wrong contrast text being applied:

<img width="127" alt="CleanShot 2024-08-20 at 15 01 32@2x" src="https://github.com/user-attachments/assets/f9095d93-1b02-4f1d-93a4-a7188781f9bf">

I reckon this might affect other areas as well, but I have only identified this behavior for the `Button` component

### Expected behavior

I expect a button with a dark theme color background to have white contrast text:

<img width="127" alt="CleanShot 2024-08-20 at 15 03 31@2x" src="https://github.com/user-attachments/assets/2a7b5d9e-6471-4582-8242-273781c03cf9">


### Context

_No response_

### Your environment

Chrome Version 127.0.6533.120 (Official Build) (arm64)

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
  System:
    OS: macOS 12.4
  Binaries:
    Node: 18.13.0 - ~/.nvm/versions/node/v18.13.0/bin/node
    npm: 8.19.3 - ~/.nvm/versions/node/v18.13.0/bin/npm
    pnpm: Not Found
  Browsers:
    Chrome: 127.0.6533.120
    Edge: Not Found
    Safari: 15.5
  npmPackages:
    @emotion/react:  11.13.0
    @emotion/styled:  11.13.0
    @mui/base:  5.0.0-beta.40
    @mui/core-downloads-tracker:  5.16.6
    @mui/icons-material:  5.16.6
    @mui/lab:  5.0.0-alpha.173
    @mui/material:  5.16.6
    @mui/private-theming:  5.16.6
    @mui/styled-engine:  5.16.6
    @mui/system:  5.16.6
    @mui/types:  7.2.15
    @mui/utils:  5.16.6
    @mui/x-date-pickers:  7.12.0
    @types/react:  18.3.3
    react:  18.3.1
    react-dom:  18.3.1
    styled-components:  6.1.12
    typescript: ^5.5.4 => 5.5.4
```
</details>


**Search keywords**: contrast, comma, rgb
Ambiguous terms: dark, wrong, white, contrast, dark theme color, new color syntax, legacy syntax, dark theme color background
Questions:
1. What is meant by "newer syntax" and "legacy syntax" in the context of assigning a dark theme color?
2. Can you clarify the specific areas where this contrast issue might affect besides the `Button` component?
Clarified requirement: @mui/material:  5.16


Clarify this requirement: ### Summary

Could you export SelectListbox component like AutocompleteListbox component?

### Examples

_No response_

### Motivation

_No response_

**Search keywords**: SelectListbox
Ambiguous terms: export, like
Questions:
1. What specific aspects of the AutocompleteListbox component should be included in the exported SelectListbox component?
2. Are there any specific functionalities or features that need to be matched between the two components?
Clarified requirement: Create an exported SelectListbox component that incorporates specific aspects of the AutocompleteListbox component.


Clarify this requirement: ### Steps to reproduce

Link to live example: (required)

Steps:
1. Run `npx @mui/codemod@next v6.0.0/styled packages` on the latest [`mui-x` master](https://github.com/mui/mui-x) branch
2. Observe multiple (56) errors


### Current behavior

A few example errors:
```
mui/mui-x/packages/x-date-pickers/tsconfig.build.json Transformation error (Missing semicolon. (4:11))
SyntaxError: Missing semicolon. (4:11)
```
```
mui/mui-x/packages/x-license/package.json Transformation error (Missing semicolon. (2:8))
SyntaxError: Missing semicolon. (2:8)
```
```
mui/mui-x/packages/x-date-pickers/src/AdapterLuxon/AdapterLuxon.ts Transformation error (Unexpected token (149:34))
SyntaxError: Unexpected token (149:34)
```
```
mui/mui-x/packages/x-data-grid/src/models/gridColumnGrouping.ts Transformation error (Unexpected token (25:25))
SyntaxError: Unexpected token (25:25)
```

### Expected behavior

Codemod does not produce the above errors, but ignores the code that it does not need to transform.

### Context

_No response_

### Your environment

<details>
  <summary><code>npx @mui/envinfo</code></summary>

```
System:
    OS: macOS 14.5
  Binaries:
    Node: 18.20.2 - ~/.nvm/versions/node/v18.20.2/bin/node
    npm: 10.5.0 - ~/.nvm/versions/node/v18.20.2/bin/npm
    pnpm: 9.6.0 - ~/.nvm/versions/node/v18.20.2/bin/pnpm
  Browsers:
    Chrome: 127.0.6533.89
    Edge: 127.0.2651.86
    Safari: 17.5
  npmPackages:
    @emotion/react: ^11.13.0 => 11.13.0 
    @emotion/styled: ^11.13.0 => 11.13.0 
    @mui/icons-material: ^5.16.5 => 5.16.5 
    @mui/internal-markdown: ^1.0.8 => 1.0.8 
    @mui/internal-test-utils: ^1.0.5 => 1.0.5 
    @mui/material: ^5.16.5 => 5.16.5 
    @mui/monorepo: github:mui/material-ui#4a82b6b0e0395db8fa0a0d49b6b76de4516b1579 => 6.0.0-beta.4 
    @mui/utils: ^5.16.5 => 5.16.5 
    @types/react: ^18.3.3 => 18.3.3 
    react: ^18.3.1 => 18.3.1 
    react-dom: ^18.3.1 => 18.3.1 
    typescript: ^5.5.4 => 5.5.4 
```
</details>


**Search keywords**: codemod, styles
Ambiguous terms: ignores, above, need
Questions:
1. What does "ignores the code that it does not need to transform" specifically mean?
2. Can you clarify what is meant by "above errors"?
Clarified requirement: @mui/icons-material: ^


Clarify this requirement: ### Summary

When an Autocomplete with multiple possible values already has a few options selected, it could end up with very limited space while typing to add a new option. It would be cool if the text input part could be rendered on a new line when overflow starts and/or when there's very limited space to type a query/value.

### Examples

In the example you can see only 4 characters of input are visible.
<img width="767" alt="Screenshot 2024-08-06 at 10 22 23" src="https://github.com/user-attachments/assets/3cccbd44-3bd4-4d45-8160-990a7b770927">


### Motivation

This is useful when writing complex values that prefer context of already written text.

P.S. My company has 10 pro licenses.

**Search keywords**: Autocomplete, multiple
Ambiguous terms: cool, limited, very limited, complex
Questions:
1. What defines the threshold for "very limited space" when typing to add a new option?
2. Can you clarify what is meant by "complex values"?
Clarified requirement: When an Autocomplete with multiple possible values already has a few options selected, the text input part should be rendered on a new line when overflow starts or when there is minimal space available to type a query/value. This feature is particularly useful for writing values that require context from previously written text.


Clarify this requirement: ### Summary

The codebase rely on logic like

https://github.com/mui/material-ui/blob/85a3b55d22570881db6ac1b99181ef79c18fc58d/packages/mui-system/src/colorManipulator/colorManipulator.js#L240

which comes with bundle size. However, CSS Relative Color Syntax (RCS) https://lea.verou.me/specs/#relative-colors-rcs is coming. We will be able to rely on it. This should save bundle size and improve the customization experience as it will be clearer in the Browser devtool inspector tool where the color is coming from.

### Examples

```css
--color-lighterer: oklch(from var(--color) calc(l + 0.2) c h);
--color-alpha-50: oklab(from var(--color) l a b / 50%);
```

On the colorspace we want to use, oklch looks like a solid option: https://www.smashingmagazine.com/2023/08/oklch-color-spaces-gamuts-css/. It has a limit though: https://github.com/w3c/csswg-drafts/issues/9449, to be careful.

To see how this fit with `color-mix(`. 

---

If this is successful, we could also look doing the same for the color contrast utils. Actually, we might even need to consider both problems at the same time. https://lea.verou.me/blog/2024/contrast-color/ is a great dive into the topic. A must read (e.g. APAC vs. legal requirement). 

### Motivation

Is likely part of solving #40104, and #37901. 

**Search keywords**: -
Ambiguous terms: clearer, improve, solid, careful, successful, great, must
Questions:
1. What specific improvements are expected in terms of bundle size and customization experience by relying on CSS Relative Color Syntax (RCS)?
2. How will the utilization of CSS Relative Color Syntax (RCS) impact the current color manipulation logic in the codebase?
Clarified requirement: The codebase currently relies on logic from a specific file for color manipulation, which contributes to the bundle size. By transitioning to CSS Relative Color Syntax (RCS), the goal is to reduce the bundle size, enhance customization experience, and provide clearer visibility of color sources in the Browser devtool inspector tool. This transition should also align with the use of the oklch colorspace, with considerations for its limitations, and explore integrating color contrast utilities. The motivation behind this transition is linked to addressing specific issues identified as #40104 and #37901.


Clarify this requirement: ### Summary

We support two select modes:

- "normal" https://mui.com/material-ui/react-select/#basic-select
- "native" https://mui.com/material-ui/react-select/#native-select

The native select mode is meant to improve the UX on mobile, it's also meant to improve the performance when hitting limits with the "normal" one.

With the introduction of https://developer.chrome.com/blog/new-in-web-ui-io-2024#stylable_select, I wonder:

- Should we adopt this feature for our native select, matching the style of the none native one?
- Do we even need a Base UI select component. A question for Select component owner and maintainers to answer https://www.notion.so/mui-org/Select-31a61434055c498abf0f4a47254242e8

### Motivation

https://github.com/whatwg/html/issues/9799
Ambiguous terms: improve, meant, improve, performance, introduction, wonder, matching, style, need, question
Questions:
1. What specific aspects of the UX are meant to be improved by the native select mode?
2. What limitations are typically encountered with the "normal" select mode that the native mode aims to address?
Clarified requirement: We have two select modes: "normal" and "native". The native mode is designed to enhance mobile UX and improve performance when the "normal" mode reaches its limits. With the new stylable select feature introduced in https://developer.chrome.com/blog/new-in-web-ui-io-2024#stylable_select, we are considering whether to implement this for our native select to match the style of the non-native one. Additionally, there is a question about the necessity of a Base UI select component that the Select component owner and maintainers need to address. This decision is motivated by the discussion in https://github.com/whatwg/html/issues/9799.


Clarify this requirement: ### Steps to reproduce

Link to live example: https://codesandbox.io/s/frosty-snowflake-zjl49r?file=/src/Demo.js

Steps:
1. Take the example in https://github.com/mui/material-ui/pull/43022#discussion_r1687208774 with React 19

```jsx
<Slide direction="up" in={checked} mountOnEnter unmountOnExit>
  <p>sample</p>
  <p>sample</p>
</Slide>
```

2. Toggle the switch

3. Check the errors

<img width="600" alt="SCR-20240801-kkbh" src="https://github.com/user-attachments/assets/06c8af02-f421-4289-a0cd-a14cb4f384ee">

but nothing tells you how to fix it.

### Current behavior

No information on what is wrong.

You could argue that TypeScript will let you know ahead of time, but what if you get the type wrong? At least, from this issue, we can collect upvotes from developers who faced the same challenge.

### Expected behavior

A clear error message.

### Context
 
- On the removal of the propTypes check in React 19: https://github.com/facebook/react/issues/28992.
- Cases of doing error messages not the right way: https://github.com/mui/mui-x/pull/13911, https://github.com/mui/mui-x/pull/12992. It's not a so simple problem to solve.
- The future of prop-types: https://www.notion.so/mui-org/RFC-Discontinue-use-of-prop-types-ea106ba181704688ad70b155919ce4e1
- Possible simple solution with a new helper:

```diff
diff --git a/packages/mui-material/src/Slide/Slide.js b/packages/mui-material/src/Slide/Slide.js
index d669e811d6..f316556579 100644
--- a/packages/mui-material/src/Slide/Slide.js
+++ b/packages/mui-material/src/Slide/Slide.js
@@ -1,6 +1,8 @@
 'use client';
 import * as React from 'react';
 import PropTypes from 'prop-types';
+import getDisplayName from '@mui/utils/getDisplayName';
+import checkPropTypes from 'prop-types/checkPropTypes';
 import { Transition } from 'react-transition-group';
 import chainPropTypes from '@mui/utils/chainPropTypes';
 import HTMLElementType from '@mui/utils/HTMLElementType';
@@ -82,11 +84,20 @@ export function setTranslateValue(direction, node, containerProp) {
   }
 }

+function muiCheckPropTypes(Component, props) {
+  if (process.env.NODE_ENV === 'production') {
+    return;
+  }
+  if (React.version >= '19') {
+    return checkPropTypes(Component.propTypes, props, 'prop', getDisplayName(Component));
+  }
+}
+
 /**
  * The Slide transition is used by the [Drawer](/material-ui/react-drawer/) component.
  * It uses [react-transition-group](https://github.com/reactjs/react-transition-group) internally.
  */
-const Slide = React.forwardRef(function Slide(props, ref) {
+const Slide = React.forwardRef(function SlideIn(props, ref) {
+  if (process.env.NODE_ENV !== 'production') {
+    muiCheckPropTypes(Slide, props);
+  }
+
```

### Your environment

```
    "@emotion/react": "11.13.0",
    "@emotion/styled": "11.13.0",
    "@mui/material": "5.16.6",
    "react": "19.0.0-rc.0",
    "react-dom": "19.0.0-rc.0"
```
Ambiguous terms: clear, simple, right, future, possible
Questions:
1. What specific error messages are expected to be displayed?
2. What is the purpose of the new helper function mentioned in the context?
Clarified requirement: Provide specific error messages to be displayed in the specified scenario and explain the purpose of the new helper function mentioned in the context.


Clarify this requirement: ### ESLint version

v9.26.0

### What problem do you want to solve?

I'm trying out the brilliant [_Bulk Suppression_](https://eslint.org/docs/latest/use/suppressions) feature released in v9.24. It's really promising for legacy codebases, to suppress violations in legacy code while still enabling strict rules on new code. It also helps to keep `eslint-disable` directives only for false positives and for violations that I'm okay with not fixing.

The main downside I've seen so far is that there is no way to **suppress warning-level violations** — from the docs:

> Only rules configured as "error" are suppressed. If a rule is enabled as "warn", ESLint will not suppress the violations.

### What do you think is the correct solution?

I think the bulk suppression feature should simply work for all enabled rules, regardless of `error`/`warn` level.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

My linting config relies heavily on warnings as a way to reduce noise during development. For instance, when I declare a variable, I don't want to see a red squiggle before I've had time to write the code that makes use of it. Yellow squiggles are much less confronting and easier to "tune out".

But once I'm ready to commit/push my code, I want to make sure I'm not adding any new warnings to the codebase, so I always run ESLint with `--max-warnings=0`.

Being able to suppress warnings would be really beneficial for me for the same reason as being able to suppress errors: I currently have over 3000 warnings in the legacy codebase I'm working on; they are all legit, but fixing them is not worth the effort, and if I disable the rules, I don't get warned when I write new code :cry:

In effect, I could pass the number of warnings that I want to suppress via `--max-warnings`, but it's not ideal since one could very well fix a warning in legacy code and introduce a new warning in new code within the same commit... I think the bulk the suppression feature has the same limitation but only on a rule-by-rule basis at least.

_Originally posted by @axelboc in https://github.com/eslint/eslint/discussions/19613_
Ambiguous terms: fast, user-friendly, brilliant, promising, strict, okay, confronting, beneficial, legit, ideal
Questions:
1. What specific feature in ESLint v9.24 are you referring to when mentioning "Bulk Suppression"?
2. Can you clarify what you mean by "suppress warning-level violations"?
Clarified requirement: ESLint version v9.26.0 introduces a Bulk Suppression feature that aims to suppress violations in legacy code while still enabling strict rules on new code. However, the current limitation is that only rules configured as "error" are suppressed, not those configured as "warn." The request is to enhance the Bulk Suppression feature to work for all enabled rules, regardless of their "error" or "warn" level.


Clarify this requirement: ### ESLint version

9.x

### What problem do you want to solve?

We currently use `find-up` to find the closest flat config file.

[empathic](https://github.com/lukeed/empathic) is a much faster alternative (benchmarks in the repo)

we have already migrated to this in various other repos, so it has been well tested. given that we are settling on it across many dev tools, it will also de-dupe increasingly well in future (as it replaces many different `find-*` packages with just one)

### What do you think is the correct solution?

Switch to the faster dependency.

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: faster
Questions:
1. What specific aspect of the dependency makes it faster than the current one?
2. How will switching to the faster dependency impact the overall performance of the tool?
Clarified requirement: Update the ESLint version to 9.x and switch to the `empathic` dependency as it is a faster alternative to the current `find-up` dependency. The goal is to improve performance by utilizing a faster dependency.


Clarify this requirement: ### ESLint version

v9.26.0

### What problem do you want to solve?

ESLint [v9.26.0](https://eslint.org/blog/2025/05/eslint-v9.26.0-released/#mcp-server-integration) introduces a built-in MCP server (#19592), which on its own is a brilliant feature! 👏

However, adding `@modelcontextprotocol/sdk` as a direct dependency of the core library package bloats the dependency graphs of users who don't use the MCP at all.

I noticed this when a seemingly routine `pnpm up` caused a `+600` diff in the `pnpm-lock.yaml`. Sure enough, the culprit was `@modelcontextprotocol/sdk`.[^1]

[^1]: Here are the [declared dependencies](https://github.com/modelcontextprotocol/typescript-sdk/blob/621ccea997bf318ee99c7f64ce19609e838615fa/package.json#L48-L59) in the `package.json`.

### What do you think is the correct solution?

Spin off the MCP server as its own _separate_ CLI package from the core ESLint CLI package.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

As I'd like to minimize the dependency surface of my projects, I consider this to be an essential refactor.
Ambiguous terms: seemingly, routine, brilliant, essential
Questions:
1. What is the purpose of the MCP server introduced in ESLint v9.26.0?
2. How does adding `@modelcontextprotocol/sdk` as a direct dependency affect users who don't use the MCP?
Clarified requirement: Update ESLint v9.26.0 by spinning off the MCP server as its own separate CLI package to reduce the dependency graph bloat caused by adding `@modelcontextprotocol/sdk` as a direct dependency of the core library package.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

Right now we have `npm run test:performance` as a performance tests, however, it gives me inconsistent results when run over time. In most cases, the times increase the more times I run the test even without any changes to the code. This makes it difficult to determine if changes are actually affecting overall performance.

For instance, here are two runs, executed back-to-back on my machine. The median for single-file linting is almost an entire one second longer in the second run then the first, and the median for the multi-file linting is more than two seconds longer.

<details><summary>Run 1</summary>

```shell
$ npm run test:performance

> eslint@9.25.1 test:performance
> node Makefile.js perf


Loading:
  Load performance Run #1:  393.2312ms
  Load performance Run #2:  362.5725ms
  Load performance Run #3:  375.9464ms
  Load performance Run #4:  418.9092ms
  Load performance Run #5:  289.1527ms

  Load Performance median:  375.9464ms


Single File:
  CPU Speed is 2304 with multiplier 13000000
  Performance Run #1:  5141.3512ms
  Performance Run #2:  4238.4965ms
  Performance Run #3:  3736.1255ms
  Performance Run #4:  3756.1516ms
  Performance Run #5:  3902.634ms

  Performance budget ok:  3902.634ms (limit: 5642.361111111111ms)


Multi Files (450 files):
  CPU Speed is 2304 with multiplier 39000000
  Performance Run #1:  10183.0626ms
  Performance Run #2:  9867.0768ms
  Performance Run #3:  10272.8082ms
  Performance Run #4:  10528.0819ms
  Performance Run #5:  12737.2459ms

  Performance budget ok:  10272.8082ms (limit: 16927.083333333332ms)

```
</details>

<details><summary>Run 2</summary>

```shell
$ npm run test:performance

> eslint@9.25.1 test:performance
> node Makefile.js perf


Loading:
  Load performance Run #1:  292.4174ms
  Load performance Run #2:  309.7286ms
  Load performance Run #3:  317.5898ms
  Load performance Run #4:  486.638ms
  Load performance Run #5:  320.4985ms

  Load Performance median:  317.5898ms


Single File:
  CPU Speed is 2304 with multiplier 13000000
  Performance Run #1:  3710.871ms
  Performance Run #2:  3886.6845ms
  Performance Run #3:  4845.4551ms
  Performance Run #4:  5080.1957ms
  Performance Run #5:  4950.8853ms

  Performance budget ok:  4845.4551ms (limit: 5642.361111111111ms)


Multi Files (450 files):
  CPU Speed is 2304 with multiplier 39000000
  Performance Run #1:  12910.4252ms
  Performance Run #2:  12239.1613ms
  Performance Run #3:  12555.3277ms
  Performance Run #4:  13088.5363ms
  Performance Run #5:  12608.6794ms

  Performance budget ok:  12608.6794ms (limit: 16927.083333333332ms)


```

</details>

### What do you think is the correct solution?

I'm not sure. Maybe the perf test should run in a Docker container?

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Looking for a volunteer to dig into this.
Ambiguous terms: difficult, correct, fast, inconsistent, user-friendly
Questions:
1. What specific changes are being made to the ESLint version that might be impacting the performance test results?
2. How is the performance budget being determined and what criteria are used for it?
Clarified requirement: The ESLint version is causing inconsistent results in the performance test `npm run test:performance` over time, making it hard to assess the impact of code changes. The performance test results show increasing times even with no code changes. The median times for single-file and multi-file linting are significantly longer in subsequent runs. The task is to investigate if running the perf test in a Docker container could address this issue.


Clarify this requirement: ### What rule do you want to change?

no-shadow-restricted-names 

### What change do you want to make?

Generate more warnings

### How do you think the change should be implemented?

A new default behavior

### Example code

```js
/*eslint no-shadow-restricted-names: "error"*/

const globalThis = {};

function test(globalThis) {}
```

### What does the rule currently do for this code?

No warnings reported

### What will the rule do after it's changed?

Report shadowing of `globalThis`.

### Participation

- [ ] I am willing to submit a pull request to implement this change.

### Additional comments

Related: https://github.com/eslint/eslint/issues/19658
Ambiguous terms: more, default, new
Questions:
1. What specifically do you mean by "more warnings"?
2. Can you clarify what you mean by "a new default behavior"?
Clarified requirement: Change the `no-shadow-restricted-names` rule to report shadowing of `globalThis` by generating additional warnings with a revised default behavior.


Clarify this requirement: ### ESLint version

9.25.1

### What problem do you want to solve?

Settings is current typed as any record `{ [key: string]: unknown }`, which is totally valid. However, some plugins make use of the settings options pretty extensively (like react, jsx-a11y, perfectionist, etc.).

If the Linter.Settings was an interface type, then every consumer could optionally add a module declaration to the package, and add the plugin's type info into the setting.

Example:

```ts
declare module 'eslint' {
    interface ConfigSettings {
        'jsx-a11y': {
            components: Record<string, string>;
        };
    }
}

export default defineConfig({
    settings: {
        // ...IDE Now gives me type suggestions for a `jsx-a11y` property in here!
    }
});

```

### What do you think is the correct solution?

It keeps all the current functionality and is the TS recommended way of letting consumers add their own type info at their own discretion.

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: pretty extensively, consumer, type info, discretion
Questions:
1. What does "consumer" refer to in this context?
2. Can you clarify what is meant by "type info" being added at the consumer's discretion?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

9.24.0

### What problem do you want to solve?

ESLint currently has confusing behavior around custom plugin keys, string based extends and rule configurations.

An example:

```js
import { defineConfig } from "eslint/config";
import { plugin as ts } from "typescript-eslint";

export default defineConfig(
    {
        plugins: {
            ts,
        },
        extends: ["ts/stylistic"],
        rules: {
            "ts/array-type": "off",
        },
    },
);
```

This not work as I would intuitively expect: it does not disable the `@typescript-eslint/array-type` rule added by the `ts/stylistic` config. This is confusing because to make this work I have to know the name the plugin decided to use for its rules, but extends does not have this restrictions.

For more information and examples, see the [relevant part of RFC126](https://github.com/eslint/rfcs/blob/bd9dc57de306e596a6d680e4a199afdd9659ed32/designs/2024-config-extends/README.md#reassignable-plugin-configs).

### What do you think is the correct solution?

In eslint/rfcs#126 it was proposed to solve this by adding a new `meta.namespace` key to `Plugin` and have `defineConfig` rewrite the key used to reference a rule in the extended configurations. At least that is how I understood the solution, for more details, see the RFC text.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Since the RFC is merged, I assume the decision on this was already made? I am mainly opening this issue, because I just ran into this, remembered some talk about it in the RFC, but did not find an issue I could subscribe to for updates. I searched the issue tracker for this, but the only thing I found was #19116, which is already closed.
Ambiguous terms: confusing, intuitively, restrictions
Questions:
1. What specific behavior around custom plugin keys, string based extends, and rule configurations in ESLint is considered confusing?
2. How does the proposed solution in eslint/rfcs#126 aim to address the issue with custom plugin keys and rule configurations?
Clarified requirement: The requirement discusses the confusing behavior in ESLint related to custom plugin keys, string-based extends, and rule configurations. It provides an example code snippet and mentions a proposed solution in eslint/rfcs#126 to address this confusion. The requirement also indicates the willingness to submit a pull request for the proposed change.


Clarify this requirement: ### What rule do you want to change?

no-useless-escape

### What change do you want to make?

Generate fewer warnings

### How do you think the change should be implemented?

A new option

### Example code

```js
/[0\-]/
```

### What does the rule currently do for this code?

It currently marks `\-` as a useless escape

### What will the rule do after it's changed?

It will not mark `\-` as a useless escape in regex character sets

### Participation

- [x] I am willing to submit a pull request to implement this change.

### Additional comments

`/[0\-]/` while technically a useless escape, omitting the escape is a common source of errors when additional characters are added to the character set accidentally creating a character range. For example `/[0-]/` extended into `/[0-9]/` produces a very different outcome than adding a single character `9` to the character set.
Ambiguous terms: fewer, new, common, additional
Questions:
1. What specific type of warnings are currently being generated that you want to reduce?
2. Can you provide more details on how the new option will affect the existing rule?
Clarified requirement: Introduce a new option that will prevent marking `\-` as a useless escape in regex character sets.


Clarify this requirement: ### ESLint version

v8.57.1

### What problem do you want to solve?

when adding a new rule not all rules and/or uses of the rule are fixable with the `fix` flag. i would like a new flag added that adds an ignore rule to those lines so i dont have to manually do this.

### What do you think is the correct solution?

add a new `ignore` flag.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

this would make enabling new flags a lot easier since eslint already knows the lines effected and by what rules.
Ambiguous terms: new, easier, a lot
Questions:
1. What does the current `fix` flag do in ESLint?
2. Can you provide an example of how the new `ignore` flag would work in practice?
Clarified requirement: Add a new `ignore` flag to ESLint that can be used when adding a new rule, allowing for specific lines to be ignored from the rule's enforcement, similar to the `fix` flag but without automatically attempting to fix the issue.


Clarify this requirement: ### Which packages would you like to change?

- [ ] `espree`
- [x] `eslint-scope`
- [ ] `eslint-visitor-keys`

### What problem do you want to solve?

There are a lot of ESLint rules that need to determine if a given identifier refers to a global or not. As a result, we have multiple copies of functions that try to determine if an identifier refers to a global:
https://github.com/search?q=repo%3Aeslint%2Feslint%20isglobal&type=code

That also means plugin rules need to implement their own.

### What do you think is the correct solution?

I think this is common enough that we should add a `isGlobalReference()` method to ~~`ScopeManager`~~ `SourceCode` to encapsulate this functionality:

```js
const isGlobal = sourceCode.isGlobalScope(node);
```

I think the method should accept a node and then determine from that node if it contains a reference to a global variable. Basically, we can copy the code from here:

https://github.com/eslint/eslint/blob/e62e26761561e1d78c6466a2d74dbf946012fddc/lib/rules/prefer-regex-literals.js#L175-L184

~~Then maybe we could expose the method on `SourceCode` to make it easier for rules to access.~~

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Looking for a volunteer to take this on.
Ambiguous terms: common enough, correct solution, maybe
Questions:
1. What is the purpose of the `isGlobalReference()` method you are proposing?
2. How would the `SourceCode` differ from the existing `ScopeManager` in this context?
Clarified requirement: Looking for a volunteer to take this on.


Clarify this requirement: ### ESLint version

9.24.0

### What problem do you want to solve?

An issue occurs in bundling ESLint for WebExtension use.

It appears that ESLint is depending [Ajv](https://github.com/eslint/eslint/blob/910bd13c4cb49001f2a9f172229360771b857585/package.json#L120) to [validate ESLint configurations](https://github.com/eslint/eslint/blob/910bd13c4cb49001f2a9f172229360771b857585/lib/config/rule-validator.js#L158) by matching them to a JSON schema. Ajv [uses Function()](https://github.com/ajv-validator/ajv/blob/82735a15826a30cc51e97a1bbfb59b3d388e4b98/lib/compile/index.ts#L171) to compile JSON schemas into JavaScript functions.

The `new Function()` is blocked by the browser CSP which results in a `throw`.

See also: [Errors with eslint-linter-browserify](https://github.com/UziTech/eslint-linter-browserify/issues/519)



### What do you think is the correct solution?

An alternative method (for the WebExtension context) would be greatly beneficial.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Although ESLont v8  also used the same validation, it causes no issues in the WebExtension context.
It is possible that it is not called (tested 8.41.0 & 8.57.0).
Ambiguous terms: issue, problem, beneficial, correct, alternative, possible
Questions:
1. What specific issue is encountered when bundling ESLint for WebExtension use?
2. What alternative method is being proposed for the WebExtension context?
Clarified requirement: The requirement aims to address an issue that arises when bundling ESLint for WebExtension use due to the browser CSP blocking the `new Function()` method used by Ajv to compile JSON schemas into JavaScript functions. The proposed solution involves finding an alternative method for the WebExtension context.


Clarify this requirement: ### ESLint version

9.24.0

### What problem do you want to solve?

Thanks to [this PR](https://github.com/eslint/eslint/pull/19159),  bulk suppressions were implemented in ESLint. 
However, this functionality is not implemented in the Node.js API and is not available from libraries such as vscode-eslint.

### What do you think is the correct solution?

By porting the bulk suppression functionality to the ESLint engine,
developers using ESLint via the API will also be able to use the bulk suppression functionality.

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: bulk suppression, functionality
Questions:
1. What is meant by "bulk suppression" in the context of ESLint?
2. Can you provide more clarity on what specific functionality needs to be ported to the ESLint engine?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

ESLint currently doesn't track JSX references. For example:

```js
import { Card } from "./card.jsx";

export function createCard(name) {
    return <Card name={name} />;
}
```

Right now, ESLint doesn't know that `<Card>` is a reference to the `Card` import.

### What do you think is the correct solution?

Enable JSX reference tracking in `eslint-scope`. This has already been added to `eslint-scope` but has not been enabled in ESLint.

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

Tracking for v10.
Ambiguous terms: fast, user-friendly
Questions:
1. What specific feature related to JSX reference tracking needs to be enabled in `eslint-scope`?
2. Can you provide more details on how the tracking for v10 should be implemented in ESLint?
Clarified requirement: Tracking for v10.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

Currently, a rule has no way to indicate if it works on any given language. This information would be helpful for two reasons:

1. Documentation purposes - being able to see which JS rules have been updated to support TS syntax.
2. Runtime purposes - automatically turning off rules that don't apply to the given language (for instance, turning off JS rules when linting CSS files)

### What do you think is the correct solution?

In the 2025-02-20 TSC meeting, we discussed adding two properties to `meta`:

1. `meta.language` - a string, such as "javascript", "css"
2. `meta.dialects` - an array of strings, such as `["javascript", "typescript"]`

@JoshuaKGoldberg [suggested](https://github.com/eslint/eslint/pull/19431/files/de59b04450d780f0e5c4f8826c318f8d263438f0..b7b964a3d87fa0044ffab51cbe3fe69bf514b6b9#r1968176879) merging both properties into a single object instead.

It's probably worth putting together an RFC that takes into account the two use cases (documentation and runtime) as well as finalizing what the `meta` info should look like.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: helpful, correct, worth, finalizing
Questions:
1. What does "finalizing" refer to in this context?
2. What does "worth" mean in relation to putting together an RFC?
Clarified requirement: It's probably worth putting together an RFC that takes into account the two use cases (documentation and runtime) as well as defining what the `meta` info should look like.


Clarify this requirement: ### What rule do you want to change?

no-inline-comments

### What change do you want to make?

In ESLint v8.53.0 you have [deprecated](https://eslint.org/blog/2023/10/deprecating-formatting-rules/) all rules that relate to formatting and conflict with formatters, in particular Prettier.

I have a question, don't you think that the [`no-inline-comments`](https://eslint.org/docs/latest/rules/no-inline-comments) rule is also related to formatting and should be moved to ESLint Stylistic?

Here's an example. This code:

```js
const someValue = 
  someBooleanValue 
    // comments
    ? []
    : [otherValue]
```

Will transform into this:

```js
const someValue = someBooleanValue
  ? // comments
    []
  : [otherValue];
```

Playground:

https://prettier.io/playground/#N4Igxg9gdgLgprEAuc0DOMAEaIFs4BqAhgDYCucmAvJgDpSbZ5wBCEEJcRUx5l9jRgHohmSLnyw0AwQH5MAbQC6MxkkUQYACzgAnXhSUgANCAgAHGAEt0yUEV26IAdwAKDhGmQhSzogE8vUwAjXSIwAGs4GABlInwAGSsoOGQAM1I0OBCwyOiY83DkgHNkGF0KUyzcKzKK7JA4AA9zPStJGFIAFT0oBys4LyQMkiyqks4ARTJNVOHMhoArNCaYibhp2fSF0wBHGfhXJ3MhnzQAWhS4ABMbkxByoisSEoBhPFwib1ISe7R1gCCMHKVmCZEOeiSKW2owaWhguBIAHUtFZ4GhCmA4DFPGirAA3NH+bxgNBBED4igASSgt1gMTAuislgBtJiMH8nBhYxA5icWSRYXM3j5gz0+NSpmSWV0MCORGKn25DUKuhl3mCRGCcF+pl0cH2Vn18sVX3msNMnWCSKs120yAATKYyFkulqhiMeXBcNrrrdrgluMUyAq4AAxCC6T7AkrfcEQe585IwG12rTIACsAAYAL45oA

### What does the rule currently do for this code?

N/A.

### What will the rule do after it's changed?

I think, this rule should be deprecated.

### Participation

- [x] I am willing to submit a pull request to implement this change.
Ambiguous terms: deprecated, formatting, related, Stylistic
Questions:
1. What specific criteria determine if a rule is considered to be related to formatting?
2. Can you provide an example of a rule that is currently in ESLint Stylistic for reference?
Clarified requirement: - [x] I am willing to submit a pull request to implement this change.


Clarify this requirement: ### What rule do you want to change?

every rule's meta.message attribute

### What change do you want to make?

Implement suggestions

### How do you think the change should be implemented?

A new default behavior

### Example code

```js
// eslint.config.js
module.exports = [
  /* ... */
]

// convert to new structure
module.exports = {
  language: 'en-US', // en-US as default, and also if not exist rule's language configuration as provided 
  rules: [ /* ... */ ] // the original rules array
}
```

### What does the rule currently do for this code?

```js
module.exports = {
    meta: {
        type: "suggestion",

        docs: {
            description: "Require braces around arrow function bodies",
            recommended: false,
            url: "https://eslint.org/docs/latest/rules/arrow-body-style"
        },

        messages: {
            unexpectedOtherBlock: "Unexpected block statement surrounding arrow body",
            unexpectedEmptyBlock: "Unexpected block statement surrounding arrow body; put a value of `undefined` immediately after the `=>`.",
            unexpectedObjectBlock: "Unexpected block statement surrounding arrow body; parenthesize the returned value and move it immediately after the `=>`.",
            unexpectedSingleBlock: "Unexpected block statement surrounding arrow body; move the returned value immediately after the `=>`.",
            expectedBlock: "Expected block statement surrounding arrow body."
        }
    }
}
```

### What will the rule do after it's changed?

```js
module.exports = {
    meta: {
        type: "suggestion",

        docs: {
            description: "Require braces around arrow function bodies",
            recommended: false,
            url: "https://eslint.org/docs/latest/rules/arrow-body-style"
        },

        messages: {
            // support reading i18n object
            unexpectedOtherBlock: {
               "en-US": "Unexpected block statement surrounding arrow body",
               "zh-CN": "不期望箭头函数包裹块语句"
            },
            unexpectedEmptyBlock: "Unexpected block statement surrounding arrow body; put a value of `undefined` immediately after the `=>`.",
            unexpectedObjectBlock: "Unexpected block statement surrounding arrow body; parenthesize the returned value and move it immediately after the `=>`.",
            unexpectedSingleBlock: "Unexpected block statement surrounding arrow body; move the returned value immediately after the `=>`.",
            expectedBlock: "Expected block statement surrounding arrow body."
        }
    }
}
```

### Participation

- [x] I am willing to submit a pull request to implement this change.

### Additional comments

_No response_
Ambiguous terms: new default behavior, suggestions, implement, support, reading, i18n object
Questions:
1. What specifically should the new default behavior entail?
2. How should the i18n object be utilized in the implementation?
Clarified requirement: Update the messages in the meta.message attribute to be structured in a way that supports different languages using an i18n object.


Clarify this requirement: ### ESLint version

9.15.0

### What problem do you want to solve?

Forking out of #19134 & https://github.com/typescript-eslint/typescript-eslint/issues/10338 -> https://github.com/eslint/eslint/issues/19169#issuecomment-2499150529:

> The only acceptable way to extend a core rule is to copy the file into your own project and then wrap it however you want. That does put more maintenance burden on plugin developers, but that's the point. If you want to do something that isn't officially supported, you need to take full responsibility for that implementation.

This is not an ideal situation for plugin developers. The required extra work in lieu of having a pluggable API or abstractions necessitates that plugin developers:

- Maintain automations to keep up with ESLint's releases - including copying rules and any imported dependencies from ESLint core & its package dependencies
  - Amusingly, this again leads plugins to rely on implementation details. Just, now that would only be during their build steps, not their published packages
- Be deeply familiar with and having a dependency on the potentially any/all implementation details of base rules

Much of that work is already in play today, including taking the dependency on base rules. Both the current unsupported approach _and_ the recommended _"copy and wrap"_ approach cause higher-than-expected levels of implementation detail reliance in extensions.

### What do you think is the correct solution?

I honestly have no good idea. If the goal of ESLint is to not allow plugins to rely on _any_ behavior from rules -which is my interpretation of https://github.com/eslint/rfcs/pull/80#discussion_r629623105 - then generalizing any of the following strategies we typically do in typescript-eslint seem moot.

For example, [`@typescript-eslint/no-unused-expressions`](https://github.com/typescript-eslint/typescript-eslint/blob/f5e23e28653705fc7021d8c780f0d63656dea518/packages/eslint-plugin/src/rules/no-unused-expressions.ts) effectively wraps the base rule's `ExpressionStatement` with filtering logic. But if we can't rely on the base rule having any particular node selectors, then... 🤷

If the ESLint team has appetite to work with plugin developers on this, maybe it would be useful as a next step for someone to gather all the various extension rules and strategies they've taken? Just to see what the landscape & common strategies are?

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

Personally, I don't think resolving this issue should block #19169. The _"don't do this"_ urge with the current _"copy and wrap"_ recommended approach can be added regardless of this issue. I suspect finding a more preferable strategy (this issue) will take much longer. If and when an alternate strategy is resolved, it can always add it to the docs.

I'll also note that plugins aren't "choosing" to write extension rules: they _have_ to to satisfy user need. For example, typescript-eslint's extension rules must act the same as their base rules _except_ for cases where TypeScript's syntax and/or type checking change something. I see extension rules as an expected use case for plugins that just hasn't yet had a formalized first-party ESLint API. If plugins could avoid taking any dependency on core rule behavior in this way -and therefore inconveniencing the ESLint project- that would be even better!

---

Edit (March 2025): The discussion is long enough that comments are being hidden by default. Turning the rules from https://github.com/eslint/eslint/issues/19173#issuecomment-2619649206 into a task list here:

- [x] [`@typescript-eslint/class-methods-use-this`](https://typescript-eslint.io/rules/class-methods-use-this): #19498
- [x] [`@typescript-eslint/default-param-last`](https://typescript-eslint.io/rules/default-param-last): #19431
- [x] [`@typescript-eslint/init-declarations`](https://typescript-eslint.io/rules/init-declarations): #19540
- [ ] [`@typescript-eslint/max-params`](https://typescript-eslint.io/rules/max-params): #19557
- [x] [`@typescript-eslint/no-array-constructor`](https://typescript-eslint.io/rules/no-array-constructor): #19493
- [x] [`@typescript-eslint/no-dupe-class-members`](https://typescript-eslint.io/rules/no-dupe-class-members): #19558
- [x] [`@typescript-eslint/no-empty-function`](https://typescript-eslint.io/rules/no-empty-function): #19551
- [x] [`@typescript-eslint/no-invalid-this`](https://typescript-eslint.io/rules/no-invalid-this): #19532
- [x] [`@typescript-eslint/no-loop-func`](https://typescript-eslint.io/rules/no-loop-func): #19559
- [x] [`@typescript-eslint/no-loss-of-precision`](https://typescript-eslint.io/rules/no-loss-of-precision): #19560
- [ ] [`@typescript-eslint/no-magic-numbers`](https://typescript-eslint.io/rules/no-magic-numbers): #19561
- [ ] [`@typescript-eslint/no-redeclare`](https://typescript-eslint.io/rules/no-redeclare): #19563
- [ ] [`@typescript-eslint/no-restricted-imports`](https://typescript-eslint.io/rules/no-restricted-imports): #19562
- [ ] [`@typescript-eslint/no-shadow`](https://typescript-eslint.io/rules/no-shadow): #19565
- [x] [`@typescript-eslint/no-unused-expressions`](https://typescript-eslint.io/rules/no-unused-expressions): #19564 
- [ ] [`@typescript-eslint/no-unused-vars`](https://typescript-eslint.io/rules/no-unused-vars): #19580
- [ ] [`@typescript-eslint/no-use-before-define`](https://typescript-eslint.io/rules/no-use-before-define): #19566
- [x] [`@typescript-eslint/no-useless-constructor`](https://typescript-eslint.io/rules/no-useless-constructor): #19535
Ambiguous terms: ideal, good, correct, preferable, much longer, better
Questions:
1. What specific challenges do plugin developers face when extending core rules in ESLint?
2. How does the current approach of copying and wrapping core rules impact plugin developers?
Clarified requirement: Specify the challenges plugin developers face when extending core rules in ESLint and explain the impact of the current copying and wrapping approach on them.


Clarify this requirement: ### ESLint version

v9.x

### What problem do you want to solve?

Currently the only way to pass [feature flags](https://eslint.org/docs/latest/flags/) is via the CLI or NodeJS API directly.

This is cumbersome at scale because:
- opting-in users into the flags can require large-scale coordination to get people to change their IDE config
- turning on a flag means having to update all NodeJS API usages across a repository at the same time

### What do you think is the correct solution?

A much simpler alternative would be allowing passing of feature flags via an environment variable.
This would allow setting of the flags via direnv or similar tools to transparently turn on the flags for all developers and tools working in the repo.

For example at Canva we have tools that would allow us to inject an `export ESLINT_FLAGS="unstable_config_lookup_from_file"` or similar into all users `.bashrc`/etc file -- but for various reasons we could not easily get all users to change their IDE configs (there are multiple IDEs and no shared configuration, for example).

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: simpler, much, allowing, transparently, easily
Questions:
1. What specific feature flags are currently being passed via the CLI or NodeJS API?
2. Can you provide more details on why it is difficult to get all users to change their IDE configs?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

v10.0.0

### What problem do you want to solve?

In https://github.com/eslint/eslint/issues/18485#issuecomment-2195450564 it was agreed to deprecate the `nodeType` property on `LintMessage` and remove it in a future release (since that will be breaking change).

`LintMessage#nodeType` and `TestCaseError#type` have been deprecated in #19019, so we should probably remove these two properties in v10.

This change will have the most visible impact on the unit tests in `eslint`, where the deprecated properties are still found in a number of occurrences and will need to be removed, especially `TestCaseError#type` in rule tests.

### What do you think is the correct solution?

Remove `LintMessage#nodeType` and `TestCaseError#type` in ESLint v10.

* Remove the properties and update the logic if necessary
* Update type definitions
* Update unit tests
* Test the changes with other packages, especially `@eslint/markdown` and `@eslint/json` to ensure that they will still work
* Note the breaking changes for plugin developers in the migration guide


### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: probably, most visible, especially, necessary, correct, willing
Questions:
1. What specific properties need to be removed in ESLint v10?
2. Are there any other properties or components affected by this change that need to be addressed?
Clarified requirement: Remove the `LintMessage#nodeType` and `TestCaseError#type` properties in ESLint v10 to address the deprecation agreed upon in issues #18485 and #19019. Update logic, type definitions, and unit tests accordingly, ensuring compatibility with packages like `@eslint/markdown` and `@eslint/json`. Note the breaking changes for plugin developers in the migration guide.


Clarify this requirement: ### ESLint version

HEAD/v9.10.0

### What problem do you want to solve?

| test | current behavior | proposed behavior |
|---------|-------------------|---------------------------|
| `valid: [{code: "", errors: [{message: "xxx"}]}]` | ✅ | ❌ Valid test cases should not have an 'errors' property". |
| `invalid: [{code: "", errors: [{}]}]` | ~~✅~~❌ | ❌ Test error must specify either a 'messageId' or 'message'. |
| `invalid: [{code: "", errors: [{message: "xxx", suggestions: null}]}]` | ✅ | ❌ Test error object property 'suggestions' should be an array or a number. |
|`valid: [{code: "foo"}]`, `invalid: [{code: "foo", errors: 1}]` | ✅| ❌ detected duplicate test case |
....

### What do you think is the correct solution?

explained above.

Question: should this be a breaking change? or a normal bugfix(can be shipped in eslint v9)?

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

I had a wip https://github.com/aladdin-add/eslint/tree/issue13434-0

there may be more edge cases, opened the issue to track all these cases.🤓
Ambiguous terms: edge cases, fast, user-friendly
Questions:
1. What specific change is being proposed in the ESLint version?
2. Is the issue being tracked for this change on GitHub for reference?
Clarified requirement: The ESLint version HEAD/v9.10.0 proposes changes to the handling of test cases in the code. The proposed changes include adjustments to valid and invalid test cases, with specific requirements for error objects. The contributor is willing to submit a pull request for this change and has a work in progress (WIP) on GitHub for reference.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

We inherited a lot of hardcoded rule configuration types from `@types/eslint`, but these were all handcoded and we've already seen that they are out of date. (https://github.com/eslint/eslint/pull/18902, https://github.com/eslint/eslint/pull/18906, https://github.com/eslint/eslint/pull/18905, https://github.com/eslint/eslint/pull/18903, https://github.com/eslint/eslint/pull/18901). Keeping the types in sync with rules is going to be a problem going forward.

### What do you think is the correct solution?

We should create a script that automatically generates the rule config types based on the rule schemas.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Looking for a volunteer for this.
Ambiguous terms: hardcoded, out of date, problem, correct, volunteer
Questions:
1. What specifically do you mean by "hardcoded rule configuration types"?
2. Can you clarify what you mean by "rule schemas"?
Clarified requirement: Looking for a volunteer for this.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

Currently, ESLint passes the raw text of a file to a processor's `preprocess()` method, which may include a BOM.

However, processors rarely check for the BOM before attempting to parse the text (even our own Markdown processor doesn't do the check), which can lead to hard-to-decipher parsing errors if the parser isn't handling the BOM. This seems like a serious footgun in the API that we should fix.

### What do you think is the correct solution?

Instead, I think we should pass the text with the BOM removed, as it seems like that would be the most expected behavior from a processor perspective. In most cases, this will be a non-breaking change, as any processor that is checking for a BOM will still function as expected while those that do not will avoid a potential error.

The downside of this change is that processors that return a block representing the entire file in addition to subparts of the file will no longer see the BOM, which means the `unicode-bom` rule won't pick up a BOM in the original file when present.

If that is a concern, we can add a third parameter to `preprocess()` that indicates whether or not the BOM the present so processors that explicitly want to check for the BOM may do so.

(Note: Returning a block that represents the entire file is suboptimal and something we can hopefully avoid in the future with [prelint plugins](https://github.com/eslint/rfcs/pull/105).)

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: rarely, hard-to-decipher, serious, expected, most cases, avoid, concern, hopefully
Questions:
1. What specific problems can arise from passing the raw text with a BOM to a processor's `preprocess()` method?
2. Can you clarify what is meant by "processors that return a block representing the entire file in addition to subparts of the file"?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

v9

### What problem do you want to solve?

In a rule `fix` function, 

```js
fixer.replaceText(node, replacement.text);
```

when `replacement.text` is undefined, it will replace the node with `undefined`.

### What do you think is the correct solution?

Throw an error instead.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

Prevent mistakes.
Ambiguous terms: undefined
Questions:
1. What is the significance of `undefined` in this context?
2. Can you provide an example of when `replacement.text` might be undefined?
Clarified requirement: Update ESLint version to v9. In a rule `fix` function, when `replacement.text` is undefined, it currently replaces the node with `undefined`. The correct solution is to throw an error instead. The goal is to prevent mistakes.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

While working on a new API design for the core, I've come across the situation where I'm not sure if the API I'm envisioning is practical or will work the way I expect. As such, it will be difficult to design an API from scratch without performing some implementation along the way...and I don't want to have to rewrite the core on my own in the process.

### What do you think is the correct solution?

What I'd like to do is start refactoring the current core in a way that makes it easier to experiment with a new API. Specifically, to start pulling things out of `Linter` and `ESLint` and into their own classes. These don't necessarily have to be the final new core API, but it would at least give me an opportunity to explore everything the core is currently doing and see if I can start carving out smaller classes of functionality that will inform the new API.

Here are some of the pieces I have in mind:

- [x] Extract parsing into a class
- [x] Extract pre/postprocess into a class
- [x] Extract rule context into a class
- [x] Extract config normalization/validation into a class
- [x] Extract ESQuery parsing into a class
- [ ] Consolidate config-related functionality
- [ ] Refactor source code traversal to allow for async traversal
- [ ] Replace `SafeEmitter` with an async-capable option

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: practical, work, easier, experiment, explore, inform, smaller, functionality, refactor, async, option
Questions:
1. What specific aspects of the current core need to be refactored into their own classes?
2. Can you clarify the goal of consolidating config-related functionality?
Clarified requirement: Refactor the current core by extracting parsing, pre/postprocess, rule context, config normalization/validation, and ESQuery parsing into their own classes. Additionally, consolidate config-related functionality and refactor source code traversal to allow for async traversal. Replace `SafeEmitter` with an async-capable option.


Clarify this requirement: ### ESLint version

8.56.0

### What problem do you want to solve?

Some rules provide autofixing, which is great, but can sometimes be broken or otherwise simply unwanted for various reasons.
Unsafe autofixes should be suggestions, and broken fixes should be reported, *but* ESLint is a large ecosystem where some very useful plugins are not always actively maintained. Even then, wanting to disable an autofix for project-specific or personal reasons could still happen.

### What do you think is the correct solution?

I'd like ESLint to provide a way to configure rules to disable their autofixing. I can immediately think of two approaches:

1. Similar to how Ruff (https://docs.astral.sh/ruff/settings/#lint_unfixable) does it, a top-level key to specify which rules to not autofix would be imo the least disruptive and forward/backwards compatible. It should be overridable (in the `overrides` section), and picked up when extending a configuration.

2. Another approach I can think of is to encode that in the rule config itself. Something like `"my-plugin/my-rule": "[{severity: "error", autofix: False}, {...otherConfigs}]"` but it's harder to commit to such a change, and means that any config extension needs to reconfigure the rule correctly just to disable autofixing (which is already an issue when someone wants to set a pre-configured rule as warning for example)

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

https://www.npmjs.com/package/eslint-plugin-no-autofix is a tool that exists to currently work around this limitation of ESLint, but it is not perfect.
1. It is an extra third-party dependency, with its own potential maintenance issues (having to keep up with ESLint, separate dependencies that can fall out of date, obsolete, unsecure, etc.)
2. It may not work in all environments. For example, pre-commit.ci: https://github.com/aladdin-add/eslint-plugin/issues/98
3. It may not work correctly with all third-party rules: https://github.com/eslint-community/eslint-plugin-eslint-comments/issues/234

I searched for a similar issue but couldn't find any. So hopefully this isn't an already refused proposal 🤞
Ambiguous terms: great, large, very useful, sometimes, unsafe, broken, large ecosystem, project-specific, personal, immediately, least disruptive, forward/backwards compatible, harder, correctly, already an issue, perfect, all environments, all third-party rules, similar, hopefully
Questions:
1. What defines an autofix as "unsafe" or "broken" in the context of ESLint rules?
2. How would the configuration to disable autofixing interact with existing ESLint rule configurations?
Clarified requirement: ESLint should provide a way to configure rules to disable their autofixing. This can be achieved by either introducing a top-level key to specify rules that should not be autofixed, which can be overridden in the `overrides` section and when extending a configuration, or by encoding the autofixing disablement directly in the rule configuration itself.


Clarify this requirement: ### ESLint version

9.6.0

### What problem do you want to solve?

Right now when --fix is enabled, ESLint runs all rules in all <=10 rerun iterations. This has historically led to performance issues when two different areas of rules are enabled and have different performance characteristics. That split often looks like:

* 🍏 [typed linting](https://typescript-eslint.io/getting-started/typed-linting): slower, commonly with `meta.type: "problem"`, and only about one round of fixes to report
* 🍌 [stylistic rules](https://eslint.style), faster, commonly with `meta.type: "layout"`, with many fixes as rules rewrite code formatting

Today, each of ESLint's passes run _both_ of those groups of rules each time. For example, if your rule times in those two types are:

* 🍏 typed rules: ~5,000 milliseconds, with 1 round of fixes applied (very common)
* 🍌 stylistic rules: ~100 milliseconds, with 3 rounds of fixes applied (also common)

...then your total time will be ~20,400 milliseconds from 4 rounds of ~5,100 milliseconds each. 😬 

### What do you think is the correct solution?

I haven't investigated this space deeply enough to know if there's some previously determined optimal way to run these fixes. But surely there's _some_ way to be more efficient than continuously running 🍏 _and_ 🍌!

Starting proposal: how about, after the first application of rules is run, ESLint:

1. Groups the rules by `meta.type`, generating a total running time for each of those grouped types
2. Runs only one type of rule at a time, in order of which type group is fastest

Using the example above, the order rule type groups would be run is:

1. Both 🍏 and 🍌 produce fixes: ~5,100ms
2. 🍌 produces fixes, so 🍏 is skipped: ~100ms
3. 🍌 produces fixes, so 🍏 is skipped: ~100ms
4. 🍌 produces no fixes, and then neither does 🍏: ~5,100ms

...for a total of ~10,400ms. ⚡ 

Note that we'd still be running until no rules report any more fixes. This proposal does not suggest optimistically skipping rules - the final round must always have zero fixes reported. We'd just be optimizing by re-running the quick rules that tend to generate many fixes first.

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

I'm thinking it might be efficient to only turn this behavior on if the time difference between some groups is significant. Maybe 1 / (N * 2), where N = the number of different types of rules enabled?

Edit: oh, and: there's an additional optimization of applying the 🍏 slower-area fixes before 🍌 faster-area fixes. That way no 🍏 fixes are skipped in the first round and then applied later.
Ambiguous terms: fast, efficient, more efficient, optimal, significant
Questions:
1. What defines the significance of the time difference between rule groups?
2. How is the efficiency of running rules measured in this context?
Clarified requirement: The ESLint version 9.6.0 currently faces performance issues when running all rules in multiple iterations with the --fix flag enabled. The proposal suggests grouping rules by their characteristics, such as speed, and running them sequentially based on their performance to optimize the fixing process. The final round should always have zero reported fixes, and slower rules should be applied before faster ones.


Clarify this requirement: ### ESLint version

v9.4.0 (main branch)

### What problem do you want to solve?

When running `npm install` in the `eslint` repo, several deprecation warnings are shown:

```
npm warn deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.
npm warn deprecated readdir-scoped-modules@1.1.0: This functionality has been moved to @npmcli/fs
npm warn deprecated debuglog@1.0.1: Package no longer supported. Contact Support at https://www.npmjs.com/support for more info.
npm warn deprecated read-package-json@2.1.2: This package is no longer supported. Please use @npmcli/package-json instead.
npm warn deprecated @babel/plugin-proposal-class-properties@7.18.6: This proposal has been merged to the ECMAScript standard and thus this plugin is no longer maintained. Please use @babel/plugin-transform-class-properties instead.
npm warn deprecated rimraf@3.0.2: Rimraf versions prior to v4 are no longer supported
npm warn deprecated rollup-plugin-inject@3.0.2: This package has been deprecated and is no longer maintained. Please use @rollup/plugin-inject.
npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@8.1.0: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@8.1.0: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@7.1.7: Glob versions prior to v9 are no longer supported
npm warn deprecated glob@7.1.6: Glob versions prior to v9 are no longer supported
npm warn deprecated sourcemap-codec@1.4.8: Please use @jridgewell/sourcemap-codec instead
npm warn deprecated read-installed@4.0.3: This package is no longer supported.
npm warn deprecated sinon@11.1.2: 16.1.1
```

Many of these originate in the inflight package being [deprecated by the owner](https://github.com/isaacs/inflight-DEPRECATED-DO-NOT-USE/issues/5#issuecomment-2126153820). The versions of `glob` that use this package were similarly deprecated (also see [this note](https://github.com/isaacs/node-glob/issues/435#issuecomment-1673562165)).


### What do you think is the correct solution?

These dependencies come in transitively from other packages that `eslint` depend on. It would be up to them to update, and then for `eslint` to bump dependencies to those versions. 

Since the problems are surfaced to eslint, I thought it would be useful with a ticket to track the progress and link to upstream tickets. 

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: several, many, correct, useful, upstream
Questions:
1. What specific deprecation warnings related to packages are shown when running `npm install` in the `eslint` repo?
2. Who should update the dependencies and bump versions in `eslint` according to the correct solution?
Clarified requirement: The requirement details the deprecation warnings related to specific packages shown when running `npm install` in the `eslint` repository. It suggests that the dependencies causing these warnings should be updated by the packages `eslint` depends on, followed by bumping the versions in `eslint`. Additionally, it mentions the need for a ticket to track progress and link to upstream tickets.


Clarify this requirement: ### ESLint version

8.56.0

### What problem do you want to solve?

ESLint configs have traditionally been exported by ESLint plugins under a standard `configs` object (alongside the `rules` object). This has allowed tooling like [eslint-doc-generator](https://github.com/bmish/eslint-doc-generator) and [lintbase.com](https://www.lintbase.com/) to automatically detect/analyze configs and generate documentation regarding them including the list of configs, which rules belong to which configs, etc.

New [flat configs](https://eslint.org/docs/latest/use/configure/configuration-files-new) can be exported in a variety of ways, including as an arbitrary file export from the plugin, such as `require('eslint-plugin-ember/configs/recommended')` in this [example](https://github.com/ember-cli/eslint-plugin-ember/pull/2020) I worked on, and not necessarily in the `configs` object exported by the plugin.

For existing plugins that want to support both legacy and flat versions of their configs while maintaining backwards-compatability, I've typically seen them leave the `configs` object for legacy configs, and add file exports for the new flat configs.

To my knowledge, since there aren't strict requirements around how or where flat configs are exported from, the user has to manually look up in the plugin's README to find out what the configs are and how exactly to import and use them (including whether they are arrays or objects). As you can imagine, depending on the README to discover configs is not conducive to automated tooling.

### What do you think is the correct solution?

**Note:** See updated proposal in: https://github.com/eslint/eslint/issues/18095#issuecomment-1951414598

Could there be a convention or requirement for how plugins should export flat configs? Presumably, this would keep legacy config exporting the same through the `configs` object for backwards-compatability so plugins can support both config types, at least for some time.

One idea is to require or suggest plugins to export a new `configurations` object containing a mapping of config name to each loaded flat config.

And what about recommendations around the direct file path entrypoint for exporting flat configs? I've seen plugins using `eslint-plugin-example/configs/config-name` or variations of this. Perhaps we could at least recommend a path format.

Ideally, any convention or requirement would enable programmatic discoverability of flat configs, with the added benefit of simply making it easier to use flat configs.

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

Related:
* https://github.com/bmish/eslint-doc-generator/issues/376
Ambiguous terms: convention, requirement, recommendations, suggest, perhaps, ideally
Questions:
1. What specific challenges arise from the current lack of a convention for exporting flat configs?
2. How would implementing a convention for exporting flat configs improve the user experience?
Clarified requirement: Define a convention for ESLint plugins to export flat configs in a standardized way, possibly through a new `configurations` object that maps config names to each loaded flat config. Additionally, recommend a specific file path format for exporting flat configs to enable programmatic discoverability and ease of use.


Clarify this requirement: ### ESLint version

v8

### What problem do you want to solve?

eslint-plugin-import uses FileEnumerator in its `no-unused-modules` rule, for the purpose of gathering a list of files are not eslintignored, or ignored by the user's rule config, for checking if any exports or modules are unused.

It seems that in flat config, this capability does not exist.

### What do you think is the correct solution?

Something that may work nicely is a new method on `context` provided to rules, that can achieve the same goal, but I have no idea if this makes sense for eslint or not.

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

This is the sole remaining blocker (afaik) to eslint-plugin-import supporting Flat Config, after which I plan to do a breaking change to drop older eslint versions, which is something quite a lot of users have been asking for.
Ambiguous terms: nicely, sole, quite a lot of
Questions:
1. What specific capability or functionality is missing in flat config that is present in other configurations?
2. Can you clarify what you mean by a "breaking change to drop older eslint versions"?
Clarified requirement: This is the remaining blocker to eslint-plugin-import supporting Flat Config. After resolving this, I plan to make a breaking change to drop older eslint versions, a request from many users.


Clarify this requirement: ### ESLint version

N/A

### What problem do you want to solve?

Currently it's possible to declare a rule as both `fixable` and `hasSuggestions` without ever reporting either a fixer or a suggestion.

This is not great because often these flags are used for documentation purposes - which leads to bad documentation for users.

Additionally it's quite doable to create a suite of tests that never produces a fixer or a suggestion - this means that you can accidentally leave untested pathways in your rule. In the case of autofixers this is especially bad because you may not have validated that your code produces syntactically valid code!

### What do you think is the correct solution?

It would be great if ESLint could do some post-run validation for a rule - for example:
- "if the rule is marked as `fixable` and no tests produced a fixer - error"
- "if the rule is marked as `hasSuggestions` and no tests produced suggestions - error"

One might suggest that this could be done via lint rules (eg `eslint-plugin-eslint-plugin`) - however it can be quite hard to statically analyse this given rules need not be contained within one file (so it's not possible to enforce the existence of a fixer on at least one `context.report()` call). Similarly tests may be assembled via generation in some way - meaning tests are dynamic and not possible to analyse. You might be able to catch some simpler cases with a lint rule.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: great, bad, quite doable, especially, might suggest, hard, possible, similarly, simpler
Questions:
1. What are the specific flags used for documentation purposes that can be declared for a rule in ESLint?
2. How would ESLint perform post-run validation for rules that are marked as `fixable` or `hasSuggestions`?
Clarified requirement: ESLint should validate rules post-run by generating errors if a rule marked as `fixable` has no fixer produced, and if a rule marked as `hasSuggestions` has no suggestions produced during testing. This validation should ensure that rules are properly documented and thoroughly tested.


Clarify this requirement: ### ESLint version

v8.56.0

### What problem do you want to solve?

Porting https://github.com/JoshuaKGoldberg/eslint-plugin-expect-type/issues/115 over to ESLint core: at least one community plugin -`eslint-plugin-expect-type` has a rule whose fixer operates on a separate "snapshot" file in the file system, _not_ the file being linted. That rule has no native way of knowing whether ESLint is being run in `--fix` mode. Because fixers run even if ESLint isn't in fix mode, the fixer can't reliably know whether it should update the file snapshot.

### What do you think is the correct solution?

~Two thoughts:~

* ~Can we avoid running `fix()` functions when not in fix mode?~
* ~Alternately, can a rule's `context` object contain info on whether the fixer is being run? Or the `fixer` passed to the `fix()` function?~

Edit (Jan 9): https://github.com/eslint/eslint/issues/17881#issuecomment-1883593657 shows the current proposal of enabling suggestions to specify changes to other files in limited cases:

> * Limiting this option to `suggestions`, not fixes?
> * Add a new `meta` property like `meta.allowSuggestingFileChanges` _(but with a better name)_?
> * Having these out-of-file changes go through `fixer` methods that limit the allowed actions in some way?

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

A rules equivalent of what I proposed a year ago in https://github.com/eslint/rfcs/pull/102, perhaps? 🙂 

Edit (Jan 9): Later comments have filled in use cases:

* [eslint-plugin-expect-type](https://github.com/JoshuaKGoldberg/eslint-plugin-expect-type)'s [expect-type/expect rule](https://github.com/JoshuaKGoldberg/eslint-plugin-expect-type/blob/ea67df6f3c90b94ac550b7c47f2579b4c18cc46f/docs/rules/expect.md)'s [$ExpectTypeSnapshot feature](https://github.com/JoshuaKGoldberg/eslint-plugin-expect-type/blob/ea67df6f3c90b94ac550b7c47f2579b4c18cc46f/docs/rules/expect.md#expecttypesnapshot) (https://github.com/eslint/eslint/issues/17881#issuecomment-1873507895)
* CSS-in-JS styling systems such as [Panda CSS](https://panda-css.com) and [Vanilla Extract](https://vanilla-extract.style) being able to suggest moving `css(...)` calls to a new file (https://github.com/eslint/eslint/issues/17881#issuecomment-1874772298)
* Spell-checkers such as the [cspell spellchecker](https://github.com/streetsidesoftware/cspell) project's [@cspell/eslint ESLint plugin](https://www.npmjs.com/package/@cspell/eslint-plugin) being able to suggest adding to a user dictionary (https://github.com/eslint/eslint/issues/17881#issuecomment-1883593657)
Ambiguous terms: avoid, reliably, limited, better, some way
Questions:
1. What specific changes are being proposed for ESLint in relation to fixers and suggestions?
2. How do the examples provided, like eslint-plugin-expect-type and CSS-in-JS styling systems, relate to the proposed changes?
Clarified requirement: Propose changes to ESLint to enable suggestions to specify changes to other files in limited cases, such as avoiding running fix() functions when not in fix mode or providing a new meta property like meta.allowSuggestingFileChanges. This would allow rules like expect-type/expect rule to utilize features like $ExpectTypeSnapshot and other projects like CSS-in-JS styling systems to suggest moving calls to a new file.


Clarify this requirement: ### ESLint version

HEAD

### What problem do you want to solve?

Currently, our main ESLint repository benefits from the automation provided by Renovate for dependency management. However, this practice has not been uniformly adopted across all our repositories. To address this, I propose the creation of a centralized repository within our ESLint organization. This repository will not only contain configurations for Renovate but also other common GitHub Actions workflows.

Advantages of this Approach:

* Unified Workflow Management: By centralizing our GitHub Actions configurations, including Renovate, we can ensure all ESLint projects follow a consistent workflow for automated tasks, thus improving our overall efficiency.

* Reduction in Redundant Efforts: A central repository eliminates the need to duplicate GitHub Actions configurations in each repository. This reduces repetitive work and ensures uniformity across our projects.

* Simplified Updates and Maintenance: Any changes or updates to our automation configurations would need to be made only once, in the central repository. This simplifies the process of maintaining and updating our workflows.

* Extensibility for ESLint Community Projects: This centralized repository can also be made available to projects under the `eslint-community`org, allowing them to benefit from standardized GitHub Actions workflows.

refs:
* https://github.com/eslint-community/eslint-plugin-n/pull/44
* https://github.com/eslint/eslint/discussions/17424

### What do you think is the correct solution?

Creation of a Central Repository: Establish a new repository, possibly named `eslint-gha-configs`, to house our GitHub Actions configurations:

* renovate
* release-please
* add-to-triage
* stale
* codeql

### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

I'm sure Renovate config can be reused in this way, but I'm not sure if others (like `release-please`) are also feasible. help wanted!🙌
Ambiguous terms: fast, user-friendly, efficient, redundant, uniformity, simplified, standardized, feasible
Questions:
1. What specific GitHub Actions workflows will be included in the centralized repository?
2. Are there any specific criteria for determining the feasibility of including a GitHub Actions workflow like `release-please`?
Clarified requirement: Create a centralized repository named `eslint-gha-configs` to house GitHub Actions configurations such as renovate, release-please, add-to-triage, stale, and codeql.


Clarify this requirement: ### ESLint version

v8.55.0

### What problem do you want to solve?

With the new flat config system, configs are only allowed to export [known](https://eslint.org/docs/latest/use/configure/configuration-files-new#configuration-objects) properties like `rules`, `files`, etc.

However, in third-party tooling I maintain like [eslint-doc-generator](https://github.com/bmish/eslint-doc-generator#configs-list-table) and [lintbase.com](https://www.lintbase.com/), I've been letting plugins set an unofficial `description` / `meta.description` / `meta.docs.description` property to annotate their configs (or processors) with a description that can be included in the auto-generated documentation for the plugin. This won't work anymore as flat config will throw an error like `Error: Unexpected key "meta" found.`.

Furthermore, there are a variety of documentation-related properties used, allowed, or not allowed by ESLint core objects/concepts today, and this can be inconsistent and inflexible:

* Plugins: Can export `meta.name` and `meta.version`
* Rules: Can export anything, official properties are in `meta` or `meta.docs`, `meta.docs.description` is commonly used
* Rule options: Can export properties controlled by JSONSchema including [`description`](https://json-schema.org/learn/getting-started-step-by-step#create-a-schema-definition)
* Configs: No meta/documentation properties currently allowed, but a `name` property can be included to help with debugging
* Processors: Can export `meta.name` and `meta.version` for debugging

### What do you think is the correct solution?

In general, it would be useful to be able to accommodate at least the following rule documentation properties on any of the ESLint-controlled core objects/concepts: `description`, `url`, `deprecated`, `replacedBy`, plus space for arbitrary third-party/user-defined properties.

The challenge is how to place these properties in a consistent fashion across object types and in consideration for the already existing properties.

In particular, some of these rule properties are spread across `meta` and `meta.docs`. The dividing line between `meta` and `meta.docs` can be a bit blurry. I was thinking that `meta` would be for properties that are functionally used by ESLint, whereas `meta.docs` would be for non-critical/informational/custom properties that aren't necessarily used or needed by ESLint. By that division, `description`, `url`, `deprecated`, `replacedBy` would likely all fall under `meta.docs`.

Some ideas for improving the consistency and flexibility of properties on ESLint core objects/concepts:

1. Always allow `meta.docs` as an arbitrary object for any documentation / third-party properties.
2. Suggest using `meta.docs` for documentation properties like `description`, `url`, `deprecated`, `replacedBy`.
   - One exception to this: rules place `deprecated` and `replacedBy` directly on `meta`.
   - We can encourage using these common properties and suggest formats for them, [as we do today](https://eslint.org/docs/latest/extend/custom-rules#rule-structure) with rules, as they are good for the health of the plugin ecosystem and often used by IDEs and third-party tooling, but ESLint itself wouldn't necessarily enforce anything about them.
   - The list of documentation properties I have mentioned so far is not necessarily comprehensive as it's just a starting point based on existing, commonly-used rule properties.
4. Whenever a `name` or `version` is needed to be specified, include it in the `meta` object. So we could update configs to accept `meta.name` (falling back to the current `name` property for backwards compatibility if needed).

To summarize: I took an initial stab at holistically considering documentation properties, but my top priority is really just to decide where documentation properties should go on each ESLint core object (in `meta.docs` in my proposal) without necessarily specifying a complete list of all potential documentation properties and their exact formats.

Related issue about the deprecation properties:

*  https://github.com/eslint/eslint/issues/18061

### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: blurry, flexibility, consistent, arbitrary, commonly-used, comprehensive
Questions:
1. What specific rule documentation properties are currently allowed on ESLint core objects/concepts?
2. Can you provide an example of how the `meta` and `meta.docs` properties are currently being used?
Clarified requirement: Specify where documentation properties such as `description`, `url`, `deprecated`, and `replacedBy` should be placed on each ESLint core object, proposing to use `meta.docs` for these properties while allowing for flexibility in defining additional documentation properties.


Clarify this requirement: ### What problem do you want to solve?

In my last PR, I noticed that the documentation rules pages (i.e. Markdown) have inconsistent formatting. Rules randomly have either 1, 2, 3, or 5 newlines after the frontmatter.

This kind of thing is sloppy, and makes it more difficult for people to contribute, as it makes finding the proper style non-trivial.

One option I considered was to inquire about the correct number of newlines in this situation, and then do another PR to standardize it. But personally, it seems much more productive to simply propose that the docs be autoformatted, which would automatically solve this issue and related issues without having to waste time discussing trivial formatting.

Note that I am only proposing that Markdown files are auto-formatted, not all of the JavaScript. (Which would obviously be a more controversial proposal.)

The two most popular solutions in this space seem to be using [Prettier](https://prettier.io/) or [dprint](https://dprint.dev/). (While both are primarily code formatters, they also auto-format Markdown documents.) For example, I believe that [`typescript-eslint` project uses Prettier for this purpose](https://github.com/typescript-eslint/typescript-eslint/blob/main/package.json#L30).

### Participation

- [X] I am willing to submit a pull request for this change.
(But this is probably something that should be done by a core maintainer, since it involves e.g. editing CI.)
Ambiguous terms: sloppy, difficult, proper, productive, trivial, controversial, popular, primarily, auto-formatted
Questions:
1. What specific inconsistencies in formatting are present in the documentation rules pages?
2. Can you clarify what you mean by "auto-formatted" in the context of Markdown files?
Clarified requirement: In the last pull request, inconsistencies were noticed in the number of newlines after the frontmatter in the Markdown documentation rules pages. To address this issue, the proposal is to automatically standardize the formatting of Markdown files using either Prettier or dprint, without altering the formatting of all JavaScript files. The aim is to simplify contribution processes and ensure a consistent style without manual intervention.


Clarify this requirement: ### ESLint version

v8.25.0

### What problem do you want to solve?

I usually work with files that are not part of a project. They are just files on the fly on my machine.

Since I like to use the "standard" rule, I have installed it globally and added the option "overrideConfigFile" to vscode eslint extension. This way I don't have to install "standard" and any other plugins every single time.

The problem comes when I have to work on a project with its own eslint rules. If I use "overrideConfigFile", it will cause some problems, like a plugin is not found or the project itself is not using "standard".

To solve this problem, I just have to open vscode "settings.json" file and comment out "overrideConfigFile" option.

### What do you think is the correct solution?

Skip the manual process of commenting out  "overrideConfigFile" in vscode settings by following the next:

If any eslint config or config file is not found on root and up directories, use the file declared in "overrideConfigFile" option (or a new option name).

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

I'm opening the request over here instead of vscode eslint extension repository because while I was looking for a solution to this problem, I found out they rely entirely on the features you add: https://github.com/microsoft/vscode-eslint/issues/482#issuecomment-395336940

So I understand if this feature is added on a new version, it would be available on vscode eslint extension as well.
Ambiguous terms: fast, user-friendly, problem, correct, solution, manual, new, available
Questions:
1. What specific action is being taken when commenting out the "overrideConfigFile" option in vscode settings?
2. How does the current process of commenting out "overrideConfigFile" affect the eslint configuration in vscode?
Clarified requirement: Update the ESLint functionality to automatically handle the configuration file specified in the "overrideConfigFile" option if no eslint config or config file is found in the root and up directories, thereby eliminating the need for manual intervention in vscode settings.


Clarify this requirement: ### ESLint version

v8.32.0

### What problem do you want to solve?

We accepted RFC29 to make options available to processors. https://github.com/eslint/eslint/pull/12068 began the implementation, but it was never finished.

We discussed this in the 2023-01-12 TSC meeting as a solution to https://github.com/eslint/eslint-plugin-markdown/issues/208 , and I'm opening this issue to track the implementation of the RFC.

### What do you think is the correct solution?

RFC29 was written before flat config so only addressed how we'd do processor options in `.eslintrc` files. A new PR should adapt that approach for use with flat config.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: correct, solution, adapt, approach
Questions:
1. What specific changes need to be made to adapt the approach for use with flat config?
2. Can you clarify what is meant by "processor options in `.eslintrc` files"?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

v8.26.0

### What problem do you want to solve?

I am currently trying to use the .eslintcache file in our jenkins ci.

Is there anyway the cache can use relative file paths? In our instance each branch is in a seperate dir but I want to reuse the cache.

### What do you think is the correct solution?

In order to move the .eslintcache around it would be great if the cache filePaths were relative

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: great, relative
Questions:
1. Can you clarify what you mean by "relative file paths" in this context?
2. How do you envision the cache filePaths being made relative?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

v8.x

### What problem do you want to solve?

there is currently a lot of variability in how rules are documented. rules pages structures and content varies significantly. this makes harder for an end user to navigate the docs, and harder for rule makers to know how to document rules.

### What do you think is the correct solution?

- Create a standardized way to document a rule.
- Apply the standardized way to X most important rules (exact number to be determined).
- Given the very large number of rules, add guidance to contributor documentation that documenting a rule using the template is a great place to start contributing to ESLint.
- Investigate using an 11ty template for the rule documentation.


### Participation

- [X] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: a lot, significantly, harder, most important, very large, great
Questions:
1. What specific aspects of rule documentation need to be standardized?
2. How will the X most important rules be determined?
Clarified requirement: ESLint version v8.x aims to standardize the documentation of rules by creating a template for rule documentation. This template will be applied to a specific number of important rules, with the exact number to be determined. Contributors will be encouraged to use this template when documenting rules, and an 11ty template will be explored for the rule documentation. Participants are required to be willing to submit a pull request for this change.


Clarify this requirement: This issue encapsulates the proposed work for updates to the ESLint documentation website, https://eslint.org/docs. 

## Phase 1: Get to know docs with smaller, well-defined tasks

Tasks:

- [x] https://github.com/eslint/eslint/issues/16310 
- [x] https://github.com/eslint/eslint/issues/13721
  *  add as a section on https://eslint.org/docs/latest/developer-guide/working-with-rules 
- [x] https://github.com/eslint/eslint/issues/16148
- [x] https://github.com/eslint/eslint/issues/16382. Page covering the core concepts of ESLint. rules, plugins, etc.

## Phase 2: High-level information architecture update

Outline and implement an update to the ESLint documentation’s [information architecture](https://technicalwriterhq.com/knowledge-management/information-architecture/) (IA). Refactor the documentation around tasks related to three core personas:

- **The User**: Someone who wants to use ESLint as it currently exists, including plugins.
- **The Extender**: Someone who wants to extend the functionality of ESLint by creating a plugin, custom formatter, custom parser, sharable configuration, etc.
- **The Contributor**: Someone who wants to add to the ESLint core project, whether submit a request or develop a a new rule. 
- **The Maintainer**: Someone who wants to oversee management of the core ESLint project.

Tasks: 

- [x] [Outline information architecture changes](https://docs.google.com/document/d/1Dyq2Ct1iHeVkGRViO2m5UJRcWJKRWOicBQu6zIpvHeE/edit?usp=sharing)
- [x] Formal RFP: https://github.com/eslint/rfcs/pull/97
- [x] https://github.com/eslint/eslint.org/pull/388
- [x] https://github.com/eslint/eslint/pull/16665
- [x] https://github.com/eslint/eslint/issues/16720
- [x] https://github.com/eslint/eslint/issues/16648
- [x] https://github.com/eslint/eslint/issues/16761
- [x] https://github.com/eslint/eslint/issues/16762
- [x] https://github.com/eslint/eslint/issues/16763
- [x] https://github.com/eslint/eslint/issues/16764
- [x] https://github.com/eslint/eslint/issues/16775

Procedure to use with each of the page moves:  [IA Update Procedure](https://gist.github.com/bpmutter/3dc4691ab5b13e29e2420f94b654a46f)

## Phase 3: “Use ESLint in Your Project” documentation update

Add additional documentation on using ESLint for the user persona.

Tasks:

- [x] [Outline section changes](https://docs.google.com/document/d/1V0nmZ8dT4oF-X8PqG-pmDeesmOmeIj_4oi5-HpgXtDk/edit#)
- [x] https://github.com/eslint/eslint/issues/16473
- [x] https://github.com/eslint/eslint/issues/16508
- [x] https://github.com/eslint/eslint/issues/16475
- [x] https://github.com/eslint/eslint/issues/16476
- [x] https://github.com/eslint/eslint/issues/16477
- [x] https://github.com/eslint/eslint/issues/16478
- [ ] https://github.com/eslint/eslint/issues/16474

## Phase 4:  “Extend ESLint” documentation update

Add additional documentation on using ESLint for the extender persona.

Tasks: 
- [x] https://github.com/eslint/eslint/discussions/16736
- [x] [Investigate creating generated reference docs for Node.js API (perhaps with tool like JSDoc)](https://github.com/eslint/eslint/pull/16735)
- [x] https://github.com/eslint/eslint/issues/16810
- [x] https://github.com/eslint/eslint/issues/16811
- [x] https://github.com/eslint/eslint/issues/16812
- [x] https://github.com/eslint/eslint/issues/16813
- [x] https://github.com/eslint/eslint/issues/16814
- [x] https://github.com/eslint/eslint/issues/16815
- [x] https://github.com/eslint/eslint/issues/16885
- [x] https://github.com/eslint/eslint/issues/16940

## Phase 5: “Maintain ESLint” documentation update

Add additional documentation on using ESLint for the maintainer persona.

Tasks:

- [x] https://github.com/eslint/eslint/discussions/16905
- [x] https://github.com/eslint/eslint/issues/16938
- [x] https://github.com/eslint/eslint/issues/16941

## Phase 6: "Integrate ESLint" documentation update 

Add additional documentation on using ESLint for the integrator persona.

Tasks:

- [x] https://github.com/eslint/eslint/issues/17133
- [x] https://github.com/eslint/eslint/issues/17134

## Phase 7: "Contribute to ESLint" documentation update 

- [x] ~~Outline section changes~~ not taking action b/c of ESLint complete re-write which'll affect some of the contributing docs (https://github.com/eslint/eslint/discussions/16557) 

## Phase 8: ESLint Flat Configs

- [x] https://github.com/eslint/eslint/issues/17229

## Miscellaneous 

New issues that have come up throughout the documentation update project. Can be completed outside of the above phases.

- [ ] https://github.com/eslint/eslint/issues/16578
- [x] https://github.com/eslint/eslint/issues/16507
- [x] Consistently use "an `.eslint...`" throughout the docs. spun off from this thread https://github.com/eslint/eslint/pull/16510#discussion_r1021793537
- [x] https://github.com/eslint/eslint/issues/16609
- [x] https://github.com/eslint/eslint/issues/16754
Ambiguous terms: update, refactor, add, implement, outline, investigate, integrate, contribute, complete, use
Questions:
1. What specific changes are required for the ESLint documentation website?
2. Can you clarify the scope of the updates needed for each phase?
Clarified requirement: The requirement involves updating the ESLint documentation website (https://eslint.org/docs) in multiple phases, each focusing on different aspects such as information architecture, user personas, and specific documentation updates. Each phase includes a set of tasks to be completed for the website enhancement.


Clarify this requirement: ### ESLint version

8.0.0

### What problem do you want to solve?

ESLint currently allows users to disable rules. In large codebases with MANY Prs, some users disable lint rules without really knowing what they are doing. This slips by PRs because reviewers sometimes don't actually review ¯\\\_(ツ)\_/¯

There exists rules such as `no-abusive-eslint-disable` but that in and of itself can be disabled

### What do you think is the correct solution?

I'd like ESLint to allow users to configure certain rules to be exempt from all comment style disables

~~eslintrc: `"noExtraSemi": ["error", "dissalowDisable"]`~~
eslintrc: `"noExtraSemi": ["forbid"]`

so in code
```
// eslint-disable-next-line noExtraSemi
const foo = 5;;
```
Would still result in an error


### Participation

- [x] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: many, some, large, really, certain, all
Questions:
1. What specific issues arise from users disabling lint rules without understanding them in large codebases with many PRs?
2. Can you provide an example of a rule that should be exempt from comment style disables?
Clarified requirement: _No response_


Clarify this requirement: ### ESLint version

v8.8.0

### What problem do you want to solve?

Currently the [ESLint demo](https://eslint.org/demo) is custom-built as part of the website.

### What do you think is the correct solution?

We'd like to make a reusable editor web component. It would replace the existing demo, and we could also use it as a built-in playground on rule pages to allow people to play around with different options. It would provide red squigglies and possibly tooltips for errors, but the containing page would be responsible for everything else.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

We added this to the roadmap in the 2022-01-27 TSC meeting.

This mostly affects the website, but I put this issue in the main repository initially because I'm guessing a good chunk of the work will be either here or in a new repository.
Ambiguous terms: reusable, user-friendly, possibly
Questions:
1. What specific features should the reusable editor web component have?
2. Who will be responsible for maintaining and updating the reusable editor web component?
Clarified requirement: Update the ESLint demo on the website to a reusable editor web component that includes red squigglies and tooltips for errors. The component should replace the existing demo and be used as a built-in playground on rule pages. The containing page will be responsible for everything else. Maintenance and updates of the component will be handled by...


Clarify this requirement: ### ESLint version

V8.0.0

### What problem do you want to solve?

Eslint spent most of its time in parsing files.  A javascript parser written in go or rust can potentially improve the the performance of eslint. However this is not possible now, because a parser written in go or rust can only be accessed by an asynchrous function, and eslint only accepts a synchronous parse function.

These external parsers can be accessed asynchronously by 1. Webassembly 2. Communicating to a child process using stdin/stdout or networking.

An example of parser written in rust is swc: https://docs.rs/swc_ecma_parser/latest/swc_ecma_parser/ .


### What do you think is the correct solution?

Accept a parser with an asynchronous parse function.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: potentially, improve, possible, asynchronously
Questions:
1. What specific performance improvements are expected by using a parser written in go or rust?
2. How would the acceptance of an asynchronous parse function impact the current functionality of ESLint?
Clarified requirement: Update ESLint to accept a parser with an asynchronous parse function to potentially improve performance by utilizing parsers written in go or rust, which can only be accessed asynchronously through methods like Webassembly or communicating with a child process using stdin/stdout or networking.


Clarify this requirement: ### ESLint version

8.4.0

### What problem do you want to solve?

Since `ESLint` supports async formatters started from [v8.4.0](https://eslint.org/blog/2021/12/eslint-v8.4.0-released#new-features-for-custom-formatters), would be great to have support of async plugins:

```js
module.exports = {
    meta: {
        type: "suggestion",

        docs: {
            description: "disallow unnecessary semicolons",
            category: "Possible Errors",
            recommended: true,
            url: "https://eslint.org/docs/rules/no-extra-semi"
        },
        fixable: "code",
        schema: [] // no options
    },
    // would be great if create can return a Promise
    create: function(context) {
        return {
            // callback functions
        };
    }
};
```

I'm working on 🐊[`Putout`](https://github.com/coderaiser/putout) code transformer, and have a plugin for `ESLint`. The thing is 🐊`Putout` has plugins which are loaded straight after parsing (depending on options provided by user).
All 🐊`Putout` plugins are `CommonJS`, and if they will be converted to `ESM` would be impossible to use 🐊`Putout` as a plugin for `ESLint`, because it supports only synchronous plugins.

This is one of the use-cases, but `ESLint` plugins can even be written in `ESM` and be loaded to `CommonJS` this way:

```js
  create: async function(context) {
       const plugin = await import('./plugin.js'); 
       return plugin;
    }
```

So this is a big step forward.

### What do you think is the correct solution?

Add support of `create` function that returns `Promise` similar to the way formatters work.

### Participation

- [ ] I am willing to submit a pull request for this change.

### Additional comments

_No response_
Ambiguous terms: great, impossible, big
Questions:
1. What specific support is needed for the `create` function in ESLint plugins?
2. Can you clarify what you mean by "impossible" in the context of using Putout as a plugin for ESLint?
Clarified requirement: Upgrade ESLint to support the `create` function in plugins to return a Promise, similar to how formatters work, enabling asynchronous plugin functionality.


Clarify this requirement: <!--
    ESLint adheres to the Open JS Foundation Code of Conduct:
    https://eslint.org/conduct

    This template is for requesting a change that is not a bug fix, rule change, or new rule. If you are here for another reason, please see below:

    1. To report a bug: https://eslint.org/docs/developer-guide/contributing/reporting-bugs
    2. To request a rule change: https://eslint.org/docs/developer-guide/contributing/rule-changes
    3. To propose a new rule: https://eslint.org/docs/developer-guide/contributing/new-rules
    4. If you have any questions, please stop by our chatroom: https://eslint.org/chat

    Note that leaving sections blank will make it difficult for us to troubleshoot and we may have to close the issue.
-->

We test rules with a custom rule tester doing a snapshot test.

The built-in RuleTester can't customize the output assertion, we don't have the output to send to `RuleTester`, so we have to use `SourceCodeFixer` to apply fix from `messages`. [Full implementation](https://github.com/sindresorhus/eslint-plugin-unicorn/blob/main/test/utils/snapshot-rule-tester.mjs#L187)

We definitely want a better way to do snapshot test, maybe pass an `assert` option in future, but before that, can we expose `SourceCodeFixer`, so I can apply fix from the message?


**The version of ESLint you are using.**

8.0.0-beta.0


**The problem you want to solve.**

Fix our rule tester.


**Are you willing to submit a pull request to implement this change?**

Yes.
Ambiguous terms: better, maybe, definitely, better
Questions:
1. What specifically needs improvement in the current snapshot test process?
2. Can you clarify what you mean by "a better way to do snapshot test"?
Clarified requirement: ESLint is using a custom rule tester for snapshot tests but wants to improve the process. Currently, the built-in RuleTester cannot customize the output assertion, so the SourceCodeFixer is used to apply fixes from messages. The request is to potentially expose SourceCodeFixer to allow applying fixes from messages. The goal is to enhance the snapshot test process, possibly by introducing an 'assert' option in the future.


Clarify this requirement: @snitin315 @nzakas @mdjermanovic

I find `physicalFilename` is not available in `ValidTestCase`, so it makes testing cases for virtual filename unavailable, should that be supported?

Before `context.getPhysicalFilename`, I have a custom util `getPhysicalFilename` and a test case like:

```js
ruleTester.run('remark', remark, {
  valid: [
    {
      code: '<header>Header2</header>',
      parser,
      parserOptions,
      filename: path.resolve(__filename, '0-fake.mdx'), // virtual filename
    },
  ],
})
```

But when I migrate to `context.getPhysicalFilename`, it results `context.getPhysicalFilename() === filename`, it is not correct, so maybe a new `physicalFilename` option is required for this case:

```js
ruleTester.run('remark', remark, {
  valid: [
    {
      code: '<header>Header2</header>',
      parser,
      parserOptions,
      physicalFilename: __filename,
      filename: path.resolve(__filename, '0-fake.mdx'), // virtual filename
    },
  ],
})
```

_Originally posted by @JounQin in https://github.com/eslint/eslint/issues/14616#issuecomment-878712207_
Ambiguous terms: supported, required
Questions:
1. What does it mean for something to be "supported" in this context?
2. What is the specific requirement for the new `physicalFilename` option?
Clarified requirement: _Originally posted by @JounQin in https://github.com/eslint/eslint/issues/14616#issuecomment-878712207_"


Clarify this requirement: **Update**: see updated description [below](https://github.com/eslint/eslint/issues/14745#issuecomment-888205829)

**The version of ESLint you are using.**

7.29.0

**The problem you want to solve.**

A few facts:

1. Per [the v7.29.0 blog release](https://eslint.org/blog/2021/06/eslint-v7.29.0-released), further changes are anticpated toward dropping `CLIEngine`.

2. Its replacement, the ESLint class, relies on some async-only methods.

3. However, ESLint rules do not, and per @nzakas in [this comment](https://github.com/eslint/eslint/issues/3565#issuecomment-868099012), there have been no discussions or apparent interest in making `Linter` async so that asynchronous rules could be supported.

This all means that if `CLIEngine` is dropped, rules cannot take advantage of ESLint linting within their own rules.

Why would one want to run linting within a linting rule?

In `eslint-plugin-jsdoc`, we allow it in three cases all within our [jsdoc/check-examples](https://github.com/gajus/eslint-plugin-jsdoc/#eslint-plugin-jsdoc-rules-check-examples) rule:

1. To lint JavaScript code within `@example` tags

2. To lint a JavaScript value within [@default/@defaultvalue](https://jsdoc.app/tags-default.html) tags

3. To lint a JavaScript expression within the likes of `@param {type} [name=default]` or `@property {type} [name=default]`

**Your take on the correct solution to problem.**

Besides adding synchronous methods, I would think that allowing some config to be passed to the `ESLint` class which triggered use of the synchronous rather than asynchronous methods would be sufficient.

**Are you willing to submit a pull request to implement this change?**

Yes (if my health-based limits on energy and concentration allow).
Ambiguous terms: fast, user-friendly, correct, sufficient, willing
Questions:
1. What specific change is being proposed for the ESLint class to address the issue of asynchronous rules?
2. How would the configuration for the ESLint class be structured to allow for the use of synchronous methods?
Clarified requirement: The requirement discusses the need for potential changes to the ESLint class to address the issue of asynchronous rules, suggesting the addition of synchronous methods and proposing a configuration option to toggle between asynchronous and synchronous methods. Additionally, the requirement mentions the possibility of submitting a pull request to implement these changes, contingent on the submitter's health-based limitations.


Clarify this requirement: **The version of ESLint you are using.**
7.28.0


**The problem you want to solve.**
Now both real code errors and ESLint errors appear at the same level in IDEs with red squiggles.
I can see an option to change all error severity to warn.
It would be nice to have yellow squiggles on ESLint ones (Now we have to manually list every rule and change its severity to `warn`)

**Your take on the correct solution to the problem.**
```
{
  severity: 'warn',
  ...
}
```
Ambiguous terms: nice
Questions:
1. What specifically do you mean by "nice" in the context of having yellow squiggles on ESLint errors?
2. Can you clarify what you mean by "manually list every rule and change its severity to `warn`"?
Clarified requirement: ```


Clarify this requirement: **The problem you want to solve.**

In a large codebase, there can easily be hundreds or even thousands of places where inline disable directive comments (like `// eslint-disable-line no-console`) have been used.

There is not currently a convenient method to find out what rules developers are disabling like this other than manually searching the codebase or writing a custom regexp parsing script. In fact, I put together a [custom script](https://github.com/ember-template-lint/ember-template-lint/blob/master/docs/count-lint-violations.sh) for exactly this purpose, but it's a bit buggy and not easily available across different projects.

Gaining an understanding / summary statistics of what rules are being most frequently disabled by contributors can be useful for a variety of reasons:
* determining what kinds of tech debt exist in a codebase
* determining what rules may be buggy and in need of improvements
* determining what issues developers need more education about
* etc

**Your take on the correct solution to problem.**

I'm proposing a new [CLI option](https://eslint.org/docs/user-guide/command-line-interface#options) `--list-disable-directives` (or similar name) that would show the complete list of inline-disabled rules by count (descending order).

```
yarn eslint --list-disable-directives .

[normal eslint output goes here]

Rule                   | Count | Relative 
:----------------------|------:|--------:
no-console             |   125 |    40.1%
no-unused-vars         |   104 |    33.3%
radix                  |    43 |    18.8%
node/no-missing-import |    22 |     7.1%
import/order           |    15 |     4.8%
prettier/prettier      |     2 |     0.6%
no-undef               |     1 |     0.3%
```

This matches the output format of the [TIMING](https://eslint.org/docs/1.0.0/developer-guide/working-with-rules#per-rule-performance) environment variable which can be used to see summary statistics about rule performance.

**Are you willing to submit a pull request to implement this change?**

Yes
Ambiguous terms: convenient, most frequently, useful, correct, proposing, complete, descending order, summary statistics
Questions:
1. What specific criteria define a rule as being "most frequently" disabled?
2. Can you provide a clearer definition of what you mean by "summary statistics"?
Clarified requirement: The goal is to introduce a new CLI option, such as `--list-disable-directives`, that will display a comprehensive list of rules that have been inline-disabled in a codebase, ranked by the frequency of their disablement. The output should be in a table format showing the rule name, the count of times it has been disabled, and the relative percentage compared to all disabled rules. This feature aims to provide insights into the most commonly disabled rules in order to identify potential tech debt, buggy rules, or areas where developers may need more education.


Clarify this requirement: <!--
    ESLint adheres to the Open JS Foundation Code of Conduct:
    https://eslint.org/conduct

    This template is for requesting a change that is not a bug fix, rule change, or new rule. If you are here for another reason, please see below:

    1. To report a bug: https://eslint.org/docs/developer-guide/contributing/reporting-bugs
    2. To request a rule change: https://eslint.org/docs/developer-guide/contributing/rule-changes
    3. To propose a new rule: https://eslint.org/docs/developer-guide/contributing/new-rules
    4. If you have any questions, please stop by our chatroom: https://eslint.org/chat

    Note that leaving sections blank will make it difficult for us to troubleshoot and we may have to close the issue.
-->



**The version of ESLint you are using.**

v7.21.0

**The problem you want to solve.**

I want to get custom data which reported with `context.report({ data })` info in `LintMessage` in `postprocess`.

**Your take on the correct solution to problem.**

For now, we got no way to get the custom data, I have to hack to use the `message` property with `JSON.stringify/parse` instead.

**Are you willing to submit a pull request to implement this change?**

Yes
Ambiguous terms: custom, hack
Questions:
1. What is meant by "custom data" in this context?
2. Can you clarify what is meant by "hack" in this situation?
Clarified requirement: The user is using ESLint version 7.21.0 and wants to retrieve data reported with `context.report({ data })` in the `LintMessage` during the `postprocess` phase. Currently, there is no direct way to access this custom data, so they are resorting to using the `message` property with `JSON.stringify/parse` instead. They are willing to submit a pull request to implement a solution for this issue.


Clarify this requirement: <!--
    ESLint adheres to the Open JS Foundation Code of Conduct:
    https://eslint.org/conduct

    This template is for requesting a change that is not a bug fix, rule change, or new rule. If you are here for another reason, please see below:

    1. To report a bug: https://eslint.org/docs/developer-guide/contributing/reporting-bugs
    2. To request a rule change: https://eslint.org/docs/developer-guide/contributing/rule-changes
    3. To propose a new rule: https://eslint.org/docs/developer-guide/contributing/new-rules
    4. If you have any questions, please stop by our chatroom: https://eslint.org/chat

    Note that leaving sections blank will make it difficult for us to troubleshoot and we may have to close the issue.
-->

**The problem you want to solve.**

ESLint assumes that each rule and source file can be processed independently. `typescript-eslint` (ref https://github.com/eslint/rfcs/pull/42#issuecomment-561296926) and `eslint-plugin-import` (ref https://github.com/eslint/rfcs/pull/42#issuecomment-536586884) need to do upfront initialization work beyond the scope of a single rule and source file, specifically loading type information and tracing a module graph. Lacking a first-class API, they have inserted these initialization steps into the regular rule linting flow.

If we were to ship parallel linting without supporting this use case, the duplicated initialization could make parallel linting _slower_ than single-threaded linting with these plugins. The large number of ESLint users who also use one of these plugins would not benefit from parallel linting.


**Your take on the correct solution to problem.**

I'm not familiar with `typescript-eslint` and `eslint-plugin-import` internals, so I'm opening this issue to gather requirements.

What I (think I) know:

- Plugins have asked for a hook to perform pre-lint initialization.
- When we ship parallel linting, currently under discussion in RFC42, plugins will need a mechanism to share the initialization result with workers.

What I want to know:

- When before linting should ESLint call plugin initialization hooks?
- What data do plugins need from ESLint? This may constrain the answer to the previous question.
- Does ESLint need to pass any of the initialization result back to plugin rules during linting (via e.g. the rule `context` object)?
- What data do plugins need to share with workers? For example, is it JSON serializable?
- Are there other plugins beside `typescript-eslint` and `eslint-plugin-import` whose authors should be part of this discussion?
- What am I missing?


**Are you willing to submit a pull request to implement this change?**

The next step will be to write an RFC, which I will write once we've settled on requirements and hopefully brainstormed some solutions.

**Related discussions:**

- https://github.com/eslint/eslint/issues/13525
- https://github.com/eslint/rfcs/pull/42
- https://github.com/eslint/rfcs/pull/11
- https://github.com/benmosher/eslint-plugin-import/issues/1931
Ambiguous terms: slower, large, benefit
Questions:
1. What specific aspect of linting speed is meant by "slower"?
2. How is the term "large" being used in the context of ESLint users?
Clarified requirement: The requirement is to gather requirements for supporting `typescript-eslint` and `eslint-plugin-import` plugins when implementing parallel linting in ESLint. This includes determining when ESLint should call plugin initialization hooks, what data plugins need from ESLint, how initialization results should be shared with workers, and involving other relevant plugin authors in the discussion.


Clarify this requirement: * **What rule do you want to change?** `no-constant-condition`
* **Does this change cause the rule to produce more or fewer warnings?**: More
**How will the change be implemented? (New option, new default behavior, etc.)?**: New default behavior

## **Please provide some example code that this change will affect:**

<!-- Put your code examples here -->
```js
var foo = true;
if(foo) {}
```

* **What does the rule currently do for this code?**: Nothing
* **What will the rule do after it's changed?**: Warn/error
* **Are you willing to submit a pull request to implement this change?**: Possibly

_This proposal has been split out of #13752_

Currently `no-constant-condition` triggers on `if(true){}` but not on `const foo = true; if(foo){}`. In this case we could use the [`ScopeManager`](https://eslint.org/docs/developer-guide/scope-manager-interface) to attempt to follow `foo` to its declaration/assignment. If the variable is in scope and only assigned once, then we could check if the assigned value is constant.

In addition to assignments, we could also check other types of declarations. For example a function declaration could trigger an error:

```javascript
function foo() {}

if(foo){} // <= foo is always truthy here
```

Additionally, @mdjermanovic pointed out that there may be other rules which could be employing a similar technique.

I've done a [simple version of this for a rule](https://gist.github.com/captbaritone/75fcbd34b046be1154dc460798be9929#file-no-useless-null-checks-js-L217-L257) I wrote (as mentioned in #13752) which could be used as a starting place.

Shout out to @bradzacher who first suggested this approach while we were iterating on my `no-useless-null-checks` rule.
Ambiguous terms: possibly, could, attempt, could, may, could, could, could
Questions:
1. What specific change is being proposed for the `no-constant-condition` rule?
2. How will the proposed change impact the behavior of the rule?
Clarified requirement: The proposal suggests enhancing the `no-constant-condition` rule to trigger warnings/errors for constant conditions like `if(true){}` and `const foo = true; if(foo){}`, by utilizing the `ScopeManager` to track variable declarations/assignments and checking for constant values.


Clarify this requirement: This issue describes the implementation plan for eslint/rfcs#9, which will take place in several phases:

## Phase 1: Extract current config system

- [x] Create new GitHub repository (`eslint/eslintrc`)
- [x] Copy`eslintrc` source files and tests into new GitHub repository
- [x] Create Jenkins release job for `@eslint/eslintrc`
- [x] Publish `@eslint/eslintrc` to npm
- [x] Update ESLint to use `@eslint/eslintrc`
- [x] Remove in-memory filesystem from tests
- [x] Update `CLIEngine` to use `CascadingConfigArrayFactory` from `@eslint/eslintrc`

## Phase 2: Implement flat config with `eslintrc` compatibility

- [x] Create the `FlatCompat` class in `eslint/eslintrc` repository
- [x] Create `FlatConfigArray` to represent simple configs
- [x] Update `Linter` class to understand `FlatConfigArray` objects
- [x] Ensure `Linter#defineRule` and `Linter#definePlugin` throw errors when using `FlatConfigArray`
- [x] Add `context.languageOptions` in backwards-compatible way to `context` in `Linter`
- [x] Ensure `context.parserPath` still works in `Linter` for `FlatConfigArray` (for now)
- [x] Create `FlatRuleTester` to allow rule testing with `FlatConfigArray` format
- [x] Create `FlatESLint` class to mirror `ESLint` class but use `eslint.config.js` instead
- [x] #15661
- [x] #15683
- [x] #15687
- [x] Implement caching
- [x] Update `cli.js` to search for `eslint.config.js` file and use `FlatESLint` if found (`ESLint` if not)
- [x] Ensure invalid CLI flags cause errors when using flat config (for example, `--resolve-plugins-relative-to`)
- [x] Switch `eslint/eslint` repo to use flat config
- [x] Document flat config
- [x] Release ESLint with `eslintrc` compatibility
- [x] #16416
- [x] #16415
- [x] #16414 
- [x] #16413 
- [x] #16410 
- [x] #16402 
- [x] #16341 
- [x] #16340 
- [x] #16299 
- [x] #16275 
- [x] #16265 
- [x] #16264
- [x] #16537
- [x] #16875

## Phase 3: Compatibility testing

- [ ] Work with `typescript-eslint` to switch to new format and ensure it works correctly ([pull request](https://github.com/typescript-eslint/typescript-eslint/pull/6836))
- [ ] Work with `eslint-plugin-import` to switch to new format and ensure it works correctly (@mdjermanovic) https://github.com/import-js/eslint-plugin-import/pull/2829 https://github.com/import-js/eslint-plugin-import/pull/2873
- [ ] Work with `eslint-config-airbnb` to switch to new format and ensure it works correctly (@mdjermanovic)
- [x] Work with `eslint-config-standard` to switch to new format and ensure it works correctly ([pull request](https://github.com/standard/eslint-config-standard/pull/277)]
- [x] Work with `eslint-plugin-n` to switch configs to new format and ensure it works correctly (@mdjermanovic) ([pull request](https://github.com/eslint-community/eslint-plugin-n/pull/95))
- [ ] Work with `eslint-plugin-vue` to switch configs to new format and ensure it works correctly ([pull request](https://github.com/vuejs/eslint-plugin-vue/pull/2226))
- [ ] Work with `eslint-plugin-react` to switch configs to new format and ensure it works correctly (@mdjermanovic) ([pull request](https://github.com/jsx-eslint/eslint-plugin-react/pull/3600))
- [x] Switch ESLint config to load external configs/plugins without `FlatCompat`
- [x] Release ESLint with extended compatibility

## Phase 4: General availability (v9.0.0)

- [x] Write blog post about flat config format
- [x] Output warning when people use `eslintrc` files
- [x] Switch documentation so `eslint.config.js` is the default and recommended format (link to legacy `eslintrc` docs from the same page)
- [x] Switch `Linter` to use flat config by default
- [x] Switch documentation for shareable configs to flat config format (links to legacy docs included)
- [x] Switch documentation for plugins to flat config format (links to legacy docs included)
- [x] #14308
- [x] Rename `ESLint` class to `LegacyESLint` and rename `FlatESLint` to `ESLint`
- [x] Delete `RuleTester` class and rename `FlatRuleTester` to `RuleTester`
- [x] Update `api.js` to export new values for `ESLint` and `RuleTester`
- [x] Switch `shouldUseFlatConfig()` to return `true` except if `ESLINT_USE_FLAT_CONFIG` is `false`.
- [x] Release ESLint with GA flat config

## Phase 5: Remove `eslintrc` (v10.0.0)

- [ ] Remove old CLI flags
- [ ] Remove `context.parserPath`, `context.parserOptions`, `context.globals` in `Linter`
- [ ] Remove `configType` constructor option for `Linter`; throw error if found.
- [ ] Report an error when `eslint-env` config comment is used
- [ ] Remove `eslintrc` support
- [ ] Remove `eslintrc` documentation
- [ ] Delete `FlatESLint` class
- [ ] Delete `LegacyESLint` class
- [ ] Switch `shouldUseFlatConfig()` to always return `true` 
- [ ] Release ESLint without `eslintrc` :tada:
Ambiguous terms: backwards-compatible, ensure, backwards-compatible way, still works, for now, compatibility, correctly, recommended, legacy, default, include, general availability, remove, support, documentation, delete
Questions:
1. What does it mean to ensure `context.parserPath` still works in `Linter` for `FlatConfigArray` "for now"?
2. What does it mean to switch `shouldUseFlatConfig()` to return `true` except if `ESLINT_USE_FLAT_CONFIG` is `false`?
Clarified requirement: - Collaborate with `typescript-eslint`, `eslint-plugin-import`, `eslint-config-airbnb`, `eslint-config-standard`, `eslint-plugin-n`, `eslint-plugin-vue`, and `eslint-plugin-react


Clarify this requirement: <!--
    ESLint adheres to the Open JS Foundation Code of Conduct:
    https://eslint.org/conduct

    This template is for requesting a change that is not a bug fix, rule change, or new rule. If you are here for another reason, please see below:

    1. To report a bug: https://eslint.org/docs/developer-guide/contributing/reporting-bugs
    2. To request a rule change: https://eslint.org/docs/developer-guide/contributing/rule-changes
    3. To propose a new rule: https://eslint.org/docs/developer-guide/contributing/new-rules
    4. If you have any questions, please stop by our chatroom: https://eslint.org/chat

    Note that leaving sections blank will make it difficult for us to troubleshoot and we may have to close the issue.
-->



**The version of ESLint you are using.**

Latest, 7.3.0.

**The problem you want to solve.**

ESLint rules can have complex schemas. Some schemas can reach 100 lines long, and often allow various formats, such as in [no-restricted-imports](https://eslint.org/docs/rules/no-restricted-imports) which allows either an array of strings or an array of objects.

Today, unit tests for a rule will ideally ensure that the rule behavior is correct for all possible combinations of valid rule options, but it is not currently possible to test that a rule correctly disallows invalid rules schemas.

For example, with the rule [no-restricted-imports](https://eslint.org/docs/rules/no-restricted-imports), I would like to test that the rule schema fails validation when passed:
* Something that isn't an array
* An empty array
* An array containing an item that isn't a string nor object
* An array containing an object that is missing required properties like `name`
* Any other invalid combinations of input

Note that I am obviously not trying to test that JSON Schema works properly, but I am trying to test that I as a rule developer have written out my schema correctly. It can be tricky to get schemas to perfectly represent what the allowed input should be, especially when we don't even try to test the invalid cases.

The goal of improved testing here is to improve the quality of our rule schemas, thus reducing the chance of rule consumers configuring rules improperly (which can result in rules silently misbehaving or crashing).

**Your take on the correct solution to problem.**

In addition to the `valid` / `invalid` test case arrays in a rule unit test file, there could be an `error` array of invalid schemas.

**Are you willing to submit a pull request to implement this change?**

Likely yes.
Ambiguous terms: complex, ideal, correctly, improve, improperly
Questions:
1. What is meant by "complex schemas" in the context of ESLint rules?
2. Can you clarify what is meant by "improve the quality of our rule schemas"?
Clarified requirement: The user is requesting a change in ESLint to allow for an `error` array of invalid schemas in addition to the `valid` / `invalid` test case arrays in a rule unit test file. This change aims to enable testing of rule schemas for correctness and reduce the chance of rule consumers configuring rules improperly.


Clarify this requirement: **Please describe what the rule should do:**

The new rule warns `obj && obj.prop`-like notations to suggest `obj?.prop`.

**What new ECMAScript feature does this rule relate to?**

Optional chaining

**What category of rule is this? (place an "X" next to just one item)**

[X] Suggests an alternate way of doing something (suggestion)

**Provide 2-3 code examples that this rule will warn about:**

<!-- Put your code examples here -->
```js
//✖ BAD
obj && obj.prop
obj != null ? obj.prop : undefined
obj && obj[key]
obj != null ? obj[key] : undefined
func && func()
func != null ? func() : undefined
if (func) func()
if (func) { func() }

//✔ GOOD
obj?.prop
obj?.[key]
func?.()
```

**Why should this rule be included in ESLint (instead of a plugin)?**

`obj && obj.prop`-like notation is a popular practice. This rule will help people to learn the new syntax Optional Chaining. This is about a language feature rather than third-party platforms or libraries.

**Are you willing to submit a pull request to implement this rule?**

Yes.
Ambiguous terms: warns, suggests, popular, help, learn
Questions:
1. What specific action does the rule take when it encounters `obj && obj.prop`-like notations?
2. How does the rule differentiate between what is considered a warning and what is considered a suggestion?
Clarified requirement: The new rule should identify and flag instances of `obj && obj.prop`-like notations, recommending the usage of `obj?.prop` instead.


Clarify this requirement: One thing that we've been missing in our documentation is translations. Other open source projects have managed to figure this out, and now that we have a budget, it's possible to get paid translations. In my mind, the key questions to get answered are:

- [ ] Which languages would we want translations for?
- [ ] How would we manage translations (storing and updating)?
- [ ] How would those translations be represented, searched, and used on the website?

I'm opening this issue to track progress on this investigation and gather feedback.
Ambiguous terms: missing, translations, managed, possible, key, manage, represented, searched, used, progress, feedback
Questions:
1. What specific types of translations are needed for the documentation?
2. How will the feedback on the translations be collected and incorporated?
Clarified requirement: The project needs to determine the languages for translations, establish a system for managing and updating translations, and decide how the translations will be displayed, searchable, and utilized on the website. This investigation is being opened to track progress and gather feedback.


Clarify this requirement: This is a discussion issue for adding ability to run eslint in parallel for multiple files.

The idea is that ESLint is mostly CPU bound, not IO bound, so creating multiple threads (for machine with multiple cores) might (and probably will) increase performance in a meaningful way. The downside is that currently ESLint's codebase is synchronous. So this would require rewriting everything up to and including eslint.js to be asynchronous, which would be a major effort.

I played with this a little while ago and found a few libraries for Node that handle thread pool, including detection of number of cores available on the machine.
- [Node-threads-a-gogo](https://github.com/xk/node-threads-a-gogo) - seems pretty good, but looks dead.
- [nPool](https://github.com/inh3/nPool) - seems actively in development, but has native components (C++)
- [Node WebWorkers](https://github.com/audreyt/node-webworker-threads) - seems pretty dead too.
- [Parallel](https://github.com/adambom/parallel.js) - seems dead, and no pool implementation.
- [Node Clusters](https://nodejs.org/api/cluster.html) - not stable yet, and probably isn't going to be available on Node v0.10
- WebWorkers - seems that they are only implemented in io.js
  And there are a ton of other libraries out there for this.

If anyone had any experience writing multithreaded applications for node.js and would like to suggest alternatives or comment on the above list, please feel free.

P.S. https://www.airpair.com/javascript/posts/which-async-javascript-libraries-should-i-use
## <bountysource-plugin>

Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/26284182-lint-multiple-files-in-parallel?utm_campaign=plugin&utm_content=tracker%2F282608&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F282608&utm_medium=issues&utm_source=github).
</bountysource-plugin>
Ambiguous terms: meaningful, major, good, dead, stable, ton
Questions:
1. What specific changes would need to be made to make ESLint's codebase asynchronous for running in parallel?
2. Can you clarify what is meant by "dead" in the context of the libraries mentioned?
Clarified requirement: This is a discussion issue regarding the addition of the ability to run ESLint in parallel for multiple files. The proposal involves making ESLint's codebase asynchronous to utilize multiple threads for improved performance. Various Node libraries for handling thread pools have been explored, but their current status and compatibility with different Node versions need to be considered. If anyone has experience with multithreaded applications in Node.js or can suggest alternatives to the libraries mentioned, your input is welcome.
